{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # 移动文件\n",
    "# import shutil\n",
    "# shutil.move(\"data/data101045/words.vector.gz\",\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already up-to-date: synonyms in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (3.16.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from synonyms) (0.20.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from synonyms) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from synonyms) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from synonyms) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! cp 'words.vector.gz' '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/synonyms/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jieba] default dict file path ../data/vocab.txt\n",
      "[jieba] default dict file path ../data/vocab.txt\n",
      "[jieba] load default dict ../data/vocab.txt ...\n",
      "[jieba] load default dict ../data/vocab.txt ...\n",
      ">> Synonyms load wordseg dict [/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/synonyms/data/vocab.txt] ... \n",
      ">> Synonyms on loading stopwords [/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/synonyms/data/stopwords.txt] ...\n",
      "[Synonyms] on loading vectors [/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/synonyms/data/words.vector.gz] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "import synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## EDA（Easy Data Augmentation）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![EDA3](https://img-blog.csdnimg.cn/50c22b4212714b509ce053ff921d6bdd.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 对于训练集中的给定句子，随机选择并执行以下操作之一：\n",
    "* 同义词替换（SR）：从句子中随机选择 n 个不是停用词的词。 用随机选择的同义词之一替换这些单词中的每一个。\n",
    "* 随机插入 (RI)：在句子中随机找到一个词，并找出其同义词，且该同义词不是停用词。 将该同义词插入句子中的随机位置。 这样做n次。\n",
    "* 随机交换（RS）：随机选择句子中的两个单词并交换它们的位置。 这样做n次。\n",
    "* 随机删除（RD）：以概率 p 随机删除句子中的每个单词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取停用词表\n",
    "import random\n",
    "import re\n",
    "from random import shuffle\n",
    "stop_words = {word.strip() for word in open('baidu_stopwords.txt', 'r', encoding='utf8').readlines()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_synonym(word):\n",
    "    syn = set(synonyms.nearby(word)[0])\n",
    "    if word in syn:\n",
    "        syn.remove(word)\n",
    "    return list(syn)\n",
    "\n",
    "def synonym_replacement(words, n):\n",
    "    new_words = words.copy()\n",
    "    # 去除停用词，去重，变成列表\n",
    "    random_word_list = list(set([word for word in words if word not in stop_words]))\n",
    "    # 打乱\n",
    "    random.shuffle(random_word_list)\n",
    "\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonym_words = get_synonym(random_word)\n",
    "        if len(synonym_words)>=1:\n",
    "            synonym = random.choice(list(synonym_words))\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        \n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "    \n",
    "    sentence = ' '.join(new_words)\n",
    "    new_words = sentence.split(' ')\n",
    "\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 使用eda进行数据增强\n",
    "def eda(sentence, alpha_sr=0.1, num_aug=9):\n",
    "    words = synonyms.seg(sentence)[0]\n",
    "    num_words = len(words)\n",
    "    n_sr = max(1, int(alpha_sr * num_words))\n",
    "\n",
    "    augmented_sentences = []\n",
    "\n",
    "    for _ in range(num_aug):\n",
    "        a_words = synonym_replacement(words, n_sr)\n",
    "        augmented_sentences.append(' '.join(a_words))\n",
    "    return augmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 存在这样一种情况\n",
    "sentence = ['in', 'war', 'one', 'must', 'be', 'a', 'good', 'actor']\n",
    "word = 'actor'\n",
    "example_synonyms = ['actress', 'film star', 'performer', 'comedian', 'entertainer']\n",
    "new_sentence = ['in', 'war', 'one', 'must', 'be', 'a', 'good', 'film star']\n",
    "new_sentence = ['in', 'war', 'one', 'must', 'be', 'a', 'good', 'film', 'star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9 月底 15 日 以来 ， GT5316SB0 、 高通 、 三星 等 OPPO 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供应 芯片 给 OPPO ， 而 中芯国际 等 国产 芯片 跨国公司 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 OPPO 。 目前 OPPO 部分 型号 的 手机 品类 出现 货 缺 的 现象 ， 若 该 形势 持续 下去 ， OPPO 手机 业务 将 遭受 重挫 。',\n",
       " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 中兴通讯 的 重要 合作伙伴 ， 只要 没有 美国 的 有关 许可证 ， 全都 无法 供货 微处理器 给 中兴通讯 ， 而 中芯国际 等 国产 微处理器 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 中兴通讯 。 目前 中兴通讯 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 中兴通讯 手机 业务 将 遭致 挫败 。',\n",
       " '9 月 15 日 以来 ， 台积电 、 Qualcomm 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供货 积体电路 给 华为 ， 而 中芯国际 等 国产 积体电路 企业 ， 也 因 采用 美国 技术开发 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货品 少 的 现象 ， 若 该 形势 持续增长 下去 ， 华为 手机 产品销售 将 遭受 重创 。',\n",
       " '9 月 15 日 以来 ， 富士康 、 高通 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 有关 营业执照 ， 都 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货商 给 华为 。 目前 华为 部分 改进型 的 手机 产品 出现 货 太少 的 乱象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
       " '9 月 15 日 以来 ， 台积电 、 德州仪器 、 三星 等 华为 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 即使 无法 供应 芯片 给 华为 ， 而 中芯国际 等 国产 芯片 跨国公司 ， 也 因 采用 美国 技术 ， 而 无法 购进 给 华为 。 目前 华为 部分 型号 的 手机 产品 出现 货 多一些 的 怪现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭逢 重创 。',\n",
       " '9 月 15 日 以来 ， A43EI235E 、 手机芯片 、 Samsung 等 宏碁 的 重要 合作伙伴 ， 只要 没有 美国 的 相关 许可证 ， 也 无法 供应 芯片 给 宏碁 ， 而 Nashik 等 国产 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 宏碁 。 目前 宏碁 部分 型号 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 宏碁 手机 业务 将 遭逢 重创 。',\n",
       " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 华为 的 重要 服务商 ， 只要 没有 美国 的 相关 许可证 ， 都 无法 供给量 芯片 给 华为 ， 而 奥罗讷 等 改良版 芯片 企业 ， 也 因 采用 美国 技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 型号 的 手机 产品销售 出现 货 少 的 现象 ， 若 该 国际形势 继续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
       " '9 年初 15 日 以来 ， TNUMBERG34iss 、 高通 、 三星 等 华为 的 重要 合作者 ， 只要 没有 美国 的 前述 许可证 ， 都 无法 供应 芯片 给 华为 ， 而 杜博韦 等 国产 芯片 企业 ， 也 因 采用 美国 关键技术 ， 而 无法 供货 给 华为 。 目前 华为 部分 基本型 的 手机 产品 出现 货 少 的 现象 ， 若 该 形势 持续 下去 ， 华为 手机 业务 将 遭受 重创 。',\n",
       " '9 月 15 日 以来 ， 台积电 、 高通 、 三星 等 小米 的 重要 合作伙伴 ， 只要 没有 英国 的 相关 许可证 ， 就 无法 供应 芯片 给 小米 ， 而 Nashik 等 国产 芯片 企业 ， 也 因 采用 英国 技术 ， 而 无法 OEM 给 小米 。 目前 小米 部分 型号 的 手机 产品 出现 货 多一点 的 现象 ， 若 该 形势 持续性 下去 ， 小米 手机 业务 将 遭受 重创 。']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda('9月15日以来，台积电、高通、三星等华为的重要合作伙伴，只要没有美国的相关许可证，都无法供应芯片给华为，而中芯国际等国产芯片企业，也因采用美国技术，而无法供货给华为。目前华为部分型号的手机产品出现货少的现象，若该形势持续下去，华为手机业务将遭受重创。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![UDA5](https://img-blog.csdnimg.cn/9d10da70d1d0467e93ef5bb1267ac87f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/88a3abe95bbd4e369fe4d085533c9c35.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bucket_sampler import SortedSampler, BucketBatchSampler\n",
    "from EMA import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "config = {\n",
    "        'train_file_path': 'data/data100821/train.json',\n",
    "        'dev_file_path': 'data/data100821/dev.json',\n",
    "        'test_file_path': 'data/data100821/test.json',\n",
    "        'output_path': '.',\n",
    "        'model_path': 'data/data94445',\n",
    "        'batch_size': 16,\n",
    "        'num_epochs': 1,\n",
    "        'max_seq_len': 64,\n",
    "        'learning_rate': 2e-5,\n",
    "        'weight_decay': 0.01,\n",
    "        'use_bucket': True,\n",
    "        'bucket_multiplier': 200,\n",
    "        'unsup_data_ratio': 1.5,\n",
    "        'uda_softmax_temp': 0.4,\n",
    "        'uda_confidence_threshold': 0.8,\n",
    "        'device': 'cuda',\n",
    "        'n_gpus': 0,\n",
    "        'logging_step': 400,\n",
    "        'ema_start_step': 500,\n",
    "        'ema_start': False,\n",
    "        'seed': 2021\n",
    "    }\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    config['device'] = 'cpu'\n",
    "else:\n",
    "    config['n_gpus'] = torch.cuda.device_count()\n",
    "    config['batch_size'] *= config['n_gpus']\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    return seed\n",
    "\n",
    "seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: transformers==4.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (4.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (4.45.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (0.0.43)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (2020.7.14)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (1.19.1)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (0.9.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (3.0.12)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from transformers==4.0.1) (2.22.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sacremoses->transformers==4.0.1) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sacremoses->transformers==4.0.1) (7.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sacremoses->transformers==4.0.1) (0.14.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging->transformers==4.0.1) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.0.1) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.0.1) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.0.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->transformers==4.0.1) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers==4.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(config['model_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer):\n",
    "    inputs_dict = tokenizer.encode_plus(sentence_a, sentence_b, add_special_tokens=True,\n",
    "                                        return_token_type_ids=True, return_attention_mask=True)\n",
    "    inputs['input_ids'].append(inputs_dict['input_ids'])\n",
    "    inputs['token_type_ids'].append(inputs_dict['token_type_ids'])\n",
    "    inputs['attention_mask'].append(inputs_dict['attention_mask'])\n",
    "    inputs['labels'].append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对偶数据增强\n",
    "### a-b对，变成b-a对, 把两个句子换顺序\n",
    "### 我们的无监督数据增强就是用的对偶数据增强\n",
    "### BERT 输入 a，b两个句子，现在输入以b,a作为输入，增强样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "def parse_data(path, data_type='train'):\n",
    "    sentence_a = []\n",
    "    sentence_b = []\n",
    "    labels = []\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in tqdm(f.readlines(), desc=f'Reading {data_type} data'):\n",
    "            line = json.loads(line)\n",
    "            sentence_a.append(line['sentence1'])\n",
    "            sentence_b.append(line['sentence2'])\n",
    "            if data_type != 'test':\n",
    "                labels.append(int(line['label']))\n",
    "            else:\n",
    "                labels.append(0)\n",
    "    df = pd.DataFrame(zip(sentence_a, sentence_b, labels), columns=['text_a', 'text_b', 'labels'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_unsup_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer):\n",
    "    lr_inputs_dict = tokenizer.encode_plus(sentence_a, sentence_b, add_special_tokens=True,\n",
    "                                           return_token_type_ids=True, return_attention_mask=True)\n",
    "    rl_inputs_dict = tokenizer.encode_plus(sentence_b, sentence_a, add_special_tokens=True,\n",
    "                                           return_token_type_ids=True, return_attention_mask=True)\n",
    "    inputs['input_ids'].append((lr_inputs_dict['input_ids'], rl_inputs_dict['input_ids']))\n",
    "    inputs['token_type_ids'].append((lr_inputs_dict['token_type_ids'], rl_inputs_dict['token_type_ids']))\n",
    "    inputs['attention_mask'].append((lr_inputs_dict['attention_mask'], rl_inputs_dict['attention_mask']))\n",
    "    inputs['labels'].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def read_data(config, tokenizer):\n",
    "    \n",
    "    train_df = parse_data(config['train_file_path'], data_type='train')\n",
    "    dev_df = parse_data(config['dev_file_path'], data_type='dev')\n",
    "    test_df = parse_data(config['test_file_path'], data_type='test')\n",
    "\n",
    "    data_df = {'train': train_df, 'dev': dev_df, 'test': test_df}\n",
    "    processed_data = {}\n",
    "\n",
    "    unsup_data = defaultdict(list)\n",
    "    \n",
    "    for data_type, df in data_df.items():\n",
    "        inputs = defaultdict(list)\n",
    "        if data_type == 'train':\n",
    "            reversed_inputs = defaultdict(list)\n",
    "        for i, row in tqdm(df.iterrows(), desc=f'Preprocessing {data_type} data', total=len(df)):\n",
    "            label = 0 if data_type == 'test' else row[2]\n",
    "            sentence_a, sentence_b = row[0], row[1]\n",
    "            build_bert_inputs(inputs, label, sentence_a, sentence_b, tokenizer)\n",
    "\n",
    "            if data_type.startswith('test'):\n",
    "                build_bert_inputs(inputs, label, sentence_b, sentence_a, tokenizer)\n",
    "\n",
    "            build_unsup_bert_inputs(unsup_data, label, sentence_a, sentence_b, tokenizer)\n",
    "\n",
    "        processed_data[data_type] = inputs\n",
    "    \n",
    "    processed_data['unsup_data'] = unsup_data\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading train data: 100%|██████████| 34334/34334 [00:00<00:00, 259237.08it/s]\n",
      "Reading dev data: 100%|██████████| 4316/4316 [00:00<00:00, 269488.43it/s]\n",
      "Reading test data: 100%|██████████| 3861/3861 [00:00<00:00, 265531.05it/s]\n",
      "Preprocessing train data: 100%|██████████| 34334/34334 [00:43<00:00, 795.18it/s]\n",
      "Preprocessing dev data: 100%|██████████| 4316/4316 [00:05<00:00, 800.04it/s]\n",
      "Preprocessing test data: 100%|██████████| 3861/3861 [00:06<00:00, 623.95it/s]\n"
     ]
    }
   ],
   "source": [
    "data = read_data(config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class AFQMCDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dict):\n",
    "        super(AFQMCDataset, self).__init__()\n",
    "        self.data_dict = data_dict\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = (self.data_dict['input_ids'][index], self.data_dict['token_type_ids'][index],\n",
    "                self.data_dict['attention_mask'][index], self.data_dict['labels'][index])\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dict['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Collator:\n",
    "    def __init__(self, max_seq_len, tokenizer):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def pad_and_truncate(self, input_ids_list, token_type_ids_list,\n",
    "                         attention_mask_list, labels_list, max_seq_len):\n",
    "        input_ids = torch.zeros((len(input_ids_list), max_seq_len), dtype=torch.long)\n",
    "        token_type_ids = torch.zeros_like(input_ids)\n",
    "        attention_mask = torch.zeros_like(input_ids)\n",
    "        for i in range(len(input_ids_list)):\n",
    "            seq_len = len(input_ids_list[i])\n",
    "            if seq_len <= max_seq_len:\n",
    "                input_ids[i, :seq_len] = torch.tensor(input_ids_list[i], dtype=torch.long)\n",
    "                token_type_ids[i, :seq_len] = torch.tensor(token_type_ids_list[i], dtype=torch.long)\n",
    "                attention_mask[i, :seq_len] = torch.tensor(attention_mask_list[i], dtype=torch.long)\n",
    "            else:\n",
    "                input_ids[i] = torch.tensor(input_ids_list[i][:max_seq_len - 1] + [self.tokenizer.sep_token_id],\n",
    "                                            dtype=torch.long)\n",
    "                token_type_ids[i] = torch.tensor(token_type_ids_list[i][:max_seq_len], dtype=torch.long)\n",
    "                attention_mask[i] = torch.tensor(attention_mask_list[i][:max_seq_len], dtype=torch.long)\n",
    "\n",
    "\n",
    "        labels = torch.tensor(labels_list, dtype=torch.long)\n",
    "        return input_ids, token_type_ids, attention_mask, labels\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        input_ids_list, token_type_ids_list, attention_mask_list, labels_list = list(zip(*examples))\n",
    "        cur_max_seq_len = max(len(input_id) for input_id in input_ids_list)\n",
    "        max_seq_len = min(cur_max_seq_len, self.max_seq_len)\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask, labels = self.pad_and_truncate(input_ids_list, token_type_ids_list,\n",
    "                                                                                  attention_mask_list, labels_list,\n",
    "                                                                                  max_seq_len)\n",
    "\n",
    "        data_dict = {\n",
    "            'input_ids': input_ids,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collate_fn = Collator(config['max_seq_len'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UnsupAFQMCDataset(Dataset):\n",
    "    # UDA\n",
    "    def __init__(self, data_dict):\n",
    "        super(UnsupAFQMCDataset, self).__init__()\n",
    "        self.data_dict = data_dict\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_ids = self.data_dict['input_ids'][index]\n",
    "        token_type_ids = self.data_dict['token_type_ids'][index]\n",
    "        attention_mask = self.data_dict['attention_mask'][index]\n",
    "        labels = self.data_dict['labels'][index]\n",
    "        return (input_ids[0], token_type_ids[0], attention_mask[0],\n",
    "                input_ids[1], token_type_ids[1], attention_mask[1],\n",
    "                labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dict['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UnsupCollator(Collator):\n",
    "\n",
    "    def __init__(self, max_seq_len, tokenizer):\n",
    "        super(UnsupCollator, self).__init__(max_seq_len, tokenizer)\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        (ab_input_ids_list, ab_token_type_ids_list, ab_attention_mask_list,\n",
    "         ba_input_ids_list, ba_token_type_ids_list, ba_attention_mask_list,\n",
    "         labels_list) = list(zip(*examples))\n",
    "\n",
    "        cur_max_seq_len = max(len(input_id) for input_id in ab_input_ids_list)\n",
    "        max_seq_len = min(cur_max_seq_len, self.max_seq_len)\n",
    "        \n",
    "        ab_input_ids, ab_token_type_ids, ab_attention_mask, labels = self.pad_and_truncate(\n",
    "            ab_input_ids_list, ab_token_type_ids_list, ab_attention_mask_list, labels_list, max_seq_len\n",
    "        )\n",
    "\n",
    "        ba_input_ids, ba_token_type_ids, ba_attention_mask, labels = self.pad_and_truncate(\n",
    "            ba_input_ids_list, ba_token_type_ids_list, ba_attention_mask_list, labels_list, max_seq_len\n",
    "        )\n",
    "        \n",
    "        data_dict = {\n",
    "            'ab_input_ids': ab_input_ids,\n",
    "            'ab_token_type_ids': ab_token_type_ids,\n",
    "            'ab_attention_mask': ab_attention_mask,\n",
    "            'ba_input_ids': ba_input_ids,\n",
    "            'ba_token_type_ids': ba_token_type_ids,\n",
    "            'ba_attention_mask': ba_attention_mask,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "def build_dataloader(config, data, tokenizer):\n",
    "    train_dataset = AFQMCDataset(data['train'])\n",
    "    dev_dataset = AFQMCDataset(data['dev'])\n",
    "    test_dataset = AFQMCDataset(data['test'])\n",
    "    unsup_dataset = UnsupAFQMCDataset(data['unsup_data'])\n",
    "    \n",
    "    collate_fn = Collator(config['max_seq_len'], tokenizer)\n",
    "    unsup_collate_fn = UnsupCollator(config['max_seq_len'], tokenizer)\n",
    "    \n",
    "    if config['use_bucket']:\n",
    "        train_sampler = RandomSampler(train_dataset)\n",
    "        \n",
    "        bucket_sampler = BucketBatchSampler(train_sampler, batch_size=config['batch_size'],\n",
    "                                            drop_last=False, sort_key=lambda x: len(train_dataset[x][0]),  # 以 input_id 长度作为排序的指标\n",
    "                                            bucket_size_multiplier=config['bucket_multiplier'])\n",
    "\n",
    "        train_dataloader = DataLoader(dataset=train_dataset, batch_sampler=bucket_sampler,\n",
    "                                      num_workers=4, collate_fn=collate_fn)\n",
    "        \n",
    "        unsup_sampler = RandomSampler(unsup_dataset)\n",
    "\n",
    "        unsup_bucket_sampler = BucketBatchSampler(unsup_sampler, \n",
    "                            batch_size=int(config['batch_size'] * config['unsup_data_ratio']),\n",
    "                            drop_last=False, sort_key=lambda x: len(unsup_dataset[x][0]),  # 以 input_id 长度作为排序的指标\n",
    "                            bucket_size_multiplier=config['bucket_multiplier'])\n",
    "                    \n",
    "        unsup_dataloader = DataLoader(dataset=unsup_dataset, \n",
    "                            batch_sampler=unsup_bucket_sampler,\n",
    "                            num_workers=4, collate_fn=unsup_collate_fn)\n",
    "                            \n",
    "\n",
    "    else:\n",
    "        train_dataloader = DataLoader(dataset=train_dataset, batch_size=config['batch_size'],\n",
    "                                      shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "        \n",
    "        unsup_dataloader = DataLoader(\n",
    "            dataset=unsup_dataset, shuffle=True, num_workers=4, collate_fn=unsup_collate_fn,\n",
    "            batch_size=int(config['batch_size'] * config['unsup_data_ratio'])\n",
    "        )\n",
    "\n",
    "    dev_dataloader = DataLoader(dataset=dev_dataset, batch_size=config['batch_size'],\n",
    "                                shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
    "\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=config['batch_size'],\n",
    "                                 shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
    "\n",
    "    return unsup_dataloader, train_dataloader, dev_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unsup_dataloader, train_dataloader, dev_dataloader, test_dataloader = build_dataloader(config, data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# evaluation \n",
    "from sklearn import metrics\n",
    "def evaluation(config, model, val_dataloader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    val_loss = 0.\n",
    "    val_iterator = tqdm(val_dataloader, desc='Evaluation', total=len(val_dataloader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_iterator:\n",
    "            labels.append(batch['labels'])\n",
    "            batch_cuda = {item: value.to(config['device']) for item, value in list(batch.items())}\n",
    "            batch_cuda['mode'] = 'val'\n",
    "            loss, logits = model(**batch_cuda)[:2]\n",
    "\n",
    "            if config['n_gpus'] > 1:\n",
    "                loss = loss.mean()\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds.append(logits.argmax(dim=-1).detach().cpu())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    labels = torch.cat(labels, dim=0).numpy()\n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "    f1 = metrics.f1_score(labels, preds)\n",
    "    acc = metrics.accuracy_score(labels, preds)\n",
    "    return avg_val_loss, f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 复写 BertForSequenceClassification\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch.nn as nn\n",
    "class BertForAFQMC(BertForSequenceClassification):\n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                token_type_ids,\n",
    "                attention_mask,\n",
    "                labels=None,\n",
    "                mode='train'):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        outputs = (logits, )\n",
    "\n",
    "        if mode == 'val':\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "            loss = loss_fct(logits, labels.view(-1))\n",
    "                \n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/88a3abe95bbd4e369fe4d085533c9c35.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/38a2b12d76094f17819ae918b25f3c71.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![addtitional Training1](https://img-blog.csdnimg.cn/5916fe8ae028469bb877d15a1ac566de.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 用于无监督训练数据中\n",
    "基于置信度的MASK，发现MASK当前模型不自信的examples很有帮助。总结来水，无监督数据（grad)data ba_unsup_value）要 选出置信度>$\\beta$的样本（够自信的样本）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![UDA5](https://img-blog.csdnimg.cn/1ddf28077b88449aa84e0391149467e4.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "在半监督学习中，经常会遇到未标记数据量和标记数据量存在巨大差异的情况\\\n",
    "模型通常很快会在标记数据上过拟合，同时在未标记数据欠拟合。\\\n",
    "为了解决这个问题，引入一种技术，训练信号退火（TSA）. 它随着训练的进行逐渐释放。\\\n",
    "\n",
    "这是一种MASK\\\n",
    "$\\eta=1$ 代表所有数据都训练了\n",
    "$\\eta=0.5$  代表不是所有数据都训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tsa_threshold(total_steps, global_steps):\n",
    "    return np.exp((global_steps / total_steps - 1) * 5) / 2 + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/b21349f49ba446b698e6f27823983fc5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![ce](https://img-blog.csdnimg.cn/52f18386dbea423f846611c558aa24c7.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "$$CE = -plogq$$   \n",
    "$$E = -plogp$$\n",
    "p-真实分布（已知） q-预测分布\n",
    "$$KLDiv(p||q) = \\sum_{i=1}^{N}p(x_{i})(logp(x_{i})- logq(x_{i}))$$\n",
    "$$ = p(logp-logq) $$\n",
    "$$ = -plogq - (- plogp)$$\n",
    "$$ = CE-E$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![cross entropy](https://img-blog.csdnimg.cn/4572c78d76624c49b01b96a1cba42279.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![KL](https://img-blog.csdnimg.cn/189e4bc953904c199afbc7e6a11e5d9a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/88a3abe95bbd4e369fe4d085533c9c35.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/38a2b12d76094f17819ae918b25f3c71.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 返回 grad_data：需要计算梯度，需要进行反向传播的数据\n",
    "# 返回 no_grad_data: 不需要计算梯度，不需要进行反向传播的数据\n",
    "def get_data(sup_batch, unsup_batch, config):\n",
    "    grad_data = {}\n",
    "    no_grad_data = {}\n",
    "    # sup_batch [bs, seq_len]\n",
    "    # unsup_batch [bs, seq_len]\n",
    "    # 监督数据的 最长 长度\n",
    "    sup_max_len = sup_batch['input_ids'].size(1)\n",
    "\n",
    "    # 无监督数据 的最长 长度\n",
    "    unsup_max_len = unsup_batch['ba_input_ids'].size(1)\n",
    "\n",
    "    # 当前数据 的最长 长度\n",
    "    cur_max_len = max(sup_max_len, unsup_max_len)\n",
    "\n",
    "    for item, sup_value in sup_batch.items():\n",
    "        if item == 'labels':\n",
    "            grad_data[item] = sup_value.to(config['device'])\n",
    "            continue\n",
    "        \n",
    "        ba_unsup_value = unsup_batch[f'ba_{item}']\n",
    "        ab_unsup_value = unsup_batch[f'ab_{item}']\n",
    "\n",
    "        # 谁短补谁，ba_unsup_value短\n",
    "        if sup_max_len == cur_max_len:\n",
    "            padding_value = torch.zeros((ba_unsup_value.size(0), cur_max_len - unsup_max_len),\n",
    "                                        dtype=ba_unsup_value.dtype)\n",
    "            ba_unsup_value = torch.cat([ba_unsup_value, padding_value], dim=-1)\n",
    "\n",
    "        else:\n",
    "            padding_value = torch.zeros((sup_value.size(0), cur_max_len - sup_max_len),\n",
    "                                        dtype=sup_value.dtype)\n",
    "            sup_value = torch.cat([sup_value, padding_value], dim=-1)\n",
    "        \n",
    "        # 把 sup_batch 和 ba 的 数据放在一起\n",
    "        grad_value = torch.cat([sup_value, ba_unsup_value], dim=0)\n",
    "\n",
    "        grad_data[item] = grad_value.to(config['device'])\n",
    "        no_grad_data[item] = ab_unsup_value.to(config['device'])\n",
    "\n",
    "    return grad_data, no_grad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2871,  0.6413, -0.8615],\n",
      "        [-0.3649, -0.6931,  0.9023]])\n",
      "tensor([[0.8092, 0.1561, 0.0347],\n",
      "        [0.1897, 0.1366, 0.6737]])\n",
      "tensor([[9.8356e-01, 1.6068e-02, 3.7519e-04],\n",
      "        [3.9675e-02, 1.7467e-02, 9.4286e-01]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "logits = torch.randn(2,3)\n",
    "print(logits)\n",
    "t_softmax = torch.softmax(logits, dim=1)\n",
    "print(t_softmax)\n",
    "t_sharpen = torch.softmax(logits/0.4, dim=1)\n",
    "print(t_sharpen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # 无监督数据 (ab) 只需要正向传播\n",
    "def forward_no_grad(no_grad_data, config, model):\n",
    "    with torch.no_grad():\n",
    "        np_grad_logits = model(**no_grad_data)[0]\n",
    "        # ----------- sharpen -------------#\n",
    "        no_grad_probs = torch.softmax(np_grad_logits / config['uda_softmax_temp'], dim=-1)\n",
    "        # ----------- sharpen -------------#\n",
    "        # largest_probs [B] [0.879, 0.987, 0.234, 0.768, 0.333]\n",
    "        largest_probs, _= no_grad_probs.max(dim=-1)\n",
    "        unsup_loss_mask = largest_probs.gt(config['uda_confidence_threshold']).float()\n",
    "        # unsup_loss_mask tensor([True, True, False, True, False])\n",
    "    return unsup_loss_mask, no_grad_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/b21349f49ba446b698e6f27823983fc5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTI4NzA2MA==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward_with_grad(unsup_loss_mask, unsup_probs, config, cur_bs, \n",
    "    model, grad_data, total_steps, global_steps):\n",
    "    # 得到\\eta值， 随着训练的进行，阈值逐渐变大，最后是1，把所有监督数据都用上了\n",
    "    tsa_threshold = get_tsa_threshold(total_steps, global_steps)\n",
    "    \n",
    "    logits = model(**grad_data)[0]\n",
    "    # --------- 有监督损失 -------#\n",
    "    # cur_bs 无监督 ba 的 batch_size\n",
    "    # 前面一部分是 train 的 sup_data, 后面是unsup_data\n",
    "    sup_logits, unsup_logits = logits.split([logits.size(0)-cur_bs, cur_bs])\n",
    "\n",
    "    # 得到 sup_labels\n",
    "    sup_labels = grad_data['labels'][:logits.size(0)-cur_bs]\n",
    "\n",
    "    per_example_loss = nn.CrossEntropyLoss(reduction='none')(sup_logits, sup_labels)\n",
    "    \n",
    "    # 拿出 正确标签 对应的概率\n",
    "    correct_label_probs = torch.softmax(sup_logits, dim=-1).gather(dim=-1, index=sup_labels.view(-1, 1))\n",
    "    \n",
    "    # 监督数据 过于自信不要，留下小于等于 tsa_threshold 的计算损失\n",
    "    sup_loss_mask = correct_label_probs.le(tsa_threshold).squeeze().float()\n",
    "    \n",
    "    # 应用mask掩盖有监督数据过度自信的样本损失\n",
    "    per_example_loss *= sup_loss_mask\n",
    "    \n",
    "    # 有效监督样本的平均损失\n",
    "    sup_loss = per_example_loss.sum()/max(sup_loss_mask.sum(), 1) # max(sup_loss_mask.sum(), 1) 有效个数\n",
    "    # --------- 有监督损失 -------#\n",
    "\n",
    "\n",
    "    # --------- 无监督损失 -------#\n",
    "    unsup_log_probs = torch.log_softmax(unsup_logits, dim=-1)\n",
    "    # input 希望是一个对数概率\n",
    "    # Target 目标为概率值\n",
    "    per_example_kl_loss = nn.KLDivLoss(reduction='none')(unsup_log_probs, unsup_probs).sum(dim=-1)\n",
    "\n",
    "    # 应用mask掩盖无监督数据中不自信的样本损失\n",
    "    per_example_kl_loss *= unsup_loss_mask\n",
    "\n",
    "    # 计算无监督样本的平均损失\n",
    "    unsup_loss = per_example_kl_loss.sum()/max(unsup_loss_mask.sum(), 1)\n",
    "    # --------- 无监督损失 -------#\n",
    "\n",
    "    # 加权两种损失\n",
    "    loss = sup_loss + unsup_loss\n",
    "\n",
    "    # 多卡取平均\n",
    "    if config['n_gpus']>1:\n",
    "        loss = loss.mean()\n",
    "        sup_loss = sup_loss.mean()\n",
    "        unsup_loss = unsup_loss.mean()\n",
    "    \n",
    "    return loss, tsa_threshold, unsup_loss, sup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import trange\n",
    "import os\n",
    "def train(config, train_dataloader, dev_dataloader, unsup_dataloader=None):\n",
    "    model = BertForAFQMC.from_pretrained(config['model_path'])\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    model.to(config['device'])\n",
    "    # unsup_dataloader train, dev, test\n",
    "    # 使用 unsup_dataloader，因为unsup_dataloader比较大\n",
    "    total_steps = len(unsup_dataloader) * config['num_epochs']\n",
    "    epoch_iterator = trange(config['num_epochs'])\n",
    "    global_steps = 0\n",
    "    train_loss = 0.\n",
    "    logging_loss = 0.\n",
    "    best_acc = 0.\n",
    "    best_model_path = ''\n",
    "\n",
    "    if config['n_gpus'] > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    train_iterator = iter(train_dataloader)\n",
    "    for _ in epoch_iterator:\n",
    "        unsup_iterator = tqdm(unsup_dataloader, desc='Training', total=len(unsup_dataloader))\n",
    "        model.train()\n",
    "        # ----------------------- new ----------------------#\n",
    "        for unsup_batch in unsup_iterator:\n",
    "            cur_bs = unsup_batch['ab_input_ids'].size(0)\n",
    "            try:\n",
    "                sup_batch = next(train_iterator)\n",
    "            except StopIteration:\n",
    "                train_iterator = iter(train_dataloader)\n",
    "                sup_batch = next(train_iterator)\n",
    "            \n",
    "            # 返回 grad_data：需要计算梯度，需要进行反向传播的数据\n",
    "            # 返回 no_grad_data: 不需要计算梯度，不需要进行反向传播的数据\n",
    "            grad_data, no_grad_data = get_data(sup_batch, unsup_batch, config)\n",
    "            \n",
    "            # 无监督数据 (ab) 只需要正向传播\n",
    "            # mask, ab_logits\n",
    "            unsup_loss_mask, unsup_probs = forward_no_grad(no_grad_data, config, model)\n",
    "             \n",
    "            # 得出loss\n",
    "            loss, tsa_threshold, unsup_loss, sup_loss = forward_with_grad(\n",
    "                unsup_loss_mask, unsup_probs, config, cur_bs, model, grad_data, total_steps, global_steps\n",
    "            )\n",
    "            \n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            if config['ema_start']:\n",
    "                ema.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            global_steps += 1\n",
    "\n",
    "            unsup_iterator.set_postfix_str(f'running training loss: {loss.item():.4f}')\n",
    "        \n",
    "            if global_steps % config['logging_step'] == 0:\n",
    "                if global_steps >= config['ema_start_step'] and not config['ema_start']:\n",
    "                    print('\\n>>> EMA starting ...')\n",
    "                    config['ema_start'] = True\n",
    "                    ema = EMA(model.module if hasattr(model, 'module') else model, decay=0.999)\n",
    "\n",
    "                print_train_loss = (train_loss - logging_loss) / config['logging_step']\n",
    "                logging_loss = train_loss\n",
    "\n",
    "                if config['ema_start']:\n",
    "                    ema.apply_shadow()\n",
    "                val_loss, f1, acc = evaluation(config, model, dev_dataloader)\n",
    "\n",
    "                print_log = f'\\n>>> training loss: {print_train_loss:.6f}, valid loss: {val_loss:.6f}, '\n",
    "\n",
    "                if acc > best_acc:\n",
    "                    model_save_path = os.path.join(config['output_path'],\n",
    "                                                   f'checkpoint-{global_steps}-{acc:.6f}')\n",
    "                    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "                    model_to_save.save_pretrained(model_save_path)\n",
    "                    best_acc = acc\n",
    "                    best_model_path = model_save_path\n",
    "\n",
    "                print_log += f'valid f1: {f1:.6f}, valid acc: {acc:.6f}'\n",
    "\n",
    "                print(print_log)\n",
    "                model.train()\n",
    "                if config['ema_start']:\n",
    "                    ema.restore()\n",
    "\n",
    "    return model, best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at data/data94445 were not used when initializing BertForAFQMC: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForAFQMC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForAFQMC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForAFQMC were not initialized from the model checkpoint at data/data94445 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/1772 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   0%|          | 0/1772 [00:01<?, ?it/s, running training loss: 1.1108]\u001b[A\n",
      "Training:   0%|          | 1/1772 [00:01<37:37,  1.27s/it, running training loss: 1.1108]\u001b[A\n",
      "Training:   0%|          | 1/1772 [00:01<37:37,  1.27s/it, running training loss: 1.0437]\u001b[A\n",
      "Training:   0%|          | 2/1772 [00:01<27:40,  1.07it/s, running training loss: 1.0437]\u001b[A\n",
      "Training:   0%|          | 2/1772 [00:01<27:40,  1.07it/s, running training loss: 1.0851]\u001b[A\n",
      "Training:   0%|          | 3/1772 [00:01<20:28,  1.44it/s, running training loss: 1.0851]\u001b[A\n",
      "Training:   0%|          | 3/1772 [00:01<20:28,  1.44it/s, running training loss: 1.2696]\u001b[A\n",
      "Training:   0%|          | 4/1772 [00:01<16:00,  1.84it/s, running training loss: 1.2696]\u001b[A\n",
      "Training:   0%|          | 4/1772 [00:01<16:00,  1.84it/s, running training loss: 1.0886]\u001b[A\n",
      "Training:   0%|          | 5/1772 [00:01<12:14,  2.41it/s, running training loss: 1.0886]\u001b[A\n",
      "Training:   0%|          | 5/1772 [00:01<12:14,  2.41it/s, running training loss: 0.9456]\u001b[A\n",
      "Training:   0%|          | 6/1772 [00:01<09:36,  3.06it/s, running training loss: 0.9456]\u001b[A\n",
      "Training:   0%|          | 6/1772 [00:02<09:36,  3.06it/s, running training loss: 1.0038]\u001b[A\n",
      "Training:   0%|          | 7/1772 [00:02<07:47,  3.77it/s, running training loss: 1.0038]\u001b[A\n",
      "Training:   0%|          | 7/1772 [00:02<07:47,  3.77it/s, running training loss: 1.1169]\u001b[A\n",
      "Training:   0%|          | 8/1772 [00:02<06:42,  4.39it/s, running training loss: 1.1169]\u001b[A\n",
      "Training:   0%|          | 8/1772 [00:02<06:42,  4.39it/s, running training loss: 0.9052]\u001b[A\n",
      "Training:   1%|          | 9/1772 [00:02<05:48,  5.06it/s, running training loss: 0.9052]\u001b[A\n",
      "Training:   1%|          | 9/1772 [00:02<05:48,  5.06it/s, running training loss: 0.8634]\u001b[A\n",
      "Training:   1%|          | 10/1772 [00:02<05:07,  5.72it/s, running training loss: 0.8634]\u001b[A\n",
      "Training:   1%|          | 10/1772 [00:02<05:07,  5.72it/s, running training loss: 0.8412]\u001b[A\n",
      "Training:   1%|          | 11/1772 [00:02<04:51,  6.04it/s, running training loss: 0.8412]\u001b[A\n",
      "Training:   1%|          | 11/1772 [00:02<04:51,  6.04it/s, running training loss: 1.1239]\u001b[A\n",
      "Training:   1%|          | 12/1772 [00:02<04:22,  6.70it/s, running training loss: 1.1239]\u001b[A\n",
      "Training:   1%|          | 12/1772 [00:02<04:22,  6.70it/s, running training loss: 0.9325]\u001b[A\n",
      "Training:   1%|          | 13/1772 [00:02<04:07,  7.12it/s, running training loss: 0.9325]\u001b[A\n",
      "Training:   1%|          | 13/1772 [00:03<04:07,  7.12it/s, running training loss: 0.9187]\u001b[A\n",
      "Training:   1%|          | 14/1772 [00:03<04:03,  7.23it/s, running training loss: 0.9187]\u001b[A\n",
      "Training:   1%|          | 14/1772 [00:03<04:03,  7.23it/s, running training loss: 0.8340]\u001b[A\n",
      "Training:   1%|          | 15/1772 [00:03<03:51,  7.58it/s, running training loss: 0.8340]\u001b[A\n",
      "Training:   1%|          | 15/1772 [00:03<03:51,  7.58it/s, running training loss: 0.9730]\u001b[A\n",
      "Training:   1%|          | 16/1772 [00:03<03:54,  7.50it/s, running training loss: 0.9730]\u001b[A\n",
      "Training:   1%|          | 16/1772 [00:03<03:54,  7.50it/s, running training loss: 0.9689]\u001b[A\n",
      "Training:   1%|          | 17/1772 [00:03<03:50,  7.61it/s, running training loss: 0.9689]\u001b[A\n",
      "Training:   1%|          | 17/1772 [00:03<03:50,  7.61it/s, running training loss: 1.0367]\u001b[A\n",
      "Training:   1%|          | 18/1772 [00:03<03:48,  7.66it/s, running training loss: 1.0367]\u001b[A\n",
      "Training:   1%|          | 18/1772 [00:03<03:48,  7.66it/s, running training loss: 1.1254]\u001b[A\n",
      "Training:   1%|          | 19/1772 [00:03<03:56,  7.42it/s, running training loss: 1.1254]\u001b[A\n",
      "Training:   1%|          | 19/1772 [00:03<03:56,  7.42it/s, running training loss: 1.1078]\u001b[A\n",
      "Training:   1%|          | 20/1772 [00:03<03:49,  7.63it/s, running training loss: 1.1078]\u001b[A\n",
      "Training:   1%|          | 20/1772 [00:03<03:49,  7.63it/s, running training loss: 0.8381]\u001b[A\n",
      "Training:   1%|          | 21/1772 [00:03<03:43,  7.85it/s, running training loss: 0.8381]\u001b[A\n",
      "Training:   1%|          | 21/1772 [00:04<03:43,  7.85it/s, running training loss: 1.1149]\u001b[A\n",
      "Training:   1%|          | 22/1772 [00:04<04:02,  7.22it/s, running training loss: 1.1149]\u001b[A\n",
      "Training:   1%|          | 22/1772 [00:04<04:02,  7.22it/s, running training loss: 1.0172]\u001b[A\n",
      "Training:   1%|▏         | 23/1772 [00:04<03:52,  7.53it/s, running training loss: 1.0172]\u001b[A\n",
      "Training:   1%|▏         | 23/1772 [00:04<03:52,  7.53it/s, running training loss: 1.0895]\u001b[A\n",
      "Training:   1%|▏         | 24/1772 [00:04<03:56,  7.39it/s, running training loss: 1.0895]\u001b[A\n",
      "Training:   1%|▏         | 24/1772 [00:04<03:56,  7.39it/s, running training loss: 1.2376]\u001b[A\n",
      "Training:   1%|▏         | 25/1772 [00:04<03:49,  7.61it/s, running training loss: 1.2376]\u001b[A\n",
      "Training:   1%|▏         | 25/1772 [00:04<03:49,  7.61it/s, running training loss: 1.3198]\u001b[A\n",
      "Training:   1%|▏         | 26/1772 [00:04<03:47,  7.66it/s, running training loss: 1.3198]\u001b[A\n",
      "Training:   1%|▏         | 26/1772 [00:04<03:47,  7.66it/s, running training loss: 0.8903]\u001b[A\n",
      "Training:   2%|▏         | 27/1772 [00:04<03:45,  7.74it/s, running training loss: 0.8903]\u001b[A\n",
      "Training:   2%|▏         | 27/1772 [00:04<03:45,  7.74it/s, running training loss: 0.9750]\u001b[A\n",
      "Training:   2%|▏         | 28/1772 [00:04<04:17,  6.77it/s, running training loss: 0.9750]\u001b[A\n",
      "Training:   2%|▏         | 28/1772 [00:05<04:17,  6.77it/s, running training loss: 1.0035]\u001b[A\n",
      "Training:   2%|▏         | 29/1772 [00:05<04:14,  6.84it/s, running training loss: 1.0035]\u001b[A\n",
      "Training:   2%|▏         | 29/1772 [00:05<04:14,  6.84it/s, running training loss: 0.8061]\u001b[A\n",
      "Training:   2%|▏         | 30/1772 [00:05<04:06,  7.07it/s, running training loss: 0.8061]\u001b[A\n",
      "Training:   2%|▏         | 30/1772 [00:05<04:06,  7.07it/s, running training loss: 0.7595]\u001b[A\n",
      "Training:   2%|▏         | 31/1772 [00:05<03:56,  7.37it/s, running training loss: 0.7595]\u001b[A\n",
      "Training:   2%|▏         | 31/1772 [00:05<03:56,  7.37it/s, running training loss: 1.0077]\u001b[A\n",
      "Training:   2%|▏         | 32/1772 [00:05<03:46,  7.68it/s, running training loss: 1.0077]\u001b[A\n",
      "Training:   2%|▏         | 32/1772 [00:05<03:46,  7.68it/s, running training loss: 1.0033]\u001b[A\n",
      "Training:   2%|▏         | 33/1772 [00:05<03:43,  7.77it/s, running training loss: 1.0033]\u001b[A\n",
      "Training:   2%|▏         | 33/1772 [00:05<03:43,  7.77it/s, running training loss: 0.9317]\u001b[A\n",
      "Training:   2%|▏         | 34/1772 [00:05<03:53,  7.43it/s, running training loss: 0.9317]\u001b[A\n",
      "Training:   2%|▏         | 34/1772 [00:05<03:53,  7.43it/s, running training loss: 0.9582]\u001b[A\n",
      "Training:   2%|▏         | 35/1772 [00:05<03:53,  7.45it/s, running training loss: 0.9582]\u001b[A\n",
      "Training:   2%|▏         | 35/1772 [00:05<03:53,  7.45it/s, running training loss: 1.0644]\u001b[A\n",
      "Training:   2%|▏         | 36/1772 [00:05<03:50,  7.52it/s, running training loss: 1.0644]\u001b[A\n",
      "Training:   2%|▏         | 36/1772 [00:06<03:50,  7.52it/s, running training loss: 1.0912]\u001b[A\n",
      "Training:   2%|▏         | 37/1772 [00:06<03:45,  7.70it/s, running training loss: 1.0912]\u001b[A\n",
      "Training:   2%|▏         | 37/1772 [00:06<03:45,  7.70it/s, running training loss: 0.8151]\u001b[A\n",
      "Training:   2%|▏         | 38/1772 [00:06<03:48,  7.58it/s, running training loss: 0.8151]\u001b[A\n",
      "Training:   2%|▏         | 38/1772 [00:06<03:48,  7.58it/s, running training loss: 1.0744]\u001b[A\n",
      "Training:   2%|▏         | 39/1772 [00:06<03:57,  7.29it/s, running training loss: 1.0744]\u001b[A\n",
      "Training:   2%|▏         | 39/1772 [00:06<03:57,  7.29it/s, running training loss: 0.7827]\u001b[A\n",
      "Training:   2%|▏         | 40/1772 [00:06<03:53,  7.41it/s, running training loss: 0.7827]\u001b[A\n",
      "Training:   2%|▏         | 40/1772 [00:06<03:53,  7.41it/s, running training loss: 1.0464]\u001b[A\n",
      "Training:   2%|▏         | 41/1772 [00:06<03:49,  7.55it/s, running training loss: 1.0464]\u001b[A\n",
      "Training:   2%|▏         | 41/1772 [00:06<03:49,  7.55it/s, running training loss: 1.2588]\u001b[A\n",
      "Training:   2%|▏         | 42/1772 [00:06<03:43,  7.75it/s, running training loss: 1.2588]\u001b[A\n",
      "Training:   2%|▏         | 42/1772 [00:06<03:43,  7.75it/s, running training loss: 0.9669]\u001b[A\n",
      "Training:   2%|▏         | 43/1772 [00:06<03:49,  7.54it/s, running training loss: 0.9669]\u001b[A\n",
      "Training:   2%|▏         | 43/1772 [00:06<03:49,  7.54it/s, running training loss: 1.0096]\u001b[A\n",
      "Training:   2%|▏         | 44/1772 [00:06<03:48,  7.56it/s, running training loss: 1.0096]\u001b[A\n",
      "Training:   2%|▏         | 44/1772 [00:07<03:48,  7.56it/s, running training loss: 1.0056]\u001b[A\n",
      "Training:   3%|▎         | 45/1772 [00:07<04:02,  7.13it/s, running training loss: 1.0056]\u001b[A\n",
      "Training:   3%|▎         | 45/1772 [00:07<04:02,  7.13it/s, running training loss: 1.0232]\u001b[A\n",
      "Training:   3%|▎         | 46/1772 [00:07<03:56,  7.30it/s, running training loss: 1.0232]\u001b[A\n",
      "Training:   3%|▎         | 46/1772 [00:07<03:56,  7.30it/s, running training loss: 1.1494]\u001b[A\n",
      "Training:   3%|▎         | 47/1772 [00:07<03:43,  7.73it/s, running training loss: 1.1494]\u001b[A\n",
      "Training:   3%|▎         | 47/1772 [00:07<03:43,  7.73it/s, running training loss: 1.0011]\u001b[A\n",
      "Training:   3%|▎         | 48/1772 [00:07<03:38,  7.91it/s, running training loss: 1.0011]\u001b[A\n",
      "Training:   3%|▎         | 48/1772 [00:07<03:38,  7.91it/s, running training loss: 0.9980]\u001b[A\n",
      "Training:   3%|▎         | 49/1772 [00:07<03:50,  7.46it/s, running training loss: 0.9980]\u001b[A\n",
      "Training:   3%|▎         | 49/1772 [00:07<03:50,  7.46it/s, running training loss: 1.1420]\u001b[A\n",
      "Training:   3%|▎         | 50/1772 [00:07<03:45,  7.65it/s, running training loss: 1.1420]\u001b[A\n",
      "Training:   3%|▎         | 50/1772 [00:07<03:45,  7.65it/s, running training loss: 1.1929]\u001b[A\n",
      "Training:   3%|▎         | 51/1772 [00:07<03:40,  7.79it/s, running training loss: 1.1929]\u001b[A\n",
      "Training:   3%|▎         | 51/1772 [00:08<03:40,  7.79it/s, running training loss: 0.9128]\u001b[A\n",
      "Training:   3%|▎         | 52/1772 [00:08<03:34,  8.02it/s, running training loss: 0.9128]\u001b[A\n",
      "Training:   3%|▎         | 52/1772 [00:08<03:34,  8.02it/s, running training loss: 1.0541]\u001b[A\n",
      "Training:   3%|▎         | 53/1772 [00:08<04:11,  6.84it/s, running training loss: 1.0541]\u001b[A\n",
      "Training:   3%|▎         | 53/1772 [00:08<04:11,  6.84it/s, running training loss: 1.1898]\u001b[A\n",
      "Training:   3%|▎         | 54/1772 [00:08<04:37,  6.19it/s, running training loss: 1.1898]\u001b[A\n",
      "Training:   3%|▎         | 54/1772 [00:08<04:37,  6.19it/s, running training loss: 0.9499]\u001b[A\n",
      "Training:   3%|▎         | 55/1772 [00:08<04:11,  6.83it/s, running training loss: 0.9499]\u001b[A\n",
      "Training:   3%|▎         | 55/1772 [00:08<04:11,  6.83it/s, running training loss: 1.0185]\u001b[A\n",
      "Training:   3%|▎         | 56/1772 [00:08<04:17,  6.67it/s, running training loss: 1.0185]\u001b[A\n",
      "Training:   3%|▎         | 56/1772 [00:08<04:17,  6.67it/s, running training loss: 1.0621]\u001b[A\n",
      "Training:   3%|▎         | 57/1772 [00:08<04:29,  6.36it/s, running training loss: 1.0621]\u001b[A\n",
      "Training:   3%|▎         | 57/1772 [00:09<04:29,  6.36it/s, running training loss: 1.1030]\u001b[A\n",
      "Training:   3%|▎         | 58/1772 [00:09<04:22,  6.54it/s, running training loss: 1.1030]\u001b[A\n",
      "Training:   3%|▎         | 58/1772 [00:09<04:22,  6.54it/s, running training loss: 0.8216]\u001b[A\n",
      "Training:   3%|▎         | 59/1772 [00:09<04:07,  6.92it/s, running training loss: 0.8216]\u001b[A\n",
      "Training:   3%|▎         | 59/1772 [00:09<04:07,  6.92it/s, running training loss: 1.0065]\u001b[A\n",
      "Training:   3%|▎         | 60/1772 [00:09<04:07,  6.91it/s, running training loss: 1.0065]\u001b[A\n",
      "Training:   3%|▎         | 60/1772 [00:09<04:07,  6.91it/s, running training loss: 0.9173]\u001b[A\n",
      "Training:   3%|▎         | 61/1772 [00:09<04:05,  6.96it/s, running training loss: 0.9173]\u001b[A\n",
      "Training:   3%|▎         | 61/1772 [00:09<04:05,  6.96it/s, running training loss: 1.0717]\u001b[A\n",
      "Training:   3%|▎         | 62/1772 [00:09<04:04,  7.01it/s, running training loss: 1.0717]\u001b[A\n",
      "Training:   3%|▎         | 62/1772 [00:09<04:04,  7.01it/s, running training loss: 1.0096]\u001b[A\n",
      "Training:   4%|▎         | 63/1772 [00:09<04:11,  6.80it/s, running training loss: 1.0096]\u001b[A\n",
      "Training:   4%|▎         | 63/1772 [00:09<04:11,  6.80it/s, running training loss: 0.9357]\u001b[A\n",
      "Training:   4%|▎         | 64/1772 [00:09<03:53,  7.30it/s, running training loss: 0.9357]\u001b[A\n",
      "Training:   4%|▎         | 64/1772 [00:09<03:53,  7.30it/s, running training loss: 0.9801]\u001b[A\n",
      "Training:   4%|▎         | 65/1772 [00:09<03:39,  7.79it/s, running training loss: 0.9801]\u001b[A\n",
      "Training:   4%|▎         | 65/1772 [00:10<03:39,  7.79it/s, running training loss: 1.0990]\u001b[A\n",
      "Training:   4%|▎         | 66/1772 [00:10<03:50,  7.39it/s, running training loss: 1.0990]\u001b[A\n",
      "Training:   4%|▎         | 66/1772 [00:10<03:50,  7.39it/s, running training loss: 0.9567]\u001b[A\n",
      "Training:   4%|▍         | 67/1772 [00:10<03:42,  7.67it/s, running training loss: 0.9567]\u001b[A\n",
      "Training:   4%|▍         | 67/1772 [00:10<03:42,  7.67it/s, running training loss: 0.8345]\u001b[A\n",
      "Training:   4%|▍         | 68/1772 [00:10<03:36,  7.88it/s, running training loss: 0.8345]\u001b[A\n",
      "Training:   4%|▍         | 68/1772 [00:10<03:36,  7.88it/s, running training loss: 0.9816]\u001b[A\n",
      "Training:   4%|▍         | 69/1772 [00:10<03:28,  8.15it/s, running training loss: 0.9816]\u001b[A\n",
      "Training:   4%|▍         | 69/1772 [00:10<03:28,  8.15it/s, running training loss: 1.0496]\u001b[A\n",
      "Training:   4%|▍         | 70/1772 [00:10<03:33,  7.98it/s, running training loss: 1.0496]\u001b[A\n",
      "Training:   4%|▍         | 70/1772 [00:10<03:33,  7.98it/s, running training loss: 1.0092]\u001b[A\n",
      "Training:   4%|▍         | 71/1772 [00:10<03:46,  7.49it/s, running training loss: 1.0092]\u001b[A\n",
      "Training:   4%|▍         | 71/1772 [00:10<03:46,  7.49it/s, running training loss: 1.0820]\u001b[A\n",
      "Training:   4%|▍         | 72/1772 [00:10<03:45,  7.53it/s, running training loss: 1.0820]\u001b[A\n",
      "Training:   4%|▍         | 72/1772 [00:10<03:45,  7.53it/s, running training loss: 0.8964]\u001b[A\n",
      "Training:   4%|▍         | 73/1772 [00:10<03:33,  7.94it/s, running training loss: 0.8964]\u001b[A\n",
      "Training:   4%|▍         | 73/1772 [00:11<03:33,  7.94it/s, running training loss: 0.8753]\u001b[A\n",
      "Training:   4%|▍         | 74/1772 [00:11<03:53,  7.28it/s, running training loss: 0.8753]\u001b[A\n",
      "Training:   4%|▍         | 74/1772 [00:11<03:53,  7.28it/s, running training loss: 0.9169]\u001b[A\n",
      "Training:   4%|▍         | 75/1772 [00:11<03:38,  7.75it/s, running training loss: 0.9169]\u001b[A\n",
      "Training:   4%|▍         | 75/1772 [00:11<03:38,  7.75it/s, running training loss: 1.0696]\u001b[A\n",
      "Training:   4%|▍         | 76/1772 [00:11<03:40,  7.68it/s, running training loss: 1.0696]\u001b[A\n",
      "Training:   4%|▍         | 76/1772 [00:11<03:40,  7.68it/s, running training loss: 1.0740]\u001b[A\n",
      "Training:   4%|▍         | 77/1772 [00:11<03:38,  7.77it/s, running training loss: 1.0740]\u001b[A\n",
      "Training:   4%|▍         | 77/1772 [00:11<03:38,  7.77it/s, running training loss: 1.0764]\u001b[A\n",
      "Training:   4%|▍         | 78/1772 [00:11<03:52,  7.29it/s, running training loss: 1.0764]\u001b[A\n",
      "Training:   4%|▍         | 78/1772 [00:11<03:52,  7.29it/s, running training loss: 0.9867]\u001b[A\n",
      "Training:   4%|▍         | 79/1772 [00:11<03:48,  7.40it/s, running training loss: 0.9867]\u001b[A\n",
      "Training:   4%|▍         | 79/1772 [00:11<03:48,  7.40it/s, running training loss: 0.8143]\u001b[A\n",
      "Training:   5%|▍         | 80/1772 [00:11<03:37,  7.79it/s, running training loss: 0.8143]\u001b[A\n",
      "Training:   5%|▍         | 80/1772 [00:12<03:37,  7.79it/s, running training loss: 0.9919]\u001b[A\n",
      "Training:   5%|▍         | 81/1772 [00:12<03:47,  7.42it/s, running training loss: 0.9919]\u001b[A\n",
      "Training:   5%|▍         | 81/1772 [00:12<03:47,  7.42it/s, running training loss: 1.0958]\u001b[A\n",
      "Training:   5%|▍         | 82/1772 [00:12<03:49,  7.35it/s, running training loss: 1.0958]\u001b[A\n",
      "Training:   5%|▍         | 82/1772 [00:12<03:49,  7.35it/s, running training loss: 1.1243]\u001b[A\n",
      "Training:   5%|▍         | 83/1772 [00:12<03:43,  7.54it/s, running training loss: 1.1243]\u001b[A\n",
      "Training:   5%|▍         | 83/1772 [00:12<03:43,  7.54it/s, running training loss: 1.0222]\u001b[A\n",
      "Training:   5%|▍         | 84/1772 [00:12<03:37,  7.75it/s, running training loss: 1.0222]\u001b[A\n",
      "Training:   5%|▍         | 84/1772 [00:12<03:37,  7.75it/s, running training loss: 0.7783]\u001b[A\n",
      "Training:   5%|▍         | 85/1772 [00:12<03:42,  7.60it/s, running training loss: 0.7783]\u001b[A\n",
      "Training:   5%|▍         | 85/1772 [00:12<03:42,  7.60it/s, running training loss: 0.9227]\u001b[A\n",
      "Training:   5%|▍         | 86/1772 [00:12<03:45,  7.46it/s, running training loss: 0.9227]\u001b[A\n",
      "Training:   5%|▍         | 86/1772 [00:12<03:45,  7.46it/s, running training loss: 0.9629]\u001b[A\n",
      "Training:   5%|▍         | 87/1772 [00:12<03:40,  7.64it/s, running training loss: 0.9629]\u001b[A\n",
      "Training:   5%|▍         | 87/1772 [00:12<03:40,  7.64it/s, running training loss: 1.0130]\u001b[A\n",
      "Training:   5%|▍         | 88/1772 [00:12<03:38,  7.72it/s, running training loss: 1.0130]\u001b[A\n",
      "Training:   5%|▍         | 88/1772 [00:13<03:38,  7.72it/s, running training loss: 1.1419]\u001b[A\n",
      "Training:   5%|▌         | 89/1772 [00:13<03:33,  7.88it/s, running training loss: 1.1419]\u001b[A\n",
      "Training:   5%|▌         | 89/1772 [00:13<03:33,  7.88it/s, running training loss: 1.0074]\u001b[A\n",
      "Training:   5%|▌         | 90/1772 [00:13<03:42,  7.57it/s, running training loss: 1.0074]\u001b[A\n",
      "Training:   5%|▌         | 90/1772 [00:13<03:42,  7.57it/s, running training loss: 1.0216]\u001b[A\n",
      "Training:   5%|▌         | 91/1772 [00:13<03:35,  7.80it/s, running training loss: 1.0216]\u001b[A\n",
      "Training:   5%|▌         | 91/1772 [00:13<03:35,  7.80it/s, running training loss: 1.1034]\u001b[A\n",
      "Training:   5%|▌         | 92/1772 [00:13<03:32,  7.89it/s, running training loss: 1.1034]\u001b[A\n",
      "Training:   5%|▌         | 92/1772 [00:13<03:32,  7.89it/s, running training loss: 1.2442]\u001b[A\n",
      "Training:   5%|▌         | 93/1772 [00:13<03:37,  7.71it/s, running training loss: 1.2442]\u001b[A\n",
      "Training:   5%|▌         | 93/1772 [00:13<03:37,  7.71it/s, running training loss: 0.8957]\u001b[A\n",
      "Training:   5%|▌         | 94/1772 [00:13<03:34,  7.84it/s, running training loss: 0.8957]\u001b[A\n",
      "Training:   5%|▌         | 94/1772 [00:13<03:34,  7.84it/s, running training loss: 1.0979]\u001b[A\n",
      "Training:   5%|▌         | 95/1772 [00:13<03:39,  7.64it/s, running training loss: 1.0979]\u001b[A\n",
      "Training:   5%|▌         | 95/1772 [00:14<03:39,  7.64it/s, running training loss: 1.0411]\u001b[A\n",
      "Training:   5%|▌         | 96/1772 [00:14<03:43,  7.49it/s, running training loss: 1.0411]\u001b[A\n",
      "Training:   5%|▌         | 96/1772 [00:14<03:43,  7.49it/s, running training loss: 0.9548]\u001b[A\n",
      "Training:   5%|▌         | 97/1772 [00:14<03:58,  7.03it/s, running training loss: 0.9548]\u001b[A\n",
      "Training:   5%|▌         | 97/1772 [00:14<03:58,  7.03it/s, running training loss: 1.0530]\u001b[A\n",
      "Training:   6%|▌         | 98/1772 [00:14<04:00,  6.97it/s, running training loss: 1.0530]\u001b[A\n",
      "Training:   6%|▌         | 98/1772 [00:14<04:00,  6.97it/s, running training loss: 1.0019]\u001b[A\n",
      "Training:   6%|▌         | 99/1772 [00:14<03:59,  6.98it/s, running training loss: 1.0019]\u001b[A\n",
      "Training:   6%|▌         | 99/1772 [00:14<03:59,  6.98it/s, running training loss: 0.8582]\u001b[A\n",
      "Training:   6%|▌         | 100/1772 [00:14<04:27,  6.24it/s, running training loss: 0.8582]\u001b[A\n",
      "Training:   6%|▌         | 100/1772 [00:14<04:27,  6.24it/s, running training loss: 1.1566]\u001b[A\n",
      "Training:   6%|▌         | 101/1772 [00:14<04:31,  6.15it/s, running training loss: 1.1566]\u001b[A\n",
      "Training:   6%|▌         | 101/1772 [00:14<04:31,  6.15it/s, running training loss: 1.0650]\u001b[A\n",
      "Training:   6%|▌         | 102/1772 [00:14<04:11,  6.65it/s, running training loss: 1.0650]\u001b[A\n",
      "Training:   6%|▌         | 102/1772 [00:15<04:11,  6.65it/s, running training loss: 1.3538]\u001b[A\n",
      "Training:   6%|▌         | 103/1772 [00:15<04:01,  6.90it/s, running training loss: 1.3538]\u001b[A\n",
      "Training:   6%|▌         | 103/1772 [00:15<04:01,  6.90it/s, running training loss: 1.0373]\u001b[A\n",
      "Training:   6%|▌         | 104/1772 [00:15<03:48,  7.28it/s, running training loss: 1.0373]\u001b[A\n",
      "Training:   6%|▌         | 104/1772 [00:15<03:48,  7.28it/s, running training loss: 1.1034]\u001b[A\n",
      "Training:   6%|▌         | 105/1772 [00:15<03:51,  7.19it/s, running training loss: 1.1034]\u001b[A\n",
      "Training:   6%|▌         | 105/1772 [00:15<03:51,  7.19it/s, running training loss: 1.0085]\u001b[A\n",
      "Training:   6%|▌         | 106/1772 [00:15<03:46,  7.37it/s, running training loss: 1.0085]\u001b[A\n",
      "Training:   6%|▌         | 106/1772 [00:15<03:46,  7.37it/s, running training loss: 1.0806]\u001b[A\n",
      "Training:   6%|▌         | 107/1772 [00:15<03:40,  7.56it/s, running training loss: 1.0806]\u001b[A\n",
      "Training:   6%|▌         | 107/1772 [00:15<03:40,  7.56it/s, running training loss: 1.0056]\u001b[A\n",
      "Training:   6%|▌         | 108/1772 [00:15<03:36,  7.70it/s, running training loss: 1.0056]\u001b[A\n",
      "Training:   6%|▌         | 108/1772 [00:15<03:36,  7.70it/s, running training loss: 1.0192]\u001b[A\n",
      "Training:   6%|▌         | 109/1772 [00:15<03:38,  7.61it/s, running training loss: 1.0192]\u001b[A\n",
      "Training:   6%|▌         | 109/1772 [00:15<03:38,  7.61it/s, running training loss: 1.0009]\u001b[A\n",
      "Training:   6%|▌         | 110/1772 [00:15<03:27,  8.01it/s, running training loss: 1.0009]\u001b[A\n",
      "Training:   6%|▌         | 110/1772 [00:16<03:27,  8.01it/s, running training loss: 0.9890]\u001b[A\n",
      "Training:   6%|▋         | 111/1772 [00:16<03:26,  8.05it/s, running training loss: 0.9890]\u001b[A\n",
      "Training:   6%|▋         | 111/1772 [00:16<03:26,  8.05it/s, running training loss: 1.1460]\u001b[A\n",
      "Training:   6%|▋         | 112/1772 [00:16<03:23,  8.16it/s, running training loss: 1.1460]\u001b[A\n",
      "Training:   6%|▋         | 112/1772 [00:16<03:23,  8.16it/s, running training loss: 0.9470]\u001b[A\n",
      "Training:   6%|▋         | 113/1772 [00:16<03:52,  7.15it/s, running training loss: 0.9470]\u001b[A\n",
      "Training:   6%|▋         | 113/1772 [00:16<03:52,  7.15it/s, running training loss: 1.0511]\u001b[A\n",
      "Training:   6%|▋         | 114/1772 [00:16<03:41,  7.47it/s, running training loss: 1.0511]\u001b[A\n",
      "Training:   6%|▋         | 114/1772 [00:16<03:41,  7.47it/s, running training loss: 0.9939]\u001b[A\n",
      "Training:   6%|▋         | 115/1772 [00:16<03:58,  6.95it/s, running training loss: 0.9939]\u001b[A\n",
      "Training:   6%|▋         | 115/1772 [00:16<03:58,  6.95it/s, running training loss: 1.1372]\u001b[A\n",
      "Training:   7%|▋         | 116/1772 [00:16<03:38,  7.59it/s, running training loss: 1.1372]\u001b[A\n",
      "Training:   7%|▋         | 116/1772 [00:16<03:38,  7.59it/s, running training loss: 0.8327]\u001b[A\n",
      "Training:   7%|▋         | 117/1772 [00:16<03:29,  7.91it/s, running training loss: 0.8327]\u001b[A\n",
      "Training:   7%|▋         | 117/1772 [00:17<03:29,  7.91it/s, running training loss: 0.9017]\u001b[A\n",
      "Training:   7%|▋         | 118/1772 [00:17<03:28,  7.92it/s, running training loss: 0.9017]\u001b[A\n",
      "Training:   7%|▋         | 118/1772 [00:17<03:28,  7.92it/s, running training loss: 0.9580]\u001b[A\n",
      "Training:   7%|▋         | 119/1772 [00:17<03:29,  7.88it/s, running training loss: 0.9580]\u001b[A\n",
      "Training:   7%|▋         | 119/1772 [00:17<03:29,  7.88it/s, running training loss: 0.9807]\u001b[A\n",
      "Training:   7%|▋         | 120/1772 [00:17<03:31,  7.81it/s, running training loss: 0.9807]\u001b[A\n",
      "Training:   7%|▋         | 120/1772 [00:17<03:31,  7.81it/s, running training loss: 0.9926]\u001b[A\n",
      "Training:   7%|▋         | 121/1772 [00:17<03:27,  7.95it/s, running training loss: 0.9926]\u001b[A\n",
      "Training:   7%|▋         | 121/1772 [00:17<03:27,  7.95it/s, running training loss: 0.9452]\u001b[A\n",
      "Training:   7%|▋         | 122/1772 [00:17<03:20,  8.21it/s, running training loss: 0.9452]\u001b[A\n",
      "Training:   7%|▋         | 122/1772 [00:17<03:20,  8.21it/s, running training loss: 1.0507]\u001b[A\n",
      "Training:   7%|▋         | 123/1772 [00:17<03:34,  7.70it/s, running training loss: 1.0507]\u001b[A\n",
      "Training:   7%|▋         | 123/1772 [00:17<03:34,  7.70it/s, running training loss: 0.9315]\u001b[A\n",
      "Training:   7%|▋         | 124/1772 [00:17<03:37,  7.59it/s, running training loss: 0.9315]\u001b[A\n",
      "Training:   7%|▋         | 124/1772 [00:17<03:37,  7.59it/s, running training loss: 1.2688]\u001b[A\n",
      "Training:   7%|▋         | 125/1772 [00:17<03:48,  7.21it/s, running training loss: 1.2688]\u001b[A\n",
      "Training:   7%|▋         | 125/1772 [00:18<03:48,  7.21it/s, running training loss: 1.1719]\u001b[A\n",
      "Training:   7%|▋         | 126/1772 [00:18<03:39,  7.49it/s, running training loss: 1.1719]\u001b[A\n",
      "Training:   7%|▋         | 126/1772 [00:18<03:39,  7.49it/s, running training loss: 1.1850]\u001b[A\n",
      "Training:   7%|▋         | 127/1772 [00:18<03:32,  7.74it/s, running training loss: 1.1850]\u001b[A\n",
      "Training:   7%|▋         | 127/1772 [00:18<03:32,  7.74it/s, running training loss: 1.1578]\u001b[A\n",
      "Training:   7%|▋         | 128/1772 [00:18<03:45,  7.28it/s, running training loss: 1.1578]\u001b[A\n",
      "Training:   7%|▋         | 128/1772 [00:18<03:45,  7.28it/s, running training loss: 0.9820]\u001b[A\n",
      "Training:   7%|▋         | 129/1772 [00:18<03:36,  7.59it/s, running training loss: 0.9820]\u001b[A\n",
      "Training:   7%|▋         | 129/1772 [00:18<03:36,  7.59it/s, running training loss: 1.2496]\u001b[A\n",
      "Training:   7%|▋         | 130/1772 [00:18<03:59,  6.85it/s, running training loss: 1.2496]\u001b[A\n",
      "Training:   7%|▋         | 130/1772 [00:18<03:59,  6.85it/s, running training loss: 1.0461]\u001b[A\n",
      "Training:   7%|▋         | 131/1772 [00:18<03:57,  6.92it/s, running training loss: 1.0461]\u001b[A\n",
      "Training:   7%|▋         | 131/1772 [00:18<03:57,  6.92it/s, running training loss: 0.9350]\u001b[A\n",
      "Training:   7%|▋         | 132/1772 [00:18<03:59,  6.84it/s, running training loss: 0.9350]\u001b[A\n",
      "Training:   7%|▋         | 132/1772 [00:19<03:59,  6.84it/s, running training loss: 1.1014]\u001b[A\n",
      "Training:   8%|▊         | 133/1772 [00:19<03:44,  7.31it/s, running training loss: 1.1014]\u001b[A\n",
      "Training:   8%|▊         | 133/1772 [00:19<03:44,  7.31it/s, running training loss: 0.7539]\u001b[A\n",
      "Training:   8%|▊         | 134/1772 [00:19<04:15,  6.42it/s, running training loss: 0.7539]\u001b[A\n",
      "Training:   8%|▊         | 134/1772 [00:19<04:15,  6.42it/s, running training loss: 0.8525]\u001b[A\n",
      "Training:   8%|▊         | 135/1772 [00:19<04:17,  6.36it/s, running training loss: 0.8525]\u001b[A\n",
      "Training:   8%|▊         | 135/1772 [00:19<04:17,  6.36it/s, running training loss: 0.8221]\u001b[A\n",
      "Training:   8%|▊         | 136/1772 [00:19<03:58,  6.86it/s, running training loss: 0.8221]\u001b[A\n",
      "Training:   8%|▊         | 136/1772 [00:19<03:58,  6.86it/s, running training loss: 0.9842]\u001b[A\n",
      "Training:   8%|▊         | 137/1772 [00:19<03:42,  7.34it/s, running training loss: 0.9842]\u001b[A\n",
      "Training:   8%|▊         | 137/1772 [00:19<03:42,  7.34it/s, running training loss: 0.7590]\u001b[A\n",
      "Training:   8%|▊         | 138/1772 [00:19<03:34,  7.63it/s, running training loss: 0.7590]\u001b[A\n",
      "Training:   8%|▊         | 138/1772 [00:19<03:34,  7.63it/s, running training loss: 1.0283]\u001b[A\n",
      "Training:   8%|▊         | 139/1772 [00:19<03:31,  7.74it/s, running training loss: 1.0283]\u001b[A\n",
      "Training:   8%|▊         | 139/1772 [00:20<03:31,  7.74it/s, running training loss: 1.0553]\u001b[A\n",
      "Training:   8%|▊         | 140/1772 [00:20<03:33,  7.65it/s, running training loss: 1.0553]\u001b[A\n",
      "Training:   8%|▊         | 140/1772 [00:20<03:33,  7.65it/s, running training loss: 0.8797]\u001b[A\n",
      "Training:   8%|▊         | 141/1772 [00:20<03:22,  8.07it/s, running training loss: 0.8797]\u001b[A\n",
      "Training:   8%|▊         | 141/1772 [00:20<03:22,  8.07it/s, running training loss: 1.0836]\u001b[A\n",
      "Training:   8%|▊         | 142/1772 [00:20<03:37,  7.50it/s, running training loss: 1.0836]\u001b[A\n",
      "Training:   8%|▊         | 142/1772 [00:20<03:37,  7.50it/s, running training loss: 0.9573]\u001b[A\n",
      "Training:   8%|▊         | 143/1772 [00:20<04:02,  6.73it/s, running training loss: 0.9573]\u001b[A\n",
      "Training:   8%|▊         | 143/1772 [00:20<04:02,  6.73it/s, running training loss: 1.0182]\u001b[A\n",
      "Training:   8%|▊         | 144/1772 [00:20<04:20,  6.25it/s, running training loss: 1.0182]\u001b[A\n",
      "Training:   8%|▊         | 144/1772 [00:20<04:20,  6.25it/s, running training loss: 1.0616]\u001b[A\n",
      "Training:   8%|▊         | 145/1772 [00:20<04:15,  6.37it/s, running training loss: 1.0616]\u001b[A\n",
      "Training:   8%|▊         | 145/1772 [00:20<04:15,  6.37it/s, running training loss: 0.9144]\u001b[A\n",
      "Training:   8%|▊         | 146/1772 [00:20<04:22,  6.20it/s, running training loss: 0.9144]\u001b[A\n",
      "Training:   8%|▊         | 146/1772 [00:21<04:22,  6.20it/s, running training loss: 1.0421]\u001b[A\n",
      "Training:   8%|▊         | 147/1772 [00:21<04:08,  6.53it/s, running training loss: 1.0421]\u001b[A\n",
      "Training:   8%|▊         | 147/1772 [00:21<04:08,  6.53it/s, running training loss: 1.0599]\u001b[A\n",
      "Training:   8%|▊         | 148/1772 [00:21<04:19,  6.25it/s, running training loss: 1.0599]\u001b[A\n",
      "Training:   8%|▊         | 148/1772 [00:21<04:19,  6.25it/s, running training loss: 1.2035]\u001b[A\n",
      "Training:   8%|▊         | 149/1772 [00:21<04:20,  6.23it/s, running training loss: 1.2035]\u001b[A\n",
      "Training:   8%|▊         | 149/1772 [00:21<04:20,  6.23it/s, running training loss: 1.2594]\u001b[A\n",
      "Training:   8%|▊         | 150/1772 [00:21<04:17,  6.31it/s, running training loss: 1.2594]\u001b[A\n",
      "Training:   8%|▊         | 150/1772 [00:21<04:17,  6.31it/s, running training loss: 1.4100]\u001b[A\n",
      "Training:   9%|▊         | 151/1772 [00:21<03:57,  6.84it/s, running training loss: 1.4100]\u001b[A\n",
      "Training:   9%|▊         | 151/1772 [00:21<03:57,  6.84it/s, running training loss: 1.1486]\u001b[A\n",
      "Training:   9%|▊         | 152/1772 [00:21<03:55,  6.88it/s, running training loss: 1.1486]\u001b[A\n",
      "Training:   9%|▊         | 152/1772 [00:22<03:55,  6.88it/s, running training loss: 0.9605]\u001b[A\n",
      "Training:   9%|▊         | 153/1772 [00:22<03:56,  6.83it/s, running training loss: 0.9605]\u001b[A\n",
      "Training:   9%|▊         | 153/1772 [00:22<03:56,  6.83it/s, running training loss: 1.0202]\u001b[A\n",
      "Training:   9%|▊         | 154/1772 [00:22<03:46,  7.14it/s, running training loss: 1.0202]\u001b[A\n",
      "Training:   9%|▊         | 154/1772 [00:22<03:46,  7.14it/s, running training loss: 0.8925]\u001b[A\n",
      "Training:   9%|▊         | 155/1772 [00:22<03:53,  6.93it/s, running training loss: 0.8925]\u001b[A\n",
      "Training:   9%|▊         | 155/1772 [00:22<03:53,  6.93it/s, running training loss: 1.0327]\u001b[A\n",
      "Training:   9%|▉         | 156/1772 [00:22<03:55,  6.85it/s, running training loss: 1.0327]\u001b[A\n",
      "Training:   9%|▉         | 156/1772 [00:22<03:55,  6.85it/s, running training loss: 0.8573]\u001b[A\n",
      "Training:   9%|▉         | 157/1772 [00:22<03:46,  7.14it/s, running training loss: 0.8573]\u001b[A\n",
      "Training:   9%|▉         | 157/1772 [00:22<03:46,  7.14it/s, running training loss: 0.9478]\u001b[A\n",
      "Training:   9%|▉         | 158/1772 [00:22<03:39,  7.35it/s, running training loss: 0.9478]\u001b[A\n",
      "Training:   9%|▉         | 158/1772 [00:22<03:39,  7.35it/s, running training loss: 0.7975]\u001b[A\n",
      "Training:   9%|▉         | 159/1772 [00:22<03:31,  7.63it/s, running training loss: 0.7975]\u001b[A\n",
      "Training:   9%|▉         | 159/1772 [00:22<03:31,  7.63it/s, running training loss: 1.2366]\u001b[A\n",
      "Training:   9%|▉         | 160/1772 [00:22<03:22,  7.96it/s, running training loss: 1.2366]\u001b[A\n",
      "Training:   9%|▉         | 160/1772 [00:23<03:22,  7.96it/s, running training loss: 0.8979]\u001b[A\n",
      "Training:   9%|▉         | 161/1772 [00:23<03:19,  8.08it/s, running training loss: 0.8979]\u001b[A\n",
      "Training:   9%|▉         | 161/1772 [00:23<03:19,  8.08it/s, running training loss: 0.7603]\u001b[A\n",
      "Training:   9%|▉         | 162/1772 [00:23<03:41,  7.26it/s, running training loss: 0.7603]\u001b[A\n",
      "Training:   9%|▉         | 162/1772 [00:23<03:41,  7.26it/s, running training loss: 0.7870]\u001b[A\n",
      "Training:   9%|▉         | 163/1772 [00:23<03:43,  7.20it/s, running training loss: 0.7870]\u001b[A\n",
      "Training:   9%|▉         | 163/1772 [00:23<03:43,  7.20it/s, running training loss: 1.0165]\u001b[A\n",
      "Training:   9%|▉         | 164/1772 [00:23<03:31,  7.59it/s, running training loss: 1.0165]\u001b[A\n",
      "Training:   9%|▉         | 164/1772 [00:23<03:31,  7.59it/s, running training loss: 0.8690]\u001b[A\n",
      "Training:   9%|▉         | 165/1772 [00:23<03:31,  7.61it/s, running training loss: 0.8690]\u001b[A\n",
      "Training:   9%|▉         | 165/1772 [00:23<03:31,  7.61it/s, running training loss: 0.9303]\u001b[A\n",
      "Training:   9%|▉         | 166/1772 [00:23<03:34,  7.49it/s, running training loss: 0.9303]\u001b[A\n",
      "Training:   9%|▉         | 166/1772 [00:23<03:34,  7.49it/s, running training loss: 0.8772]\u001b[A\n",
      "Training:   9%|▉         | 167/1772 [00:23<03:31,  7.60it/s, running training loss: 0.8772]\u001b[A\n",
      "Training:   9%|▉         | 167/1772 [00:24<03:31,  7.60it/s, running training loss: 0.8342]\u001b[A\n",
      "Training:   9%|▉         | 168/1772 [00:24<03:42,  7.20it/s, running training loss: 0.8342]\u001b[A\n",
      "Training:   9%|▉         | 168/1772 [00:24<03:42,  7.20it/s, running training loss: 0.9431]\u001b[A\n",
      "Training:  10%|▉         | 169/1772 [00:24<03:33,  7.52it/s, running training loss: 0.9431]\u001b[A\n",
      "Training:  10%|▉         | 169/1772 [00:24<03:33,  7.52it/s, running training loss: 0.9395]\u001b[A\n",
      "Training:  10%|▉         | 170/1772 [00:24<03:28,  7.67it/s, running training loss: 0.9395]\u001b[A\n",
      "Training:  10%|▉         | 170/1772 [00:24<03:28,  7.67it/s, running training loss: 0.9242]\u001b[A\n",
      "Training:  10%|▉         | 171/1772 [00:24<03:22,  7.90it/s, running training loss: 0.9242]\u001b[A\n",
      "Training:  10%|▉         | 171/1772 [00:24<03:22,  7.90it/s, running training loss: 1.1029]\u001b[A\n",
      "Training:  10%|▉         | 172/1772 [00:24<03:18,  8.06it/s, running training loss: 1.1029]\u001b[A\n",
      "Training:  10%|▉         | 172/1772 [00:24<03:18,  8.06it/s, running training loss: 1.0431]\u001b[A\n",
      "Training:  10%|▉         | 173/1772 [00:24<03:48,  6.99it/s, running training loss: 1.0431]\u001b[A\n",
      "Training:  10%|▉         | 173/1772 [00:24<03:48,  6.99it/s, running training loss: 1.1712]\u001b[A\n",
      "Training:  10%|▉         | 174/1772 [00:24<03:35,  7.40it/s, running training loss: 1.1712]\u001b[A\n",
      "Training:  10%|▉         | 174/1772 [00:24<03:35,  7.40it/s, running training loss: 1.0120]\u001b[A\n",
      "Training:  10%|▉         | 175/1772 [00:24<03:41,  7.21it/s, running training loss: 1.0120]\u001b[A\n",
      "Training:  10%|▉         | 175/1772 [00:25<03:41,  7.21it/s, running training loss: 1.0190]\u001b[A\n",
      "Training:  10%|▉         | 176/1772 [00:25<03:29,  7.62it/s, running training loss: 1.0190]\u001b[A\n",
      "Training:  10%|▉         | 176/1772 [00:25<03:29,  7.62it/s, running training loss: 0.8488]\u001b[A\n",
      "Training:  10%|▉         | 177/1772 [00:25<03:26,  7.72it/s, running training loss: 0.8488]\u001b[A\n",
      "Training:  10%|▉         | 177/1772 [00:25<03:26,  7.72it/s, running training loss: 1.0296]\u001b[A\n",
      "Training:  10%|█         | 178/1772 [00:25<03:23,  7.84it/s, running training loss: 1.0296]\u001b[A\n",
      "Training:  10%|█         | 178/1772 [00:25<03:23,  7.84it/s, running training loss: 0.9613]\u001b[A\n",
      "Training:  10%|█         | 179/1772 [00:25<03:23,  7.82it/s, running training loss: 0.9613]\u001b[A\n",
      "Training:  10%|█         | 179/1772 [00:25<03:23,  7.82it/s, running training loss: 1.0498]\u001b[A\n",
      "Training:  10%|█         | 180/1772 [00:25<03:29,  7.61it/s, running training loss: 1.0498]\u001b[A\n",
      "Training:  10%|█         | 180/1772 [00:25<03:29,  7.61it/s, running training loss: 0.9230]\u001b[A\n",
      "Training:  10%|█         | 181/1772 [00:25<03:28,  7.64it/s, running training loss: 0.9230]\u001b[A\n",
      "Training:  10%|█         | 181/1772 [00:25<03:28,  7.64it/s, running training loss: 1.2550]\u001b[A\n",
      "Training:  10%|█         | 182/1772 [00:25<03:19,  7.98it/s, running training loss: 1.2550]\u001b[A\n",
      "Training:  10%|█         | 182/1772 [00:25<03:19,  7.98it/s, running training loss: 0.9273]\u001b[A\n",
      "Training:  10%|█         | 183/1772 [00:25<03:21,  7.88it/s, running training loss: 0.9273]\u001b[A\n",
      "Training:  10%|█         | 183/1772 [00:26<03:21,  7.88it/s, running training loss: 1.0540]\u001b[A\n",
      "Training:  10%|█         | 184/1772 [00:26<03:37,  7.29it/s, running training loss: 1.0540]\u001b[A\n",
      "Training:  10%|█         | 184/1772 [00:26<03:37,  7.29it/s, running training loss: 0.9842]\u001b[A\n",
      "Training:  10%|█         | 185/1772 [00:26<03:32,  7.46it/s, running training loss: 0.9842]\u001b[A\n",
      "Training:  10%|█         | 185/1772 [00:26<03:32,  7.46it/s, running training loss: 1.1080]\u001b[A\n",
      "Training:  10%|█         | 186/1772 [00:26<03:56,  6.71it/s, running training loss: 1.1080]\u001b[A\n",
      "Training:  10%|█         | 186/1772 [00:26<03:56,  6.71it/s, running training loss: 1.0088]\u001b[A\n",
      "Training:  11%|█         | 187/1772 [00:26<03:54,  6.76it/s, running training loss: 1.0088]\u001b[A\n",
      "Training:  11%|█         | 187/1772 [00:26<03:54,  6.76it/s, running training loss: 1.0841]\u001b[A\n",
      "Training:  11%|█         | 188/1772 [00:26<03:48,  6.94it/s, running training loss: 1.0841]\u001b[A\n",
      "Training:  11%|█         | 188/1772 [00:26<03:48,  6.94it/s, running training loss: 0.9741]\u001b[A\n",
      "Training:  11%|█         | 189/1772 [00:26<03:41,  7.16it/s, running training loss: 0.9741]\u001b[A\n",
      "Training:  11%|█         | 189/1772 [00:26<03:41,  7.16it/s, running training loss: 1.0930]\u001b[A\n",
      "Training:  11%|█         | 190/1772 [00:26<03:34,  7.39it/s, running training loss: 1.0930]\u001b[A\n",
      "Training:  11%|█         | 190/1772 [00:27<03:34,  7.39it/s, running training loss: 1.0068]\u001b[A\n",
      "Training:  11%|█         | 191/1772 [00:27<03:35,  7.32it/s, running training loss: 1.0068]\u001b[A\n",
      "Training:  11%|█         | 191/1772 [00:27<03:35,  7.32it/s, running training loss: 1.0466]\u001b[A\n",
      "Training:  11%|█         | 192/1772 [00:27<03:31,  7.48it/s, running training loss: 1.0466]\u001b[A\n",
      "Training:  11%|█         | 192/1772 [00:27<03:31,  7.48it/s, running training loss: 1.0971]\u001b[A\n",
      "Training:  11%|█         | 193/1772 [00:27<03:39,  7.18it/s, running training loss: 1.0971]\u001b[A\n",
      "Training:  11%|█         | 193/1772 [00:27<03:39,  7.18it/s, running training loss: 0.9238]\u001b[A\n",
      "Training:  11%|█         | 194/1772 [00:27<03:40,  7.15it/s, running training loss: 0.9238]\u001b[A\n",
      "Training:  11%|█         | 194/1772 [00:27<03:40,  7.15it/s, running training loss: 0.9094]\u001b[A\n",
      "Training:  11%|█         | 195/1772 [00:27<03:29,  7.52it/s, running training loss: 0.9094]\u001b[A\n",
      "Training:  11%|█         | 195/1772 [00:27<03:29,  7.52it/s, running training loss: 0.7753]\u001b[A\n",
      "Training:  11%|█         | 196/1772 [00:27<03:25,  7.65it/s, running training loss: 0.7753]\u001b[A\n",
      "Training:  11%|█         | 196/1772 [00:27<03:25,  7.65it/s, running training loss: 0.7691]\u001b[A\n",
      "Training:  11%|█         | 197/1772 [00:27<03:30,  7.47it/s, running training loss: 0.7691]\u001b[A\n",
      "Training:  11%|█         | 197/1772 [00:28<03:30,  7.47it/s, running training loss: 0.7980]\u001b[A\n",
      "Training:  11%|█         | 198/1772 [00:28<03:30,  7.46it/s, running training loss: 0.7980]\u001b[A\n",
      "Training:  11%|█         | 198/1772 [00:28<03:30,  7.46it/s, running training loss: 0.9316]\u001b[A\n",
      "Training:  11%|█         | 199/1772 [00:28<03:25,  7.65it/s, running training loss: 0.9316]\u001b[A\n",
      "Training:  11%|█         | 199/1772 [00:28<03:25,  7.65it/s, running training loss: 1.0084]\u001b[A\n",
      "Training:  11%|█▏        | 200/1772 [00:28<03:28,  7.53it/s, running training loss: 1.0084]\u001b[A\n",
      "Training:  11%|█▏        | 200/1772 [00:28<03:28,  7.53it/s, running training loss: 0.9776]\u001b[A\n",
      "Training:  11%|█▏        | 201/1772 [00:28<03:25,  7.65it/s, running training loss: 0.9776]\u001b[A\n",
      "Training:  11%|█▏        | 201/1772 [00:28<03:25,  7.65it/s, running training loss: 1.0152]\u001b[A\n",
      "Training:  11%|█▏        | 202/1772 [00:28<03:22,  7.76it/s, running training loss: 1.0152]\u001b[A\n",
      "Training:  11%|█▏        | 202/1772 [00:28<03:22,  7.76it/s, running training loss: 0.9511]\u001b[A\n",
      "Training:  11%|█▏        | 203/1772 [00:28<03:28,  7.52it/s, running training loss: 0.9511]\u001b[A\n",
      "Training:  11%|█▏        | 203/1772 [00:28<03:28,  7.52it/s, running training loss: 1.0377]\u001b[A\n",
      "Training:  12%|█▏        | 204/1772 [00:28<03:23,  7.71it/s, running training loss: 1.0377]\u001b[A\n",
      "Training:  12%|█▏        | 204/1772 [00:28<03:23,  7.71it/s, running training loss: 1.1728]\u001b[A\n",
      "Training:  12%|█▏        | 205/1772 [00:28<03:26,  7.60it/s, running training loss: 1.1728]\u001b[A\n",
      "Training:  12%|█▏        | 205/1772 [00:29<03:26,  7.60it/s, running training loss: 0.8656]\u001b[A\n",
      "Training:  12%|█▏        | 206/1772 [00:29<03:16,  7.98it/s, running training loss: 0.8656]\u001b[A\n",
      "Training:  12%|█▏        | 206/1772 [00:29<03:16,  7.98it/s, running training loss: 1.0951]\u001b[A\n",
      "Training:  12%|█▏        | 207/1772 [00:29<03:18,  7.90it/s, running training loss: 1.0951]\u001b[A\n",
      "Training:  12%|█▏        | 207/1772 [00:29<03:18,  7.90it/s, running training loss: 1.0933]\u001b[A\n",
      "Training:  12%|█▏        | 208/1772 [00:29<03:12,  8.14it/s, running training loss: 1.0933]\u001b[A\n",
      "Training:  12%|█▏        | 208/1772 [00:29<03:12,  8.14it/s, running training loss: 0.7732]\u001b[A\n",
      "Training:  12%|█▏        | 209/1772 [00:29<03:14,  8.04it/s, running training loss: 0.7732]\u001b[A\n",
      "Training:  12%|█▏        | 209/1772 [00:29<03:14,  8.04it/s, running training loss: 0.8896]\u001b[A\n",
      "Training:  12%|█▏        | 210/1772 [00:29<03:12,  8.12it/s, running training loss: 0.8896]\u001b[A\n",
      "Training:  12%|█▏        | 210/1772 [00:29<03:12,  8.12it/s, running training loss: 0.8538]\u001b[A\n",
      "Training:  12%|█▏        | 211/1772 [00:29<03:19,  7.84it/s, running training loss: 0.8538]\u001b[A\n",
      "Training:  12%|█▏        | 211/1772 [00:29<03:19,  7.84it/s, running training loss: 1.0837]\u001b[A\n",
      "Training:  12%|█▏        | 212/1772 [00:29<03:34,  7.28it/s, running training loss: 1.0837]\u001b[A\n",
      "Training:  12%|█▏        | 212/1772 [00:30<03:34,  7.28it/s, running training loss: 0.9653]\u001b[A\n",
      "Training:  12%|█▏        | 213/1772 [00:30<03:40,  7.07it/s, running training loss: 0.9653]\u001b[A\n",
      "Training:  12%|█▏        | 213/1772 [00:30<03:40,  7.07it/s, running training loss: 0.7192]\u001b[A\n",
      "Training:  12%|█▏        | 214/1772 [00:30<03:53,  6.67it/s, running training loss: 0.7192]\u001b[A\n",
      "Training:  12%|█▏        | 214/1772 [00:30<03:53,  6.67it/s, running training loss: 0.8168]\u001b[A\n",
      "Training:  12%|█▏        | 215/1772 [00:30<03:40,  7.06it/s, running training loss: 0.8168]\u001b[A\n",
      "Training:  12%|█▏        | 215/1772 [00:30<03:40,  7.06it/s, running training loss: 0.8272]\u001b[A\n",
      "Training:  12%|█▏        | 216/1772 [00:30<03:33,  7.30it/s, running training loss: 0.8272]\u001b[A\n",
      "Training:  12%|█▏        | 216/1772 [00:30<03:33,  7.30it/s, running training loss: 0.7876]\u001b[A\n",
      "Training:  12%|█▏        | 217/1772 [00:30<03:25,  7.55it/s, running training loss: 0.7876]\u001b[A\n",
      "Training:  12%|█▏        | 217/1772 [00:30<03:25,  7.55it/s, running training loss: 1.0409]\u001b[A\n",
      "Training:  12%|█▏        | 218/1772 [00:30<03:20,  7.74it/s, running training loss: 1.0409]\u001b[A\n",
      "Training:  12%|█▏        | 218/1772 [00:30<03:20,  7.74it/s, running training loss: 1.0328]\u001b[A\n",
      "Training:  12%|█▏        | 219/1772 [00:30<03:16,  7.90it/s, running training loss: 1.0328]\u001b[A\n",
      "Training:  12%|█▏        | 219/1772 [00:30<03:16,  7.90it/s, running training loss: 0.8651]\u001b[A\n",
      "Training:  12%|█▏        | 220/1772 [00:30<03:14,  7.98it/s, running training loss: 0.8651]\u001b[A\n",
      "Training:  12%|█▏        | 220/1772 [00:31<03:14,  7.98it/s, running training loss: 0.8714]\u001b[A\n",
      "Training:  12%|█▏        | 221/1772 [00:31<03:23,  7.62it/s, running training loss: 0.8714]\u001b[A\n",
      "Training:  12%|█▏        | 221/1772 [00:31<03:23,  7.62it/s, running training loss: 1.0715]\u001b[A\n",
      "Training:  13%|█▎        | 222/1772 [00:31<03:23,  7.61it/s, running training loss: 1.0715]\u001b[A\n",
      "Training:  13%|█▎        | 222/1772 [00:31<03:23,  7.61it/s, running training loss: 0.8535]\u001b[A\n",
      "Training:  13%|█▎        | 223/1772 [00:31<03:17,  7.85it/s, running training loss: 0.8535]\u001b[A\n",
      "Training:  13%|█▎        | 223/1772 [00:31<03:17,  7.85it/s, running training loss: 0.8237]\u001b[A\n",
      "Training:  13%|█▎        | 224/1772 [00:31<03:27,  7.46it/s, running training loss: 0.8237]\u001b[A\n",
      "Training:  13%|█▎        | 224/1772 [00:31<03:27,  7.46it/s, running training loss: 0.9670]\u001b[A\n",
      "Training:  13%|█▎        | 225/1772 [00:31<03:36,  7.14it/s, running training loss: 0.9670]\u001b[A\n",
      "Training:  13%|█▎        | 225/1772 [00:31<03:36,  7.14it/s, running training loss: 1.0045]\u001b[A\n",
      "Training:  13%|█▎        | 226/1772 [00:31<03:30,  7.35it/s, running training loss: 1.0045]\u001b[A\n",
      "Training:  13%|█▎        | 226/1772 [00:31<03:30,  7.35it/s, running training loss: 0.9867]\u001b[A\n",
      "Training:  13%|█▎        | 227/1772 [00:31<03:29,  7.37it/s, running training loss: 0.9867]\u001b[A\n",
      "Training:  13%|█▎        | 227/1772 [00:32<03:29,  7.37it/s, running training loss: 1.1191]\u001b[A\n",
      "Training:  13%|█▎        | 228/1772 [00:32<03:42,  6.95it/s, running training loss: 1.1191]\u001b[A\n",
      "Training:  13%|█▎        | 228/1772 [00:32<03:42,  6.95it/s, running training loss: 1.0048]\u001b[A\n",
      "Training:  13%|█▎        | 229/1772 [00:32<03:46,  6.82it/s, running training loss: 1.0048]\u001b[A\n",
      "Training:  13%|█▎        | 229/1772 [00:32<03:46,  6.82it/s, running training loss: 1.0052]\u001b[A\n",
      "Training:  13%|█▎        | 230/1772 [00:32<03:31,  7.31it/s, running training loss: 1.0052]\u001b[A\n",
      "Training:  13%|█▎        | 230/1772 [00:32<03:31,  7.31it/s, running training loss: 0.8271]\u001b[A\n",
      "Training:  13%|█▎        | 231/1772 [00:32<03:20,  7.70it/s, running training loss: 0.8271]\u001b[A\n",
      "Training:  13%|█▎        | 231/1772 [00:32<03:20,  7.70it/s, running training loss: 0.8646]\u001b[A\n",
      "Training:  13%|█▎        | 232/1772 [00:32<03:24,  7.52it/s, running training loss: 0.8646]\u001b[A\n",
      "Training:  13%|█▎        | 232/1772 [00:32<03:24,  7.52it/s, running training loss: 0.9103]\u001b[A\n",
      "Training:  13%|█▎        | 233/1772 [00:32<03:15,  7.87it/s, running training loss: 0.9103]\u001b[A\n",
      "Training:  13%|█▎        | 233/1772 [00:32<03:15,  7.87it/s, running training loss: 1.0556]\u001b[A\n",
      "Training:  13%|█▎        | 234/1772 [00:32<03:48,  6.73it/s, running training loss: 1.0556]\u001b[A\n",
      "Training:  13%|█▎        | 234/1772 [00:33<03:48,  6.73it/s, running training loss: 0.8587]\u001b[A\n",
      "Training:  13%|█▎        | 235/1772 [00:33<03:43,  6.89it/s, running training loss: 0.8587]\u001b[A\n",
      "Training:  13%|█▎        | 235/1772 [00:33<03:43,  6.89it/s, running training loss: 0.9987]\u001b[A\n",
      "Training:  13%|█▎        | 236/1772 [00:33<03:35,  7.14it/s, running training loss: 0.9987]\u001b[A\n",
      "Training:  13%|█▎        | 236/1772 [00:33<03:35,  7.14it/s, running training loss: 1.0054]\u001b[A\n",
      "Training:  13%|█▎        | 237/1772 [00:33<03:29,  7.32it/s, running training loss: 1.0054]\u001b[A\n",
      "Training:  13%|█▎        | 237/1772 [00:33<03:29,  7.32it/s, running training loss: 0.9564]\u001b[A\n",
      "Training:  13%|█▎        | 238/1772 [00:33<03:36,  7.10it/s, running training loss: 0.9564]\u001b[A\n",
      "Training:  13%|█▎        | 238/1772 [00:33<03:36,  7.10it/s, running training loss: 0.9145]\u001b[A\n",
      "Training:  13%|█▎        | 239/1772 [00:33<03:57,  6.46it/s, running training loss: 0.9145]\u001b[A\n",
      "Training:  13%|█▎        | 239/1772 [00:33<03:57,  6.46it/s, running training loss: 0.8903]\u001b[A\n",
      "Training:  14%|█▎        | 240/1772 [00:33<03:47,  6.73it/s, running training loss: 0.8903]\u001b[A\n",
      "Training:  14%|█▎        | 240/1772 [00:33<03:47,  6.73it/s, running training loss: 0.8465]\u001b[A\n",
      "Training:  14%|█▎        | 241/1772 [00:33<03:43,  6.86it/s, running training loss: 0.8465]\u001b[A\n",
      "Training:  14%|█▎        | 241/1772 [00:34<03:43,  6.86it/s, running training loss: 0.7876]\u001b[A\n",
      "Training:  14%|█▎        | 242/1772 [00:34<03:41,  6.89it/s, running training loss: 0.7876]\u001b[A\n",
      "Training:  14%|█▎        | 242/1772 [00:34<03:41,  6.89it/s, running training loss: 0.7863]\u001b[A\n",
      "Training:  14%|█▎        | 243/1772 [00:34<03:28,  7.32it/s, running training loss: 0.7863]\u001b[A\n",
      "Training:  14%|█▎        | 243/1772 [00:34<03:28,  7.32it/s, running training loss: 0.7658]\u001b[A\n",
      "Training:  14%|█▍        | 244/1772 [00:34<03:32,  7.19it/s, running training loss: 0.7658]\u001b[A\n",
      "Training:  14%|█▍        | 244/1772 [00:34<03:32,  7.19it/s, running training loss: 0.7259]\u001b[A\n",
      "Training:  14%|█▍        | 245/1772 [00:34<03:35,  7.09it/s, running training loss: 0.7259]\u001b[A\n",
      "Training:  14%|█▍        | 245/1772 [00:34<03:35,  7.09it/s, running training loss: 0.7625]\u001b[A\n",
      "Training:  14%|█▍        | 246/1772 [00:34<03:28,  7.31it/s, running training loss: 0.7625]\u001b[A\n",
      "Training:  14%|█▍        | 246/1772 [00:34<03:28,  7.31it/s, running training loss: 0.7631]\u001b[A\n",
      "Training:  14%|█▍        | 247/1772 [00:34<03:18,  7.67it/s, running training loss: 0.7631]\u001b[A\n",
      "Training:  14%|█▍        | 247/1772 [00:34<03:18,  7.67it/s, running training loss: 0.7966]\u001b[A\n",
      "Training:  14%|█▍        | 248/1772 [00:34<03:17,  7.71it/s, running training loss: 0.7966]\u001b[A\n",
      "Training:  14%|█▍        | 248/1772 [00:34<03:17,  7.71it/s, running training loss: 0.7886]\u001b[A\n",
      "Training:  14%|█▍        | 249/1772 [00:34<03:33,  7.12it/s, running training loss: 0.7886]\u001b[A\n",
      "Training:  14%|█▍        | 249/1772 [00:35<03:33,  7.12it/s, running training loss: 0.8076]\u001b[A\n",
      "Training:  14%|█▍        | 250/1772 [00:35<03:25,  7.42it/s, running training loss: 0.8076]\u001b[A\n",
      "Training:  14%|█▍        | 250/1772 [00:35<03:25,  7.42it/s, running training loss: 0.9999]\u001b[A\n",
      "Training:  14%|█▍        | 251/1772 [00:35<03:19,  7.61it/s, running training loss: 0.9999]\u001b[A\n",
      "Training:  14%|█▍        | 251/1772 [00:35<03:19,  7.61it/s, running training loss: 1.0945]\u001b[A\n",
      "Training:  14%|█▍        | 252/1772 [00:35<03:12,  7.91it/s, running training loss: 1.0945]\u001b[A\n",
      "Training:  14%|█▍        | 252/1772 [00:35<03:12,  7.91it/s, running training loss: 1.0139]\u001b[A\n",
      "Training:  14%|█▍        | 253/1772 [00:35<03:10,  7.96it/s, running training loss: 1.0139]\u001b[A\n",
      "Training:  14%|█▍        | 253/1772 [00:35<03:10,  7.96it/s, running training loss: 0.8501]\u001b[A\n",
      "Training:  14%|█▍        | 254/1772 [00:35<03:07,  8.12it/s, running training loss: 0.8501]\u001b[A\n",
      "Training:  14%|█▍        | 254/1772 [00:35<03:07,  8.12it/s, running training loss: 1.1259]\u001b[A\n",
      "Training:  14%|█▍        | 255/1772 [00:35<03:11,  7.92it/s, running training loss: 1.1259]\u001b[A\n",
      "Training:  14%|█▍        | 255/1772 [00:35<03:11,  7.92it/s, running training loss: 1.0232]\u001b[A\n",
      "Training:  14%|█▍        | 256/1772 [00:35<03:17,  7.67it/s, running training loss: 1.0232]\u001b[A\n",
      "Training:  14%|█▍        | 256/1772 [00:35<03:17,  7.67it/s, running training loss: 1.2349]\u001b[A\n",
      "Training:  15%|█▍        | 257/1772 [00:35<03:15,  7.74it/s, running training loss: 1.2349]\u001b[A\n",
      "Training:  15%|█▍        | 257/1772 [00:36<03:15,  7.74it/s, running training loss: 0.8256]\u001b[A\n",
      "Training:  15%|█▍        | 258/1772 [00:36<03:44,  6.74it/s, running training loss: 0.8256]\u001b[A\n",
      "Training:  15%|█▍        | 258/1772 [00:36<03:44,  6.74it/s, running training loss: 0.8956]\u001b[A\n",
      "Training:  15%|█▍        | 259/1772 [00:36<03:25,  7.37it/s, running training loss: 0.8956]\u001b[A\n",
      "Training:  15%|█▍        | 259/1772 [00:36<03:25,  7.37it/s, running training loss: 0.7625]\u001b[A\n",
      "Training:  15%|█▍        | 260/1772 [00:36<03:15,  7.72it/s, running training loss: 0.7625]\u001b[A\n",
      "Training:  15%|█▍        | 260/1772 [00:36<03:15,  7.72it/s, running training loss: 0.7600]\u001b[A\n",
      "Training:  15%|█▍        | 261/1772 [00:36<03:17,  7.66it/s, running training loss: 0.7600]\u001b[A\n",
      "Training:  15%|█▍        | 261/1772 [00:36<03:17,  7.66it/s, running training loss: 0.7458]\u001b[A\n",
      "Training:  15%|█▍        | 262/1772 [00:36<03:19,  7.58it/s, running training loss: 0.7458]\u001b[A\n",
      "Training:  15%|█▍        | 262/1772 [00:36<03:19,  7.58it/s, running training loss: 0.7979]\u001b[A\n",
      "Training:  15%|█▍        | 263/1772 [00:36<03:04,  8.16it/s, running training loss: 0.7979]\u001b[A\n",
      "Training:  15%|█▍        | 263/1772 [00:36<03:04,  8.16it/s, running training loss: 0.7150]\u001b[A\n",
      "Training:  15%|█▍        | 264/1772 [00:36<03:10,  7.93it/s, running training loss: 0.7150]\u001b[A\n",
      "Training:  15%|█▍        | 264/1772 [00:36<03:10,  7.93it/s, running training loss: 0.9847]\u001b[A\n",
      "Training:  15%|█▍        | 265/1772 [00:36<03:01,  8.28it/s, running training loss: 0.9847]\u001b[A\n",
      "Training:  15%|█▍        | 265/1772 [00:37<03:01,  8.28it/s, running training loss: 0.8034]\u001b[A\n",
      "Training:  15%|█▌        | 266/1772 [00:37<03:08,  7.99it/s, running training loss: 0.8034]\u001b[A\n",
      "Training:  15%|█▌        | 266/1772 [00:37<03:08,  7.99it/s, running training loss: 0.9174]\u001b[A\n",
      "Training:  15%|█▌        | 267/1772 [00:37<03:14,  7.72it/s, running training loss: 0.9174]\u001b[A\n",
      "Training:  15%|█▌        | 267/1772 [00:37<03:14,  7.72it/s, running training loss: 0.9359]\u001b[A\n",
      "Training:  15%|█▌        | 268/1772 [00:37<03:39,  6.85it/s, running training loss: 0.9359]\u001b[A\n",
      "Training:  15%|█▌        | 268/1772 [00:37<03:39,  6.85it/s, running training loss: 0.8747]\u001b[A\n",
      "Training:  15%|█▌        | 269/1772 [00:37<03:43,  6.71it/s, running training loss: 0.8747]\u001b[A\n",
      "Training:  15%|█▌        | 269/1772 [00:37<03:43,  6.71it/s, running training loss: 0.8333]\u001b[A\n",
      "Training:  15%|█▌        | 270/1772 [00:37<03:32,  7.07it/s, running training loss: 0.8333]\u001b[A\n",
      "Training:  15%|█▌        | 270/1772 [00:37<03:32,  7.07it/s, running training loss: 0.9282]\u001b[A\n",
      "Training:  15%|█▌        | 271/1772 [00:37<03:19,  7.54it/s, running training loss: 0.9282]\u001b[A\n",
      "Training:  15%|█▌        | 271/1772 [00:37<03:19,  7.54it/s, running training loss: 0.7479]\u001b[A\n",
      "Training:  15%|█▌        | 272/1772 [00:37<03:21,  7.44it/s, running training loss: 0.7479]\u001b[A\n",
      "Training:  15%|█▌        | 272/1772 [00:38<03:21,  7.44it/s, running training loss: 0.9352]\u001b[A\n",
      "Training:  15%|█▌        | 273/1772 [00:38<03:20,  7.48it/s, running training loss: 0.9352]\u001b[A\n",
      "Training:  15%|█▌        | 273/1772 [00:38<03:20,  7.48it/s, running training loss: 0.7799]\u001b[A\n",
      "Training:  15%|█▌        | 274/1772 [00:38<03:22,  7.42it/s, running training loss: 0.7799]\u001b[A\n",
      "Training:  15%|█▌        | 274/1772 [00:38<03:22,  7.42it/s, running training loss: 0.9142]\u001b[A\n",
      "Training:  16%|█▌        | 275/1772 [00:38<03:17,  7.59it/s, running training loss: 0.9142]\u001b[A\n",
      "Training:  16%|█▌        | 275/1772 [00:38<03:17,  7.59it/s, running training loss: 0.7362]\u001b[A\n",
      "Training:  16%|█▌        | 276/1772 [00:38<03:24,  7.33it/s, running training loss: 0.7362]\u001b[A\n",
      "Training:  16%|█▌        | 276/1772 [00:38<03:24,  7.33it/s, running training loss: 0.9518]\u001b[A\n",
      "Training:  16%|█▌        | 277/1772 [00:38<03:14,  7.69it/s, running training loss: 0.9518]\u001b[A\n",
      "Training:  16%|█▌        | 277/1772 [00:38<03:14,  7.69it/s, running training loss: 0.7920]\u001b[A\n",
      "Training:  16%|█▌        | 278/1772 [00:38<03:09,  7.90it/s, running training loss: 0.7920]\u001b[A\n",
      "Training:  16%|█▌        | 278/1772 [00:38<03:09,  7.90it/s, running training loss: 0.8160]\u001b[A\n",
      "Training:  16%|█▌        | 279/1772 [00:38<03:01,  8.21it/s, running training loss: 0.8160]\u001b[A\n",
      "Training:  16%|█▌        | 279/1772 [00:38<03:01,  8.21it/s, running training loss: 0.8847]\u001b[A\n",
      "Training:  16%|█▌        | 280/1772 [00:38<03:08,  7.94it/s, running training loss: 0.8847]\u001b[A\n",
      "Training:  16%|█▌        | 280/1772 [00:39<03:08,  7.94it/s, running training loss: 1.0174]\u001b[A\n",
      "Training:  16%|█▌        | 281/1772 [00:39<03:06,  8.01it/s, running training loss: 1.0174]\u001b[A\n",
      "Training:  16%|█▌        | 281/1772 [00:39<03:06,  8.01it/s, running training loss: 1.0105]\u001b[A\n",
      "Training:  16%|█▌        | 282/1772 [00:39<03:07,  7.95it/s, running training loss: 1.0105]\u001b[A\n",
      "Training:  16%|█▌        | 282/1772 [00:39<03:07,  7.95it/s, running training loss: 1.0533]\u001b[A\n",
      "Training:  16%|█▌        | 283/1772 [00:39<03:15,  7.62it/s, running training loss: 1.0533]\u001b[A\n",
      "Training:  16%|█▌        | 283/1772 [00:39<03:15,  7.62it/s, running training loss: 0.9926]\u001b[A\n",
      "Training:  16%|█▌        | 284/1772 [00:39<03:25,  7.26it/s, running training loss: 0.9926]\u001b[A\n",
      "Training:  16%|█▌        | 284/1772 [00:39<03:25,  7.26it/s, running training loss: 0.9339]\u001b[A\n",
      "Training:  16%|█▌        | 285/1772 [00:39<03:20,  7.40it/s, running training loss: 0.9339]\u001b[A\n",
      "Training:  16%|█▌        | 285/1772 [00:39<03:20,  7.40it/s, running training loss: 0.7336]\u001b[A\n",
      "Training:  16%|█▌        | 286/1772 [00:39<03:16,  7.58it/s, running training loss: 0.7336]\u001b[A\n",
      "Training:  16%|█▌        | 286/1772 [00:39<03:16,  7.58it/s, running training loss: 0.8738]\u001b[A\n",
      "Training:  16%|█▌        | 287/1772 [00:39<03:10,  7.79it/s, running training loss: 0.8738]\u001b[A\n",
      "Training:  16%|█▌        | 287/1772 [00:40<03:10,  7.79it/s, running training loss: 0.7562]\u001b[A\n",
      "Training:  16%|█▋        | 288/1772 [00:40<03:10,  7.80it/s, running training loss: 0.7562]\u001b[A\n",
      "Training:  16%|█▋        | 288/1772 [00:40<03:10,  7.80it/s, running training loss: 0.9684]\u001b[A\n",
      "Training:  16%|█▋        | 289/1772 [00:40<03:21,  7.36it/s, running training loss: 0.9684]\u001b[A\n",
      "Training:  16%|█▋        | 289/1772 [00:40<03:21,  7.36it/s, running training loss: 0.9125]\u001b[A\n",
      "Training:  16%|█▋        | 290/1772 [00:40<03:36,  6.83it/s, running training loss: 0.9125]\u001b[A\n",
      "Training:  16%|█▋        | 290/1772 [00:40<03:36,  6.83it/s, running training loss: 0.9332]\u001b[A\n",
      "Training:  16%|█▋        | 291/1772 [00:40<03:42,  6.66it/s, running training loss: 0.9332]\u001b[A\n",
      "Training:  16%|█▋        | 291/1772 [00:40<03:42,  6.66it/s, running training loss: 0.9548]\u001b[A\n",
      "Training:  16%|█▋        | 292/1772 [00:40<03:30,  7.03it/s, running training loss: 0.9548]\u001b[A\n",
      "Training:  16%|█▋        | 292/1772 [00:40<03:30,  7.03it/s, running training loss: 1.0041]\u001b[A\n",
      "Training:  17%|█▋        | 293/1772 [00:40<03:17,  7.50it/s, running training loss: 1.0041]\u001b[A\n",
      "Training:  17%|█▋        | 293/1772 [00:40<03:17,  7.50it/s, running training loss: 0.8063]\u001b[A\n",
      "Training:  17%|█▋        | 294/1772 [00:40<03:21,  7.35it/s, running training loss: 0.8063]\u001b[A\n",
      "Training:  17%|█▋        | 294/1772 [00:41<03:21,  7.35it/s, running training loss: 1.0121]\u001b[A\n",
      "Training:  17%|█▋        | 295/1772 [00:41<03:25,  7.20it/s, running training loss: 1.0121]\u001b[A\n",
      "Training:  17%|█▋        | 295/1772 [00:41<03:25,  7.20it/s, running training loss: 0.8295]\u001b[A\n",
      "Training:  17%|█▋        | 296/1772 [00:41<03:28,  7.07it/s, running training loss: 0.8295]\u001b[A\n",
      "Training:  17%|█▋        | 296/1772 [00:41<03:28,  7.07it/s, running training loss: 0.8023]\u001b[A\n",
      "Training:  17%|█▋        | 297/1772 [00:41<03:18,  7.44it/s, running training loss: 0.8023]\u001b[A\n",
      "Training:  17%|█▋        | 297/1772 [00:41<03:18,  7.44it/s, running training loss: 0.7519]\u001b[A\n",
      "Training:  17%|█▋        | 298/1772 [00:41<03:25,  7.17it/s, running training loss: 0.7519]\u001b[A\n",
      "Training:  17%|█▋        | 298/1772 [00:41<03:25,  7.17it/s, running training loss: 0.9328]\u001b[A\n",
      "Training:  17%|█▋        | 299/1772 [00:41<03:26,  7.12it/s, running training loss: 0.9328]\u001b[A\n",
      "Training:  17%|█▋        | 299/1772 [00:41<03:26,  7.12it/s, running training loss: 0.9918]\u001b[A\n",
      "Training:  17%|█▋        | 300/1772 [00:41<03:19,  7.38it/s, running training loss: 0.9918]\u001b[A\n",
      "Training:  17%|█▋        | 300/1772 [00:41<03:19,  7.38it/s, running training loss: 1.1779]\u001b[A\n",
      "Training:  17%|█▋        | 301/1772 [00:41<03:49,  6.41it/s, running training loss: 1.1779]\u001b[A\n",
      "Training:  17%|█▋        | 301/1772 [00:42<03:49,  6.41it/s, running training loss: 0.9610]\u001b[A\n",
      "Training:  17%|█▋        | 302/1772 [00:42<03:57,  6.19it/s, running training loss: 0.9610]\u001b[A\n",
      "Training:  17%|█▋        | 302/1772 [00:42<03:57,  6.19it/s, running training loss: 1.0443]\u001b[A\n",
      "Training:  17%|█▋        | 303/1772 [00:42<03:42,  6.60it/s, running training loss: 1.0443]\u001b[A\n",
      "Training:  17%|█▋        | 303/1772 [00:42<03:42,  6.60it/s, running training loss: 1.0772]\u001b[A\n",
      "Training:  17%|█▋        | 304/1772 [00:42<03:42,  6.61it/s, running training loss: 1.0772]\u001b[A\n",
      "Training:  17%|█▋        | 304/1772 [00:42<03:42,  6.61it/s, running training loss: 0.8668]\u001b[A\n",
      "Training:  17%|█▋        | 305/1772 [00:42<03:40,  6.66it/s, running training loss: 0.8668]\u001b[A\n",
      "Training:  17%|█▋        | 305/1772 [00:42<03:40,  6.66it/s, running training loss: 0.9337]\u001b[A\n",
      "Training:  17%|█▋        | 306/1772 [00:42<03:27,  7.06it/s, running training loss: 0.9337]\u001b[A\n",
      "Training:  17%|█▋        | 306/1772 [00:42<03:27,  7.06it/s, running training loss: 0.7820]\u001b[A\n",
      "Training:  17%|█▋        | 307/1772 [00:42<03:17,  7.41it/s, running training loss: 0.7820]\u001b[A\n",
      "Training:  17%|█▋        | 307/1772 [00:42<03:17,  7.41it/s, running training loss: 1.1423]\u001b[A\n",
      "Training:  17%|█▋        | 308/1772 [00:42<03:21,  7.25it/s, running training loss: 1.1423]\u001b[A\n",
      "Training:  17%|█▋        | 308/1772 [00:43<03:21,  7.25it/s, running training loss: 1.0116]\u001b[A\n",
      "Training:  17%|█▋        | 309/1772 [00:43<03:16,  7.43it/s, running training loss: 1.0116]\u001b[A\n",
      "Training:  17%|█▋        | 309/1772 [00:43<03:16,  7.43it/s, running training loss: 0.9730]\u001b[A\n",
      "Training:  17%|█▋        | 310/1772 [00:43<03:47,  6.42it/s, running training loss: 0.9730]\u001b[A\n",
      "Training:  17%|█▋        | 310/1772 [00:43<03:47,  6.42it/s, running training loss: 0.9793]\u001b[A\n",
      "Training:  18%|█▊        | 311/1772 [00:43<03:31,  6.89it/s, running training loss: 0.9793]\u001b[A\n",
      "Training:  18%|█▊        | 311/1772 [00:43<03:31,  6.89it/s, running training loss: 0.9385]\u001b[A\n",
      "Training:  18%|█▊        | 312/1772 [00:43<03:25,  7.11it/s, running training loss: 0.9385]\u001b[A\n",
      "Training:  18%|█▊        | 312/1772 [00:43<03:25,  7.11it/s, running training loss: 1.1156]\u001b[A\n",
      "Training:  18%|█▊        | 313/1772 [00:43<03:37,  6.71it/s, running training loss: 1.1156]\u001b[A\n",
      "Training:  18%|█▊        | 313/1772 [00:43<03:37,  6.71it/s, running training loss: 1.0922]\u001b[A\n",
      "Training:  18%|█▊        | 314/1772 [00:43<03:32,  6.87it/s, running training loss: 1.0922]\u001b[A\n",
      "Training:  18%|█▊        | 314/1772 [00:43<03:32,  6.87it/s, running training loss: 0.7759]\u001b[A\n",
      "Training:  18%|█▊        | 315/1772 [00:43<03:21,  7.24it/s, running training loss: 0.7759]\u001b[A\n",
      "Training:  18%|█▊        | 315/1772 [00:44<03:21,  7.24it/s, running training loss: 0.8470]\u001b[A\n",
      "Training:  18%|█▊        | 316/1772 [00:44<03:16,  7.42it/s, running training loss: 0.8470]\u001b[A\n",
      "Training:  18%|█▊        | 316/1772 [00:44<03:16,  7.42it/s, running training loss: 0.8221]\u001b[A\n",
      "Training:  18%|█▊        | 317/1772 [00:44<03:12,  7.55it/s, running training loss: 0.8221]\u001b[A\n",
      "Training:  18%|█▊        | 317/1772 [00:44<03:12,  7.55it/s, running training loss: 0.8300]\u001b[A\n",
      "Training:  18%|█▊        | 318/1772 [00:44<03:11,  7.58it/s, running training loss: 0.8300]\u001b[A\n",
      "Training:  18%|█▊        | 318/1772 [00:44<03:11,  7.58it/s, running training loss: 0.9171]\u001b[A\n",
      "Training:  18%|█▊        | 319/1772 [00:44<03:18,  7.31it/s, running training loss: 0.9171]\u001b[A\n",
      "Training:  18%|█▊        | 319/1772 [00:44<03:18,  7.31it/s, running training loss: 1.0763]\u001b[A\n",
      "Training:  18%|█▊        | 320/1772 [00:44<03:15,  7.42it/s, running training loss: 1.0763]\u001b[A\n",
      "Training:  18%|█▊        | 320/1772 [00:44<03:15,  7.42it/s, running training loss: 0.9821]\u001b[A\n",
      "Training:  18%|█▊        | 321/1772 [00:44<03:16,  7.39it/s, running training loss: 0.9821]\u001b[A\n",
      "Training:  18%|█▊        | 321/1772 [00:44<03:16,  7.39it/s, running training loss: 0.9380]\u001b[A\n",
      "Training:  18%|█▊        | 322/1772 [00:44<03:12,  7.52it/s, running training loss: 0.9380]\u001b[A\n",
      "Training:  18%|█▊        | 322/1772 [00:44<03:12,  7.52it/s, running training loss: 0.9046]\u001b[A\n",
      "Training:  18%|█▊        | 323/1772 [00:44<03:11,  7.57it/s, running training loss: 0.9046]\u001b[A\n",
      "Training:  18%|█▊        | 323/1772 [00:45<03:11,  7.57it/s, running training loss: 1.0052]\u001b[A\n",
      "Training:  18%|█▊        | 324/1772 [00:45<03:07,  7.74it/s, running training loss: 1.0052]\u001b[A\n",
      "Training:  18%|█▊        | 324/1772 [00:45<03:07,  7.74it/s, running training loss: 1.1619]\u001b[A\n",
      "Training:  18%|█▊        | 325/1772 [00:45<03:33,  6.78it/s, running training loss: 1.1619]\u001b[A\n",
      "Training:  18%|█▊        | 325/1772 [00:45<03:33,  6.78it/s, running training loss: 1.0523]\u001b[A\n",
      "Training:  18%|█▊        | 326/1772 [00:45<03:22,  7.13it/s, running training loss: 1.0523]\u001b[A\n",
      "Training:  18%|█▊        | 326/1772 [00:45<03:22,  7.13it/s, running training loss: 1.0475]\u001b[A\n",
      "Training:  18%|█▊        | 327/1772 [00:45<03:22,  7.12it/s, running training loss: 1.0475]\u001b[A\n",
      "Training:  18%|█▊        | 327/1772 [00:45<03:22,  7.12it/s, running training loss: 0.9684]\u001b[A\n",
      "Training:  19%|█▊        | 328/1772 [00:45<03:27,  6.97it/s, running training loss: 0.9684]\u001b[A\n",
      "Training:  19%|█▊        | 328/1772 [00:45<03:27,  6.97it/s, running training loss: 0.8815]\u001b[A\n",
      "Training:  19%|█▊        | 329/1772 [00:45<03:30,  6.87it/s, running training loss: 0.8815]\u001b[A\n",
      "Training:  19%|█▊        | 329/1772 [00:46<03:30,  6.87it/s, running training loss: 0.9705]\u001b[A\n",
      "Training:  19%|█▊        | 330/1772 [00:46<03:36,  6.66it/s, running training loss: 0.9705]\u001b[A\n",
      "Training:  19%|█▊        | 330/1772 [00:46<03:36,  6.66it/s, running training loss: 0.8217]\u001b[A\n",
      "Training:  19%|█▊        | 331/1772 [00:46<03:25,  7.01it/s, running training loss: 0.8217]\u001b[A\n",
      "Training:  19%|█▊        | 331/1772 [00:46<03:25,  7.01it/s, running training loss: 0.7666]\u001b[A\n",
      "Training:  19%|█▊        | 332/1772 [00:46<03:22,  7.10it/s, running training loss: 0.7666]\u001b[A\n",
      "Training:  19%|█▊        | 332/1772 [00:46<03:22,  7.10it/s, running training loss: 0.8048]\u001b[A\n",
      "Training:  19%|█▉        | 333/1772 [00:46<03:12,  7.47it/s, running training loss: 0.8048]\u001b[A\n",
      "Training:  19%|█▉        | 333/1772 [00:46<03:12,  7.47it/s, running training loss: 0.9631]\u001b[A\n",
      "Training:  19%|█▉        | 334/1772 [00:46<03:09,  7.57it/s, running training loss: 0.9631]\u001b[A\n",
      "Training:  19%|█▉        | 334/1772 [00:46<03:09,  7.57it/s, running training loss: 0.9266]\u001b[A\n",
      "Training:  19%|█▉        | 335/1772 [00:46<03:14,  7.41it/s, running training loss: 0.9266]\u001b[A\n",
      "Training:  19%|█▉        | 335/1772 [00:46<03:14,  7.41it/s, running training loss: 1.0903]\u001b[A\n",
      "Training:  19%|█▉        | 336/1772 [00:46<03:08,  7.64it/s, running training loss: 1.0903]\u001b[A\n",
      "Training:  19%|█▉        | 336/1772 [00:46<03:08,  7.64it/s, running training loss: 0.9649]\u001b[A\n",
      "Training:  19%|█▉        | 337/1772 [00:46<03:06,  7.71it/s, running training loss: 0.9649]\u001b[A\n",
      "Training:  19%|█▉        | 337/1772 [00:47<03:06,  7.71it/s, running training loss: 0.9747]\u001b[A\n",
      "Training:  19%|█▉        | 338/1772 [00:47<03:24,  7.01it/s, running training loss: 0.9747]\u001b[A\n",
      "Training:  19%|█▉        | 338/1772 [00:47<03:24,  7.01it/s, running training loss: 1.0064]\u001b[A\n",
      "Training:  19%|█▉        | 339/1772 [00:47<03:20,  7.16it/s, running training loss: 1.0064]\u001b[A\n",
      "Training:  19%|█▉        | 339/1772 [00:47<03:20,  7.16it/s, running training loss: 0.9305]\u001b[A\n",
      "Training:  19%|█▉        | 340/1772 [00:47<03:10,  7.50it/s, running training loss: 0.9305]\u001b[A\n",
      "Training:  19%|█▉        | 340/1772 [00:47<03:10,  7.50it/s, running training loss: 0.9084]\u001b[A\n",
      "Training:  19%|█▉        | 341/1772 [00:47<03:08,  7.61it/s, running training loss: 0.9084]\u001b[A\n",
      "Training:  19%|█▉        | 341/1772 [00:47<03:08,  7.61it/s, running training loss: 0.9506]\u001b[A\n",
      "Training:  19%|█▉        | 342/1772 [00:47<03:09,  7.56it/s, running training loss: 0.9506]\u001b[A\n",
      "Training:  19%|█▉        | 342/1772 [00:47<03:09,  7.56it/s, running training loss: 0.9456]\u001b[A\n",
      "Training:  19%|█▉        | 343/1772 [00:47<03:00,  7.90it/s, running training loss: 0.9456]\u001b[A\n",
      "Training:  19%|█▉        | 343/1772 [00:47<03:00,  7.90it/s, running training loss: 1.0499]\u001b[A\n",
      "Training:  19%|█▉        | 344/1772 [00:47<03:10,  7.49it/s, running training loss: 1.0499]\u001b[A\n",
      "Training:  19%|█▉        | 344/1772 [00:48<03:10,  7.49it/s, running training loss: 0.8555]\u001b[A\n",
      "Training:  19%|█▉        | 345/1772 [00:48<03:07,  7.60it/s, running training loss: 0.8555]\u001b[A\n",
      "Training:  19%|█▉        | 345/1772 [00:48<03:07,  7.60it/s, running training loss: 1.0822]\u001b[A\n",
      "Training:  20%|█▉        | 346/1772 [00:48<03:07,  7.60it/s, running training loss: 1.0822]\u001b[A\n",
      "Training:  20%|█▉        | 346/1772 [00:48<03:07,  7.60it/s, running training loss: 0.9400]\u001b[A\n",
      "Training:  20%|█▉        | 347/1772 [00:48<03:07,  7.62it/s, running training loss: 0.9400]\u001b[A\n",
      "Training:  20%|█▉        | 347/1772 [00:48<03:07,  7.62it/s, running training loss: 0.8185]\u001b[A\n",
      "Training:  20%|█▉        | 348/1772 [00:48<03:02,  7.79it/s, running training loss: 0.8185]\u001b[A\n",
      "Training:  20%|█▉        | 348/1772 [00:48<03:02,  7.79it/s, running training loss: 0.8613]\u001b[A\n",
      "Training:  20%|█▉        | 349/1772 [00:48<03:08,  7.53it/s, running training loss: 0.8613]\u001b[A\n",
      "Training:  20%|█▉        | 349/1772 [00:48<03:08,  7.53it/s, running training loss: 0.8856]\u001b[A\n",
      "Training:  20%|█▉        | 350/1772 [00:48<03:09,  7.52it/s, running training loss: 0.8856]\u001b[A\n",
      "Training:  20%|█▉        | 350/1772 [00:48<03:09,  7.52it/s, running training loss: 0.8892]\u001b[A\n",
      "Training:  20%|█▉        | 351/1772 [00:48<03:07,  7.56it/s, running training loss: 0.8892]\u001b[A\n",
      "Training:  20%|█▉        | 351/1772 [00:48<03:07,  7.56it/s, running training loss: 0.9080]\u001b[A\n",
      "Training:  20%|█▉        | 352/1772 [00:48<03:20,  7.08it/s, running training loss: 0.9080]\u001b[A\n",
      "Training:  20%|█▉        | 352/1772 [00:49<03:20,  7.08it/s, running training loss: 1.0883]\u001b[A\n",
      "Training:  20%|█▉        | 353/1772 [00:49<03:40,  6.44it/s, running training loss: 1.0883]\u001b[A\n",
      "Training:  20%|█▉        | 353/1772 [00:49<03:40,  6.44it/s, running training loss: 0.9619]\u001b[A\n",
      "Training:  20%|█▉        | 354/1772 [00:49<03:34,  6.61it/s, running training loss: 0.9619]\u001b[A\n",
      "Training:  20%|█▉        | 354/1772 [00:49<03:34,  6.61it/s, running training loss: 0.9820]\u001b[A\n",
      "Training:  20%|██        | 355/1772 [00:49<03:45,  6.27it/s, running training loss: 0.9820]\u001b[A\n",
      "Training:  20%|██        | 355/1772 [00:49<03:45,  6.27it/s, running training loss: 1.0812]\u001b[A\n",
      "Training:  20%|██        | 356/1772 [00:49<03:31,  6.70it/s, running training loss: 1.0812]\u001b[A\n",
      "Training:  20%|██        | 356/1772 [00:49<03:31,  6.70it/s, running training loss: 1.0635]\u001b[A\n",
      "Training:  20%|██        | 357/1772 [00:49<03:15,  7.23it/s, running training loss: 1.0635]\u001b[A\n",
      "Training:  20%|██        | 357/1772 [00:49<03:15,  7.23it/s, running training loss: 1.0606]\u001b[A\n",
      "Training:  20%|██        | 358/1772 [00:49<03:09,  7.45it/s, running training loss: 1.0606]\u001b[A\n",
      "Training:  20%|██        | 358/1772 [00:49<03:09,  7.45it/s, running training loss: 0.9473]\u001b[A\n",
      "Training:  20%|██        | 359/1772 [00:49<03:00,  7.81it/s, running training loss: 0.9473]\u001b[A\n",
      "Training:  20%|██        | 359/1772 [00:50<03:00,  7.81it/s, running training loss: 1.0320]\u001b[A\n",
      "Training:  20%|██        | 360/1772 [00:50<03:07,  7.53it/s, running training loss: 1.0320]\u001b[A\n",
      "Training:  20%|██        | 360/1772 [00:50<03:07,  7.53it/s, running training loss: 1.0176]\u001b[A\n",
      "Training:  20%|██        | 361/1772 [00:50<03:17,  7.15it/s, running training loss: 1.0176]\u001b[A\n",
      "Training:  20%|██        | 361/1772 [00:50<03:17,  7.15it/s, running training loss: 1.0126]\u001b[A\n",
      "Training:  20%|██        | 362/1772 [00:50<03:11,  7.38it/s, running training loss: 1.0126]\u001b[A\n",
      "Training:  20%|██        | 362/1772 [00:50<03:11,  7.38it/s, running training loss: 0.9245]\u001b[A\n",
      "Training:  20%|██        | 363/1772 [00:50<03:03,  7.68it/s, running training loss: 0.9245]\u001b[A\n",
      "Training:  20%|██        | 363/1772 [00:50<03:03,  7.68it/s, running training loss: 1.0113]\u001b[A\n",
      "Training:  21%|██        | 364/1772 [00:50<03:04,  7.65it/s, running training loss: 1.0113]\u001b[A\n",
      "Training:  21%|██        | 364/1772 [00:50<03:04,  7.65it/s, running training loss: 1.3177]\u001b[A\n",
      "Training:  21%|██        | 365/1772 [00:50<02:56,  7.96it/s, running training loss: 1.3177]\u001b[A\n",
      "Training:  21%|██        | 365/1772 [00:50<02:56,  7.96it/s, running training loss: 0.9647]\u001b[A\n",
      "Training:  21%|██        | 366/1772 [00:50<02:55,  8.01it/s, running training loss: 0.9647]\u001b[A\n",
      "Training:  21%|██        | 366/1772 [00:50<02:55,  8.01it/s, running training loss: 0.9521]\u001b[A\n",
      "Training:  21%|██        | 367/1772 [00:50<02:53,  8.08it/s, running training loss: 0.9521]\u001b[A\n",
      "Training:  21%|██        | 367/1772 [00:51<02:53,  8.08it/s, running training loss: 1.0530]\u001b[A\n",
      "Training:  21%|██        | 368/1772 [00:51<02:53,  8.11it/s, running training loss: 1.0530]\u001b[A\n",
      "Training:  21%|██        | 368/1772 [00:51<02:53,  8.11it/s, running training loss: 0.9636]\u001b[A\n",
      "Training:  21%|██        | 369/1772 [00:51<02:51,  8.19it/s, running training loss: 0.9636]\u001b[A\n",
      "Training:  21%|██        | 369/1772 [00:51<02:51,  8.19it/s, running training loss: 1.0009]\u001b[A\n",
      "Training:  21%|██        | 370/1772 [00:51<03:06,  7.53it/s, running training loss: 1.0009]\u001b[A\n",
      "Training:  21%|██        | 370/1772 [00:51<03:06,  7.53it/s, running training loss: 0.9676]\u001b[A\n",
      "Training:  21%|██        | 371/1772 [00:51<03:02,  7.68it/s, running training loss: 0.9676]\u001b[A\n",
      "Training:  21%|██        | 371/1772 [00:51<03:02,  7.68it/s, running training loss: 0.7591]\u001b[A\n",
      "Training:  21%|██        | 372/1772 [00:51<03:00,  7.77it/s, running training loss: 0.7591]\u001b[A\n",
      "Training:  21%|██        | 372/1772 [00:51<03:00,  7.77it/s, running training loss: 0.7407]\u001b[A\n",
      "Training:  21%|██        | 373/1772 [00:51<02:55,  7.99it/s, running training loss: 0.7407]\u001b[A\n",
      "Training:  21%|██        | 373/1772 [00:51<02:55,  7.99it/s, running training loss: 0.7751]\u001b[A\n",
      "Training:  21%|██        | 374/1772 [00:51<02:54,  8.00it/s, running training loss: 0.7751]\u001b[A\n",
      "Training:  21%|██        | 374/1772 [00:52<02:54,  8.00it/s, running training loss: 0.9269]\u001b[A\n",
      "Training:  21%|██        | 375/1772 [00:52<03:09,  7.39it/s, running training loss: 0.9269]\u001b[A\n",
      "Training:  21%|██        | 375/1772 [00:52<03:09,  7.39it/s, running training loss: 0.8335]\u001b[A\n",
      "Training:  21%|██        | 376/1772 [00:52<03:03,  7.61it/s, running training loss: 0.8335]\u001b[A\n",
      "Training:  21%|██        | 376/1772 [00:52<03:03,  7.61it/s, running training loss: 0.9202]\u001b[A\n",
      "Training:  21%|██▏       | 377/1772 [00:52<02:55,  7.97it/s, running training loss: 0.9202]\u001b[A\n",
      "Training:  21%|██▏       | 377/1772 [00:52<02:55,  7.97it/s, running training loss: 1.0304]\u001b[A\n",
      "Training:  21%|██▏       | 378/1772 [00:52<03:14,  7.16it/s, running training loss: 1.0304]\u001b[A\n",
      "Training:  21%|██▏       | 378/1772 [00:52<03:14,  7.16it/s, running training loss: 1.0977]\u001b[A\n",
      "Training:  21%|██▏       | 379/1772 [00:52<03:04,  7.57it/s, running training loss: 1.0977]\u001b[A\n",
      "Training:  21%|██▏       | 379/1772 [00:52<03:04,  7.57it/s, running training loss: 0.9733]\u001b[A\n",
      "Training:  21%|██▏       | 380/1772 [00:52<03:18,  7.01it/s, running training loss: 0.9733]\u001b[A\n",
      "Training:  21%|██▏       | 380/1772 [00:52<03:18,  7.01it/s, running training loss: 0.9841]\u001b[A\n",
      "Training:  22%|██▏       | 381/1772 [00:52<03:03,  7.59it/s, running training loss: 0.9841]\u001b[A\n",
      "Training:  22%|██▏       | 381/1772 [00:52<03:03,  7.59it/s, running training loss: 0.9629]\u001b[A\n",
      "Training:  22%|██▏       | 382/1772 [00:52<03:03,  7.57it/s, running training loss: 0.9629]\u001b[A\n",
      "Training:  22%|██▏       | 382/1772 [00:53<03:03,  7.57it/s, running training loss: 0.9424]\u001b[A\n",
      "Training:  22%|██▏       | 383/1772 [00:53<03:00,  7.70it/s, running training loss: 0.9424]\u001b[A\n",
      "Training:  22%|██▏       | 383/1772 [00:53<03:00,  7.70it/s, running training loss: 0.8719]\u001b[A\n",
      "Training:  22%|██▏       | 384/1772 [00:53<02:56,  7.88it/s, running training loss: 0.8719]\u001b[A\n",
      "Training:  22%|██▏       | 384/1772 [00:53<02:56,  7.88it/s, running training loss: 0.9996]\u001b[A\n",
      "Training:  22%|██▏       | 385/1772 [00:53<03:01,  7.66it/s, running training loss: 0.9996]\u001b[A\n",
      "Training:  22%|██▏       | 385/1772 [00:53<03:01,  7.66it/s, running training loss: 0.9461]\u001b[A\n",
      "Training:  22%|██▏       | 386/1772 [00:53<02:58,  7.75it/s, running training loss: 0.9461]\u001b[A\n",
      "Training:  22%|██▏       | 386/1772 [00:53<02:58,  7.75it/s, running training loss: 1.1522]\u001b[A\n",
      "Training:  22%|██▏       | 387/1772 [00:53<02:54,  7.92it/s, running training loss: 1.1522]\u001b[A\n",
      "Training:  22%|██▏       | 387/1772 [00:53<02:54,  7.92it/s, running training loss: 0.9770]\u001b[A\n",
      "Training:  22%|██▏       | 388/1772 [00:53<02:50,  8.14it/s, running training loss: 0.9770]\u001b[A\n",
      "Training:  22%|██▏       | 388/1772 [00:53<02:50,  8.14it/s, running training loss: 0.9893]\u001b[A\n",
      "Training:  22%|██▏       | 389/1772 [00:53<02:53,  7.97it/s, running training loss: 0.9893]\u001b[A\n",
      "Training:  22%|██▏       | 389/1772 [00:53<02:53,  7.97it/s, running training loss: 0.9750]\u001b[A\n",
      "Training:  22%|██▏       | 390/1772 [00:53<02:52,  7.99it/s, running training loss: 0.9750]\u001b[A\n",
      "Training:  22%|██▏       | 390/1772 [00:54<02:52,  7.99it/s, running training loss: 0.8105]\u001b[A\n",
      "Training:  22%|██▏       | 391/1772 [00:54<02:52,  8.00it/s, running training loss: 0.8105]\u001b[A\n",
      "Training:  22%|██▏       | 391/1772 [00:54<02:52,  8.00it/s, running training loss: 0.9768]\u001b[A\n",
      "Training:  22%|██▏       | 392/1772 [00:54<02:46,  8.29it/s, running training loss: 0.9768]\u001b[A\n",
      "Training:  22%|██▏       | 392/1772 [00:54<02:46,  8.29it/s, running training loss: 0.9510]\u001b[A\n",
      "Training:  22%|██▏       | 393/1772 [00:54<03:00,  7.66it/s, running training loss: 0.9510]\u001b[A\n",
      "Training:  22%|██▏       | 393/1772 [00:54<03:00,  7.66it/s, running training loss: 1.0011]\u001b[A\n",
      "Training:  22%|██▏       | 394/1772 [00:54<02:54,  7.87it/s, running training loss: 1.0011]\u001b[A\n",
      "Training:  22%|██▏       | 394/1772 [00:54<02:54,  7.87it/s, running training loss: 0.9210]\u001b[A\n",
      "Training:  22%|██▏       | 395/1772 [00:54<02:58,  7.70it/s, running training loss: 0.9210]\u001b[A\n",
      "Training:  22%|██▏       | 395/1772 [00:54<02:58,  7.70it/s, running training loss: 1.1898]\u001b[A\n",
      "Training:  22%|██▏       | 396/1772 [00:54<03:02,  7.55it/s, running training loss: 1.1898]\u001b[A\n",
      "Training:  22%|██▏       | 396/1772 [00:54<03:02,  7.55it/s, running training loss: 0.9878]\u001b[A\n",
      "Training:  22%|██▏       | 397/1772 [00:54<02:57,  7.77it/s, running training loss: 0.9878]\u001b[A\n",
      "Training:  22%|██▏       | 397/1772 [00:54<02:57,  7.77it/s, running training loss: 1.0824]\u001b[A\n",
      "Training:  22%|██▏       | 398/1772 [00:54<02:55,  7.81it/s, running training loss: 1.0824]\u001b[A\n",
      "Training:  22%|██▏       | 398/1772 [00:55<02:55,  7.81it/s, running training loss: 1.1681]\u001b[A\n",
      "Training:  23%|██▎       | 399/1772 [00:55<02:54,  7.85it/s, running training loss: 1.1681]\u001b[A\n",
      "Training:  23%|██▎       | 399/1772 [00:55<02:54,  7.85it/s, running training loss: 1.1181]\u001b[A\n",
      "\n",
      "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   0%|          | 1/270 [00:00<02:43,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   3%|▎         | 7/270 [00:00<01:53,  2.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   5%|▍         | 13/270 [00:00<01:18,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   7%|▋         | 19/270 [00:00<00:55,  4.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   9%|▉         | 25/270 [00:01<00:38,  6.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  11%|█▏        | 31/270 [00:01<00:27,  8.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  14%|█▎        | 37/270 [00:01<00:20, 11.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  16%|█▌        | 43/270 [00:01<00:15, 15.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  18%|█▊        | 49/270 [00:01<00:11, 19.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  20%|██        | 55/270 [00:01<00:08, 24.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  23%|██▎       | 61/270 [00:01<00:07, 29.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  25%|██▍       | 67/270 [00:01<00:05, 34.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  27%|██▋       | 74/270 [00:01<00:04, 39.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  30%|██▉       | 80/270 [00:01<00:04, 43.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  32%|███▏      | 86/270 [00:02<00:03, 46.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  34%|███▍      | 92/270 [00:02<00:03, 48.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  37%|███▋      | 99/270 [00:02<00:03, 52.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  39%|███▉      | 105/270 [00:02<00:03, 53.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  41%|████      | 111/270 [00:02<00:02, 55.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  43%|████▎     | 117/270 [00:02<00:02, 56.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  46%|████▌     | 124/270 [00:02<00:02, 57.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  48%|████▊     | 130/270 [00:02<00:02, 53.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  50%|█████     | 136/270 [00:02<00:02, 54.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  53%|█████▎    | 142/270 [00:03<00:02, 55.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  55%|█████▍    | 148/270 [00:03<00:02, 56.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  57%|█████▋    | 154/270 [00:03<00:02, 55.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  59%|█████▉    | 160/270 [00:03<00:01, 56.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  61%|██████▏   | 166/270 [00:03<00:01, 56.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  64%|██████▎   | 172/270 [00:03<00:01, 57.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  66%|██████▌   | 178/270 [00:03<00:01, 55.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  68%|██████▊   | 184/270 [00:03<00:01, 54.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  70%|███████   | 190/270 [00:03<00:01, 55.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  73%|███████▎  | 196/270 [00:04<00:01, 55.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  75%|███████▍  | 202/270 [00:04<00:01, 54.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  77%|███████▋  | 208/270 [00:04<00:01, 55.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  79%|███████▉  | 214/270 [00:04<00:01, 55.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  82%|████████▏ | 221/270 [00:04<00:00, 57.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  84%|████████▍ | 228/270 [00:04<00:00, 57.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  87%|████████▋ | 234/270 [00:04<00:00, 57.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  89%|████████▉ | 240/270 [00:04<00:00, 57.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  91%|█████████ | 246/270 [00:04<00:00, 56.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  93%|█████████▎| 252/270 [00:05<00:00, 54.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  96%|█████████▌| 258/270 [00:05<00:00, 54.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  98%|█████████▊| 264/270 [00:05<00:00, 54.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation: 100%|██████████| 270/270 [00:05<00:00, 48.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Training:  23%|██▎       | 400/1772 [01:01<44:58,  1.97s/it, running training loss: 1.1181]\u001b[A\n",
      "Training:  23%|██▎       | 400/1772 [01:01<44:58,  1.97s/it, running training loss: 1.2731]\u001b[A\n",
      "Training:  23%|██▎       | 401/1772 [01:01<32:24,  1.42s/it, running training loss: 1.2731]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> training loss: 0.972990, valid loss: 0.644075, valid f1: 0.368159, valid acc: 0.646895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  23%|██▎       | 401/1772 [01:01<32:24,  1.42s/it, running training loss: 1.0375]\u001b[A\n",
      "Training:  23%|██▎       | 402/1772 [01:01<23:31,  1.03s/it, running training loss: 1.0375]\u001b[A\n",
      "Training:  23%|██▎       | 402/1772 [01:01<23:31,  1.03s/it, running training loss: 0.8650]\u001b[A\n",
      "Training:  23%|██▎       | 403/1772 [01:01<17:22,  1.31it/s, running training loss: 0.8650]\u001b[A\n",
      "Training:  23%|██▎       | 403/1772 [01:01<17:22,  1.31it/s, running training loss: 0.9297]\u001b[A\n",
      "Training:  23%|██▎       | 404/1772 [01:01<13:01,  1.75it/s, running training loss: 0.9297]\u001b[A\n",
      "Training:  23%|██▎       | 404/1772 [01:02<13:01,  1.75it/s, running training loss: 0.7594]\u001b[A\n",
      "Training:  23%|██▎       | 405/1772 [01:02<09:55,  2.29it/s, running training loss: 0.7594]\u001b[A\n",
      "Training:  23%|██▎       | 405/1772 [01:02<09:55,  2.29it/s, running training loss: 1.0619]\u001b[A\n",
      "Training:  23%|██▎       | 406/1772 [01:02<07:46,  2.93it/s, running training loss: 1.0619]\u001b[A\n",
      "Training:  23%|██▎       | 406/1772 [01:02<07:46,  2.93it/s, running training loss: 0.9061]\u001b[A\n",
      "Training:  23%|██▎       | 407/1772 [01:02<06:35,  3.45it/s, running training loss: 0.9061]\u001b[A\n",
      "Training:  23%|██▎       | 407/1772 [01:02<06:35,  3.45it/s, running training loss: 0.9823]\u001b[A\n",
      "Training:  23%|██▎       | 408/1772 [01:02<05:42,  3.98it/s, running training loss: 0.9823]\u001b[A\n",
      "Training:  23%|██▎       | 408/1772 [01:02<05:42,  3.98it/s, running training loss: 0.9033]\u001b[A\n",
      "Training:  23%|██▎       | 409/1772 [01:02<04:47,  4.74it/s, running training loss: 0.9033]\u001b[A\n",
      "Training:  23%|██▎       | 409/1772 [01:02<04:47,  4.74it/s, running training loss: 1.1552]\u001b[A\n",
      "Training:  23%|██▎       | 410/1772 [01:02<04:42,  4.82it/s, running training loss: 1.1552]\u001b[A\n",
      "Training:  23%|██▎       | 410/1772 [01:02<04:42,  4.82it/s, running training loss: 1.0465]\u001b[A\n",
      "Training:  23%|██▎       | 411/1772 [01:02<04:09,  5.47it/s, running training loss: 1.0465]\u001b[A\n",
      "Training:  23%|██▎       | 411/1772 [01:03<04:09,  5.47it/s, running training loss: 0.9576]\u001b[A\n",
      "Training:  23%|██▎       | 412/1772 [01:03<03:45,  6.04it/s, running training loss: 0.9576]\u001b[A\n",
      "Training:  23%|██▎       | 412/1772 [01:03<03:45,  6.04it/s, running training loss: 0.9429]\u001b[A\n",
      "Training:  23%|██▎       | 413/1772 [01:03<03:27,  6.56it/s, running training loss: 0.9429]\u001b[A\n",
      "Training:  23%|██▎       | 413/1772 [01:03<03:27,  6.56it/s, running training loss: 0.9511]\u001b[A\n",
      "Training:  23%|██▎       | 414/1772 [01:03<03:22,  6.69it/s, running training loss: 0.9511]\u001b[A\n",
      "Training:  23%|██▎       | 414/1772 [01:03<03:22,  6.69it/s, running training loss: 0.8555]\u001b[A\n",
      "Training:  23%|██▎       | 415/1772 [01:03<03:08,  7.19it/s, running training loss: 0.8555]\u001b[A\n",
      "Training:  23%|██▎       | 415/1772 [01:03<03:08,  7.19it/s, running training loss: 0.9414]\u001b[A\n",
      "Training:  23%|██▎       | 416/1772 [01:03<03:06,  7.28it/s, running training loss: 0.9414]\u001b[A\n",
      "Training:  23%|██▎       | 416/1772 [01:03<03:06,  7.28it/s, running training loss: 0.8890]\u001b[A\n",
      "Training:  24%|██▎       | 417/1772 [01:03<03:17,  6.87it/s, running training loss: 0.8890]\u001b[A\n",
      "Training:  24%|██▎       | 417/1772 [01:03<03:17,  6.87it/s, running training loss: 0.8947]\u001b[A\n",
      "Training:  24%|██▎       | 418/1772 [01:03<03:14,  6.98it/s, running training loss: 0.8947]\u001b[A\n",
      "Training:  24%|██▎       | 418/1772 [01:04<03:14,  6.98it/s, running training loss: 1.0186]\u001b[A\n",
      "Training:  24%|██▎       | 419/1772 [01:04<03:22,  6.68it/s, running training loss: 1.0186]\u001b[A\n",
      "Training:  24%|██▎       | 419/1772 [01:04<03:22,  6.68it/s, running training loss: 0.9905]\u001b[A\n",
      "Training:  24%|██▎       | 420/1772 [01:04<03:33,  6.33it/s, running training loss: 0.9905]\u001b[A\n",
      "Training:  24%|██▎       | 420/1772 [01:04<03:33,  6.33it/s, running training loss: 0.7597]\u001b[A\n",
      "Training:  24%|██▍       | 421/1772 [01:04<03:23,  6.63it/s, running training loss: 0.7597]\u001b[A\n",
      "Training:  24%|██▍       | 421/1772 [01:04<03:23,  6.63it/s, running training loss: 0.8749]\u001b[A\n",
      "Training:  24%|██▍       | 422/1772 [01:04<03:13,  6.97it/s, running training loss: 0.8749]\u001b[A\n",
      "Training:  24%|██▍       | 422/1772 [01:04<03:13,  6.97it/s, running training loss: 0.9085]\u001b[A\n",
      "Training:  24%|██▍       | 423/1772 [01:04<03:18,  6.80it/s, running training loss: 0.9085]\u001b[A\n",
      "Training:  24%|██▍       | 423/1772 [01:04<03:18,  6.80it/s, running training loss: 0.9853]\u001b[A\n",
      "Training:  24%|██▍       | 424/1772 [01:04<03:09,  7.13it/s, running training loss: 0.9853]\u001b[A\n",
      "Training:  24%|██▍       | 424/1772 [01:04<03:09,  7.13it/s, running training loss: 1.0210]\u001b[A\n",
      "Training:  24%|██▍       | 425/1772 [01:04<03:03,  7.36it/s, running training loss: 1.0210]\u001b[A\n",
      "Training:  24%|██▍       | 425/1772 [01:04<03:03,  7.36it/s, running training loss: 0.9075]\u001b[A\n",
      "Training:  24%|██▍       | 426/1772 [01:04<03:05,  7.27it/s, running training loss: 0.9075]\u001b[A\n",
      "Training:  24%|██▍       | 426/1772 [01:05<03:05,  7.27it/s, running training loss: 1.0089]\u001b[A\n",
      "Training:  24%|██▍       | 427/1772 [01:05<03:02,  7.38it/s, running training loss: 1.0089]\u001b[A\n",
      "Training:  24%|██▍       | 427/1772 [01:05<03:02,  7.38it/s, running training loss: 1.0941]\u001b[A\n",
      "Training:  24%|██▍       | 428/1772 [01:05<03:15,  6.86it/s, running training loss: 1.0941]\u001b[A\n",
      "Training:  24%|██▍       | 428/1772 [01:05<03:15,  6.86it/s, running training loss: 1.0635]\u001b[A\n",
      "Training:  24%|██▍       | 429/1772 [01:05<03:19,  6.72it/s, running training loss: 1.0635]\u001b[A\n",
      "Training:  24%|██▍       | 429/1772 [01:05<03:19,  6.72it/s, running training loss: 1.0532]\u001b[A\n",
      "Training:  24%|██▍       | 430/1772 [01:05<03:19,  6.72it/s, running training loss: 1.0532]\u001b[A\n",
      "Training:  24%|██▍       | 430/1772 [01:05<03:19,  6.72it/s, running training loss: 0.9777]\u001b[A\n",
      "Training:  24%|██▍       | 431/1772 [01:05<03:03,  7.30it/s, running training loss: 0.9777]\u001b[A\n",
      "Training:  24%|██▍       | 431/1772 [01:05<03:03,  7.30it/s, running training loss: 1.0931]\u001b[A\n",
      "Training:  24%|██▍       | 432/1772 [01:05<03:10,  7.03it/s, running training loss: 1.0931]\u001b[A\n",
      "Training:  24%|██▍       | 432/1772 [01:05<03:10,  7.03it/s, running training loss: 0.9589]\u001b[A\n",
      "Training:  24%|██▍       | 433/1772 [01:05<03:03,  7.32it/s, running training loss: 0.9589]\u001b[A\n",
      "Training:  24%|██▍       | 433/1772 [01:06<03:03,  7.32it/s, running training loss: 0.8624]\u001b[A\n",
      "Training:  24%|██▍       | 434/1772 [01:06<03:06,  7.17it/s, running training loss: 0.8624]\u001b[A\n",
      "Training:  24%|██▍       | 434/1772 [01:06<03:06,  7.17it/s, running training loss: 1.0078]\u001b[A\n",
      "Training:  25%|██▍       | 435/1772 [01:06<03:01,  7.38it/s, running training loss: 1.0078]\u001b[A\n",
      "Training:  25%|██▍       | 435/1772 [01:06<03:01,  7.38it/s, running training loss: 0.9838]\u001b[A\n",
      "Training:  25%|██▍       | 436/1772 [01:06<02:52,  7.73it/s, running training loss: 0.9838]\u001b[A\n",
      "Training:  25%|██▍       | 436/1772 [01:06<02:52,  7.73it/s, running training loss: 1.0982]\u001b[A\n",
      "Training:  25%|██▍       | 437/1772 [01:06<03:10,  7.00it/s, running training loss: 1.0982]\u001b[A\n",
      "Training:  25%|██▍       | 437/1772 [01:06<03:10,  7.00it/s, running training loss: 1.4526]\u001b[A\n",
      "Training:  25%|██▍       | 438/1772 [01:06<03:05,  7.21it/s, running training loss: 1.4526]\u001b[A\n",
      "Training:  25%|██▍       | 438/1772 [01:06<03:05,  7.21it/s, running training loss: 0.9646]\u001b[A\n",
      "Training:  25%|██▍       | 439/1772 [01:06<03:05,  7.20it/s, running training loss: 0.9646]\u001b[A\n",
      "Training:  25%|██▍       | 439/1772 [01:06<03:05,  7.20it/s, running training loss: 0.9729]\u001b[A\n",
      "Training:  25%|██▍       | 440/1772 [01:06<02:59,  7.43it/s, running training loss: 0.9729]\u001b[A\n",
      "Training:  25%|██▍       | 440/1772 [01:07<02:59,  7.43it/s, running training loss: 0.9152]\u001b[A\n",
      "Training:  25%|██▍       | 441/1772 [01:07<02:56,  7.53it/s, running training loss: 0.9152]\u001b[A\n",
      "Training:  25%|██▍       | 441/1772 [01:07<02:56,  7.53it/s, running training loss: 0.9663]\u001b[A\n",
      "Training:  25%|██▍       | 442/1772 [01:07<02:52,  7.72it/s, running training loss: 0.9663]\u001b[A\n",
      "Training:  25%|██▍       | 442/1772 [01:07<02:52,  7.72it/s, running training loss: 1.2651]\u001b[A\n",
      "Training:  25%|██▌       | 443/1772 [01:07<02:45,  8.03it/s, running training loss: 1.2651]\u001b[A\n",
      "Training:  25%|██▌       | 443/1772 [01:07<02:45,  8.03it/s, running training loss: 1.0186]\u001b[A\n",
      "Training:  25%|██▌       | 444/1772 [01:07<02:44,  8.07it/s, running training loss: 1.0186]\u001b[A\n",
      "Training:  25%|██▌       | 444/1772 [01:07<02:44,  8.07it/s, running training loss: 1.1896]\u001b[A\n",
      "Training:  25%|██▌       | 445/1772 [01:07<02:56,  7.53it/s, running training loss: 1.1896]\u001b[A\n",
      "Training:  25%|██▌       | 445/1772 [01:07<02:56,  7.53it/s, running training loss: 0.9648]\u001b[A\n",
      "Training:  25%|██▌       | 446/1772 [01:07<02:47,  7.90it/s, running training loss: 0.9648]\u001b[A\n",
      "Training:  25%|██▌       | 446/1772 [01:07<02:47,  7.90it/s, running training loss: 1.0389]\u001b[A\n",
      "Training:  25%|██▌       | 447/1772 [01:07<02:43,  8.11it/s, running training loss: 1.0389]\u001b[A\n",
      "Training:  25%|██▌       | 447/1772 [01:08<02:43,  8.11it/s, running training loss: 1.0350]\u001b[A\n",
      "Training:  25%|██▌       | 448/1772 [01:08<03:13,  6.85it/s, running training loss: 1.0350]\u001b[A\n",
      "Training:  25%|██▌       | 448/1772 [01:08<03:13,  6.85it/s, running training loss: 1.0549]\u001b[A\n",
      "Training:  25%|██▌       | 449/1772 [01:08<03:04,  7.17it/s, running training loss: 1.0549]\u001b[A\n",
      "Training:  25%|██▌       | 449/1772 [01:08<03:04,  7.17it/s, running training loss: 0.8444]\u001b[A\n",
      "Training:  25%|██▌       | 450/1772 [01:08<03:06,  7.10it/s, running training loss: 0.8444]\u001b[A\n",
      "Training:  25%|██▌       | 450/1772 [01:08<03:06,  7.10it/s, running training loss: 0.8488]\u001b[A\n",
      "Training:  25%|██▌       | 451/1772 [01:08<02:56,  7.49it/s, running training loss: 0.8488]\u001b[A\n",
      "Training:  25%|██▌       | 451/1772 [01:08<02:56,  7.49it/s, running training loss: 1.0666]\u001b[A\n",
      "Training:  26%|██▌       | 452/1772 [01:08<03:00,  7.30it/s, running training loss: 1.0666]\u001b[A\n",
      "Training:  26%|██▌       | 452/1772 [01:08<03:00,  7.30it/s, running training loss: 0.8370]\u001b[A\n",
      "Training:  26%|██▌       | 453/1772 [01:08<03:10,  6.91it/s, running training loss: 0.8370]\u001b[A\n",
      "Training:  26%|██▌       | 453/1772 [01:08<03:10,  6.91it/s, running training loss: 1.1276]\u001b[A\n",
      "Training:  26%|██▌       | 454/1772 [01:08<02:58,  7.37it/s, running training loss: 1.1276]\u001b[A\n",
      "Training:  26%|██▌       | 454/1772 [01:08<02:58,  7.37it/s, running training loss: 0.9720]\u001b[A\n",
      "Training:  26%|██▌       | 455/1772 [01:08<02:50,  7.74it/s, running training loss: 0.9720]\u001b[A\n",
      "Training:  26%|██▌       | 455/1772 [01:09<02:50,  7.74it/s, running training loss: 0.8051]\u001b[A\n",
      "Training:  26%|██▌       | 456/1772 [01:09<02:47,  7.85it/s, running training loss: 0.8051]\u001b[A\n",
      "Training:  26%|██▌       | 456/1772 [01:09<02:47,  7.85it/s, running training loss: 0.9162]\u001b[A\n",
      "Training:  26%|██▌       | 457/1772 [01:09<03:12,  6.82it/s, running training loss: 0.9162]\u001b[A\n",
      "Training:  26%|██▌       | 457/1772 [01:09<03:12,  6.82it/s, running training loss: 0.8701]\u001b[A\n",
      "Training:  26%|██▌       | 458/1772 [01:09<03:24,  6.42it/s, running training loss: 0.8701]\u001b[A\n",
      "Training:  26%|██▌       | 458/1772 [01:09<03:24,  6.42it/s, running training loss: 0.8164]\u001b[A\n",
      "Training:  26%|██▌       | 459/1772 [01:09<03:19,  6.58it/s, running training loss: 0.8164]\u001b[A\n",
      "Training:  26%|██▌       | 459/1772 [01:09<03:19,  6.58it/s, running training loss: 0.9125]\u001b[A\n",
      "Training:  26%|██▌       | 460/1772 [01:09<03:05,  7.06it/s, running training loss: 0.9125]\u001b[A\n",
      "Training:  26%|██▌       | 460/1772 [01:09<03:05,  7.06it/s, running training loss: 0.9822]\u001b[A\n",
      "Training:  26%|██▌       | 461/1772 [01:09<02:53,  7.54it/s, running training loss: 0.9822]\u001b[A\n",
      "Training:  26%|██▌       | 461/1772 [01:09<02:53,  7.54it/s, running training loss: 1.1815]\u001b[A\n",
      "Training:  26%|██▌       | 462/1772 [01:09<02:44,  7.95it/s, running training loss: 1.1815]\u001b[A\n",
      "Training:  26%|██▌       | 462/1772 [01:10<02:44,  7.95it/s, running training loss: 0.9290]\u001b[A\n",
      "Training:  26%|██▌       | 463/1772 [01:10<02:43,  8.00it/s, running training loss: 0.9290]\u001b[A\n",
      "Training:  26%|██▌       | 463/1772 [01:10<02:43,  8.00it/s, running training loss: 0.9004]\u001b[A\n",
      "Training:  26%|██▌       | 464/1772 [01:10<02:40,  8.13it/s, running training loss: 0.9004]\u001b[A\n",
      "Training:  26%|██▌       | 464/1772 [01:10<02:40,  8.13it/s, running training loss: 1.0967]\u001b[A\n",
      "Training:  26%|██▌       | 465/1772 [01:10<02:41,  8.09it/s, running training loss: 1.0967]\u001b[A\n",
      "Training:  26%|██▌       | 465/1772 [01:10<02:41,  8.09it/s, running training loss: 0.9322]\u001b[A\n",
      "Training:  26%|██▋       | 466/1772 [01:10<02:43,  7.99it/s, running training loss: 0.9322]\u001b[A\n",
      "Training:  26%|██▋       | 466/1772 [01:10<02:43,  7.99it/s, running training loss: 1.0686]\u001b[A\n",
      "Training:  26%|██▋       | 467/1772 [01:10<02:47,  7.80it/s, running training loss: 1.0686]\u001b[A\n",
      "Training:  26%|██▋       | 467/1772 [01:10<02:47,  7.80it/s, running training loss: 0.9757]\u001b[A\n",
      "Training:  26%|██▋       | 468/1772 [01:10<02:54,  7.46it/s, running training loss: 0.9757]\u001b[A\n",
      "Training:  26%|██▋       | 468/1772 [01:10<02:54,  7.46it/s, running training loss: 1.2548]\u001b[A\n",
      "Training:  26%|██▋       | 469/1772 [01:10<03:19,  6.53it/s, running training loss: 1.2548]\u001b[A\n",
      "Training:  26%|██▋       | 469/1772 [01:11<03:19,  6.53it/s, running training loss: 0.8742]\u001b[A\n",
      "Training:  27%|██▋       | 470/1772 [01:11<03:16,  6.63it/s, running training loss: 0.8742]\u001b[A\n",
      "Training:  27%|██▋       | 470/1772 [01:11<03:16,  6.63it/s, running training loss: 0.9779]\u001b[A\n",
      "Training:  27%|██▋       | 471/1772 [01:11<03:16,  6.63it/s, running training loss: 0.9779]\u001b[A\n",
      "Training:  27%|██▋       | 471/1772 [01:11<03:16,  6.63it/s, running training loss: 0.9536]\u001b[A\n",
      "Training:  27%|██▋       | 472/1772 [01:11<03:12,  6.74it/s, running training loss: 0.9536]\u001b[A\n",
      "Training:  27%|██▋       | 472/1772 [01:11<03:12,  6.74it/s, running training loss: 1.0824]\u001b[A\n",
      "Training:  27%|██▋       | 473/1772 [01:11<02:58,  7.29it/s, running training loss: 1.0824]\u001b[A\n",
      "Training:  27%|██▋       | 473/1772 [01:11<02:58,  7.29it/s, running training loss: 0.8766]\u001b[A\n",
      "Training:  27%|██▋       | 474/1772 [01:11<03:01,  7.15it/s, running training loss: 0.8766]\u001b[A\n",
      "Training:  27%|██▋       | 474/1772 [01:11<03:01,  7.15it/s, running training loss: 0.9942]\u001b[A\n",
      "Training:  27%|██▋       | 475/1772 [01:11<03:18,  6.55it/s, running training loss: 0.9942]\u001b[A\n",
      "Training:  27%|██▋       | 475/1772 [01:11<03:18,  6.55it/s, running training loss: 0.9739]\u001b[A\n",
      "Training:  27%|██▋       | 476/1772 [01:11<03:05,  7.00it/s, running training loss: 0.9739]\u001b[A\n",
      "Training:  27%|██▋       | 476/1772 [01:12<03:05,  7.00it/s, running training loss: 1.4930]\u001b[A\n",
      "Training:  27%|██▋       | 477/1772 [01:12<03:02,  7.11it/s, running training loss: 1.4930]\u001b[A\n",
      "Training:  27%|██▋       | 477/1772 [01:12<03:02,  7.11it/s, running training loss: 1.4253]\u001b[A\n",
      "Training:  27%|██▋       | 478/1772 [01:12<02:59,  7.21it/s, running training loss: 1.4253]\u001b[A\n",
      "Training:  27%|██▋       | 478/1772 [01:12<02:59,  7.21it/s, running training loss: 1.5658]\u001b[A\n",
      "Training:  27%|██▋       | 479/1772 [01:12<03:08,  6.88it/s, running training loss: 1.5658]\u001b[A\n",
      "Training:  27%|██▋       | 479/1772 [01:12<03:08,  6.88it/s, running training loss: 1.6981]\u001b[A\n",
      "Training:  27%|██▋       | 480/1772 [01:12<03:22,  6.39it/s, running training loss: 1.6981]\u001b[A\n",
      "Training:  27%|██▋       | 480/1772 [01:12<03:22,  6.39it/s, running training loss: 0.8688]\u001b[A\n",
      "Training:  27%|██▋       | 481/1772 [01:12<03:09,  6.82it/s, running training loss: 0.8688]\u001b[A\n",
      "Training:  27%|██▋       | 481/1772 [01:12<03:09,  6.82it/s, running training loss: 1.2370]\u001b[A\n",
      "Training:  27%|██▋       | 482/1772 [01:12<02:56,  7.33it/s, running training loss: 1.2370]\u001b[A\n",
      "Training:  27%|██▋       | 482/1772 [01:12<02:56,  7.33it/s, running training loss: 0.9188]\u001b[A\n",
      "Training:  27%|██▋       | 483/1772 [01:12<02:43,  7.86it/s, running training loss: 0.9188]\u001b[A\n",
      "Training:  27%|██▋       | 483/1772 [01:12<02:43,  7.86it/s, running training loss: 0.8664]\u001b[A\n",
      "Training:  27%|██▋       | 484/1772 [01:12<02:50,  7.56it/s, running training loss: 0.8664]\u001b[A\n",
      "Training:  27%|██▋       | 484/1772 [01:13<02:50,  7.56it/s, running training loss: 1.1318]\u001b[A\n",
      "Training:  27%|██▋       | 485/1772 [01:13<02:46,  7.73it/s, running training loss: 1.1318]\u001b[A\n",
      "Training:  27%|██▋       | 485/1772 [01:13<02:46,  7.73it/s, running training loss: 0.9431]\u001b[A\n",
      "Training:  27%|██▋       | 486/1772 [01:13<02:39,  8.04it/s, running training loss: 0.9431]\u001b[A\n",
      "Training:  27%|██▋       | 486/1772 [01:13<02:39,  8.04it/s, running training loss: 0.9595]\u001b[A\n",
      "Training:  27%|██▋       | 487/1772 [01:13<02:46,  7.70it/s, running training loss: 0.9595]\u001b[A\n",
      "Training:  27%|██▋       | 487/1772 [01:13<02:46,  7.70it/s, running training loss: 0.9330]\u001b[A\n",
      "Training:  28%|██▊       | 488/1772 [01:13<02:45,  7.77it/s, running training loss: 0.9330]\u001b[A\n",
      "Training:  28%|██▊       | 488/1772 [01:13<02:45,  7.77it/s, running training loss: 1.3207]\u001b[A\n",
      "Training:  28%|██▊       | 489/1772 [01:13<02:56,  7.28it/s, running training loss: 1.3207]\u001b[A\n",
      "Training:  28%|██▊       | 489/1772 [01:13<02:56,  7.28it/s, running training loss: 0.9843]\u001b[A\n",
      "Training:  28%|██▊       | 490/1772 [01:13<02:49,  7.55it/s, running training loss: 0.9843]\u001b[A\n",
      "Training:  28%|██▊       | 490/1772 [01:13<02:49,  7.55it/s, running training loss: 1.6169]\u001b[A\n",
      "Training:  28%|██▊       | 491/1772 [01:13<02:42,  7.89it/s, running training loss: 1.6169]\u001b[A\n",
      "Training:  28%|██▊       | 491/1772 [01:13<02:42,  7.89it/s, running training loss: 0.8579]\u001b[A\n",
      "Training:  28%|██▊       | 492/1772 [01:13<02:37,  8.13it/s, running training loss: 0.8579]\u001b[A\n",
      "Training:  28%|██▊       | 492/1772 [01:14<02:37,  8.13it/s, running training loss: 1.2683]\u001b[A\n",
      "Training:  28%|██▊       | 493/1772 [01:14<02:38,  8.05it/s, running training loss: 1.2683]\u001b[A\n",
      "Training:  28%|██▊       | 493/1772 [01:14<02:38,  8.05it/s, running training loss: 0.9046]\u001b[A\n",
      "Training:  28%|██▊       | 494/1772 [01:14<02:58,  7.16it/s, running training loss: 0.9046]\u001b[A\n",
      "Training:  28%|██▊       | 494/1772 [01:14<02:58,  7.16it/s, running training loss: 1.1806]\u001b[A\n",
      "Training:  28%|██▊       | 495/1772 [01:14<02:56,  7.25it/s, running training loss: 1.1806]\u001b[A\n",
      "Training:  28%|██▊       | 495/1772 [01:14<02:56,  7.25it/s, running training loss: 0.9466]\u001b[A\n",
      "Training:  28%|██▊       | 496/1772 [01:14<02:47,  7.61it/s, running training loss: 0.9466]\u001b[A\n",
      "Training:  28%|██▊       | 496/1772 [01:14<02:47,  7.61it/s, running training loss: 0.1432]\u001b[A\n",
      "Training:  28%|██▊       | 497/1772 [01:14<02:45,  7.69it/s, running training loss: 0.1432]\u001b[A\n",
      "Training:  28%|██▊       | 497/1772 [01:14<02:45,  7.69it/s, running training loss: 0.9922]\u001b[A\n",
      "Training:  28%|██▊       | 498/1772 [01:14<02:43,  7.78it/s, running training loss: 0.9922]\u001b[A\n",
      "Training:  28%|██▊       | 498/1772 [01:14<02:43,  7.78it/s, running training loss: 1.0971]\u001b[A\n",
      "Training:  28%|██▊       | 499/1772 [01:14<02:41,  7.86it/s, running training loss: 1.0971]\u001b[A\n",
      "Training:  28%|██▊       | 499/1772 [01:15<02:41,  7.86it/s, running training loss: 1.1370]\u001b[A\n",
      "Training:  28%|██▊       | 500/1772 [01:15<02:37,  8.07it/s, running training loss: 1.1370]\u001b[A\n",
      "Training:  28%|██▊       | 500/1772 [01:15<02:37,  8.07it/s, running training loss: 1.0904]\u001b[A\n",
      "Training:  28%|██▊       | 501/1772 [01:15<02:37,  8.05it/s, running training loss: 1.0904]\u001b[A\n",
      "Training:  28%|██▊       | 501/1772 [01:15<02:37,  8.05it/s, running training loss: 1.3568]\u001b[A\n",
      "Training:  28%|██▊       | 502/1772 [01:15<02:37,  8.04it/s, running training loss: 1.3568]\u001b[A\n",
      "Training:  28%|██▊       | 502/1772 [01:15<02:37,  8.04it/s, running training loss: 1.0377]\u001b[A\n",
      "Training:  28%|██▊       | 503/1772 [01:15<02:43,  7.76it/s, running training loss: 1.0377]\u001b[A\n",
      "Training:  28%|██▊       | 503/1772 [01:15<02:43,  7.76it/s, running training loss: 0.9824]\u001b[A\n",
      "Training:  28%|██▊       | 504/1772 [01:15<02:44,  7.72it/s, running training loss: 0.9824]\u001b[A\n",
      "Training:  28%|██▊       | 504/1772 [01:15<02:44,  7.72it/s, running training loss: 1.6289]\u001b[A\n",
      "Training:  28%|██▊       | 505/1772 [01:15<02:45,  7.64it/s, running training loss: 1.6289]\u001b[A\n",
      "Training:  28%|██▊       | 505/1772 [01:15<02:45,  7.64it/s, running training loss: 0.9204]\u001b[A\n",
      "Training:  29%|██▊       | 506/1772 [01:15<02:52,  7.35it/s, running training loss: 0.9204]\u001b[A\n",
      "Training:  29%|██▊       | 506/1772 [01:15<02:52,  7.35it/s, running training loss: 1.0737]\u001b[A\n",
      "Training:  29%|██▊       | 507/1772 [01:15<02:53,  7.28it/s, running training loss: 1.0737]\u001b[A\n",
      "Training:  29%|██▊       | 507/1772 [01:16<02:53,  7.28it/s, running training loss: 0.9863]\u001b[A\n",
      "Training:  29%|██▊       | 508/1772 [01:16<02:49,  7.47it/s, running training loss: 0.9863]\u001b[A\n",
      "Training:  29%|██▊       | 508/1772 [01:16<02:49,  7.47it/s, running training loss: 1.0575]\u001b[A\n",
      "Training:  29%|██▊       | 509/1772 [01:16<02:39,  7.90it/s, running training loss: 1.0575]\u001b[A\n",
      "Training:  29%|██▊       | 509/1772 [01:16<02:39,  7.90it/s, running training loss: 1.0829]\u001b[A\n",
      "Training:  29%|██▉       | 510/1772 [01:16<02:39,  7.93it/s, running training loss: 1.0829]\u001b[A\n",
      "Training:  29%|██▉       | 510/1772 [01:16<02:39,  7.93it/s, running training loss: 0.9131]\u001b[A\n",
      "Training:  29%|██▉       | 511/1772 [01:16<02:41,  7.82it/s, running training loss: 0.9131]\u001b[A\n",
      "Training:  29%|██▉       | 511/1772 [01:16<02:41,  7.82it/s, running training loss: 0.9682]\u001b[A\n",
      "Training:  29%|██▉       | 512/1772 [01:16<02:37,  8.00it/s, running training loss: 0.9682]\u001b[A\n",
      "Training:  29%|██▉       | 512/1772 [01:16<02:37,  8.00it/s, running training loss: 0.9242]\u001b[A\n",
      "Training:  29%|██▉       | 513/1772 [01:16<02:36,  8.05it/s, running training loss: 0.9242]\u001b[A\n",
      "Training:  29%|██▉       | 513/1772 [01:16<02:36,  8.05it/s, running training loss: 0.9457]\u001b[A\n",
      "Training:  29%|██▉       | 514/1772 [01:16<02:40,  7.82it/s, running training loss: 0.9457]\u001b[A\n",
      "Training:  29%|██▉       | 514/1772 [01:16<02:40,  7.82it/s, running training loss: 1.0286]\u001b[A\n",
      "Training:  29%|██▉       | 515/1772 [01:16<02:48,  7.44it/s, running training loss: 1.0286]\u001b[A\n",
      "Training:  29%|██▉       | 515/1772 [01:17<02:48,  7.44it/s, running training loss: 1.0295]\u001b[A\n",
      "Training:  29%|██▉       | 516/1772 [01:17<02:45,  7.61it/s, running training loss: 1.0295]\u001b[A\n",
      "Training:  29%|██▉       | 516/1772 [01:17<02:45,  7.61it/s, running training loss: 0.9096]\u001b[A\n",
      "Training:  29%|██▉       | 517/1772 [01:17<02:42,  7.71it/s, running training loss: 0.9096]\u001b[A\n",
      "Training:  29%|██▉       | 517/1772 [01:17<02:42,  7.71it/s, running training loss: 0.9669]\u001b[A\n",
      "Training:  29%|██▉       | 518/1772 [01:17<02:46,  7.53it/s, running training loss: 0.9669]\u001b[A\n",
      "Training:  29%|██▉       | 518/1772 [01:17<02:46,  7.53it/s, running training loss: 1.1335]\u001b[A\n",
      "Training:  29%|██▉       | 519/1772 [01:17<02:38,  7.93it/s, running training loss: 1.1335]\u001b[A\n",
      "Training:  29%|██▉       | 519/1772 [01:17<02:38,  7.93it/s, running training loss: 0.9899]\u001b[A\n",
      "Training:  29%|██▉       | 520/1772 [01:17<02:43,  7.64it/s, running training loss: 0.9899]\u001b[A\n",
      "Training:  29%|██▉       | 520/1772 [01:17<02:43,  7.64it/s, running training loss: 0.8587]\u001b[A\n",
      "Training:  29%|██▉       | 521/1772 [01:17<02:40,  7.79it/s, running training loss: 0.8587]\u001b[A\n",
      "Training:  29%|██▉       | 521/1772 [01:17<02:40,  7.79it/s, running training loss: 0.9543]\u001b[A\n",
      "Training:  29%|██▉       | 522/1772 [01:17<02:36,  8.00it/s, running training loss: 0.9543]\u001b[A\n",
      "Training:  29%|██▉       | 522/1772 [01:17<02:36,  8.00it/s, running training loss: 0.9147]\u001b[A\n",
      "Training:  30%|██▉       | 523/1772 [01:18<02:35,  8.02it/s, running training loss: 0.9147]\u001b[A\n",
      "Training:  30%|██▉       | 523/1772 [01:18<02:35,  8.02it/s, running training loss: 0.9848]\u001b[A\n",
      "Training:  30%|██▉       | 523/1772 [01:18<02:35,  8.02it/s, running training loss: 0.9942]\u001b[A\n",
      "Training:  30%|██▉       | 525/1772 [01:18<02:31,  8.23it/s, running training loss: 0.9942]\u001b[A\n",
      "Training:  30%|██▉       | 525/1772 [01:18<02:31,  8.23it/s, running training loss: 1.1050]\u001b[A\n",
      "Training:  30%|██▉       | 526/1772 [01:18<02:45,  7.54it/s, running training loss: 1.1050]\u001b[A\n",
      "Training:  30%|██▉       | 526/1772 [01:18<02:45,  7.54it/s, running training loss: 1.1152]\u001b[A\n",
      "Training:  30%|██▉       | 527/1772 [01:18<02:39,  7.82it/s, running training loss: 1.1152]\u001b[A\n",
      "Training:  30%|██▉       | 527/1772 [01:18<02:39,  7.82it/s, running training loss: 1.5680]\u001b[A\n",
      "Training:  30%|██▉       | 528/1772 [01:18<02:43,  7.59it/s, running training loss: 1.5680]\u001b[A\n",
      "Training:  30%|██▉       | 528/1772 [01:18<02:43,  7.59it/s, running training loss: 1.0492]\u001b[A\n",
      "Training:  30%|██▉       | 529/1772 [01:18<02:39,  7.78it/s, running training loss: 1.0492]\u001b[A\n",
      "Training:  30%|██▉       | 529/1772 [01:18<02:39,  7.78it/s, running training loss: 1.3010]\u001b[A\n",
      "Training:  30%|██▉       | 530/1772 [01:18<02:44,  7.56it/s, running training loss: 1.3010]\u001b[A\n",
      "Training:  30%|██▉       | 530/1772 [01:19<02:44,  7.56it/s, running training loss: 1.5773]\u001b[A\n",
      "Training:  30%|██▉       | 531/1772 [01:19<02:43,  7.61it/s, running training loss: 1.5773]\u001b[A\n",
      "Training:  30%|██▉       | 531/1772 [01:19<02:43,  7.61it/s, running training loss: 1.1579]\u001b[A\n",
      "Training:  30%|███       | 532/1772 [01:19<02:43,  7.60it/s, running training loss: 1.1579]\u001b[A\n",
      "Training:  30%|███       | 532/1772 [01:19<02:43,  7.60it/s, running training loss: 1.3390]\u001b[A\n",
      "Training:  30%|███       | 533/1772 [01:19<02:52,  7.16it/s, running training loss: 1.3390]\u001b[A\n",
      "Training:  30%|███       | 533/1772 [01:19<02:52,  7.16it/s, running training loss: 1.0491]\u001b[A\n",
      "Training:  30%|███       | 534/1772 [01:19<02:43,  7.57it/s, running training loss: 1.0491]\u001b[A\n",
      "Training:  30%|███       | 534/1772 [01:19<02:43,  7.57it/s, running training loss: 1.0200]\u001b[A\n",
      "Training:  30%|███       | 535/1772 [01:19<02:36,  7.90it/s, running training loss: 1.0200]\u001b[A\n",
      "Training:  30%|███       | 535/1772 [01:19<02:36,  7.90it/s, running training loss: 0.9489]\u001b[A\n",
      "Training:  30%|███       | 536/1772 [01:19<02:37,  7.82it/s, running training loss: 0.9489]\u001b[A\n",
      "Training:  30%|███       | 536/1772 [01:19<02:37,  7.82it/s, running training loss: 0.9737]\u001b[A\n",
      "Training:  30%|███       | 537/1772 [01:19<02:31,  8.13it/s, running training loss: 0.9737]\u001b[A\n",
      "Training:  30%|███       | 537/1772 [01:19<02:31,  8.13it/s, running training loss: 1.0203]\u001b[A\n",
      "Training:  30%|███       | 538/1772 [01:19<02:44,  7.52it/s, running training loss: 1.0203]\u001b[A\n",
      "Training:  30%|███       | 538/1772 [01:20<02:44,  7.52it/s, running training loss: 1.0322]\u001b[A\n",
      "Training:  30%|███       | 539/1772 [01:20<02:44,  7.48it/s, running training loss: 1.0322]\u001b[A\n",
      "Training:  30%|███       | 539/1772 [01:20<02:44,  7.48it/s, running training loss: 0.7252]\u001b[A\n",
      "Training:  30%|███       | 540/1772 [01:20<02:39,  7.71it/s, running training loss: 0.7252]\u001b[A\n",
      "Training:  30%|███       | 540/1772 [01:20<02:39,  7.71it/s, running training loss: 0.9902]\u001b[A\n",
      "Training:  31%|███       | 541/1772 [01:20<03:00,  6.82it/s, running training loss: 0.9902]\u001b[A\n",
      "Training:  31%|███       | 541/1772 [01:20<03:00,  6.82it/s, running training loss: 0.7388]\u001b[A\n",
      "Training:  31%|███       | 542/1772 [01:20<02:51,  7.19it/s, running training loss: 0.7388]\u001b[A\n",
      "Training:  31%|███       | 542/1772 [01:20<02:51,  7.19it/s, running training loss: 0.8276]\u001b[A\n",
      "Training:  31%|███       | 543/1772 [01:20<02:44,  7.48it/s, running training loss: 0.8276]\u001b[A\n",
      "Training:  31%|███       | 543/1772 [01:20<02:44,  7.48it/s, running training loss: 1.0226]\u001b[A\n",
      "Training:  31%|███       | 544/1772 [01:20<02:41,  7.60it/s, running training loss: 1.0226]\u001b[A\n",
      "Training:  31%|███       | 544/1772 [01:20<02:41,  7.60it/s, running training loss: 0.9033]\u001b[A\n",
      "Training:  31%|███       | 545/1772 [01:20<02:49,  7.25it/s, running training loss: 0.9033]\u001b[A\n",
      "Training:  31%|███       | 545/1772 [01:21<02:49,  7.25it/s, running training loss: 0.9307]\u001b[A\n",
      "Training:  31%|███       | 546/1772 [01:21<02:41,  7.58it/s, running training loss: 0.9307]\u001b[A\n",
      "Training:  31%|███       | 546/1772 [01:21<02:41,  7.58it/s, running training loss: 0.9238]\u001b[A\n",
      "Training:  31%|███       | 547/1772 [01:21<02:52,  7.09it/s, running training loss: 0.9238]\u001b[A\n",
      "Training:  31%|███       | 547/1772 [01:21<02:52,  7.09it/s, running training loss: 0.9423]\u001b[A\n",
      "Training:  31%|███       | 548/1772 [01:21<02:53,  7.07it/s, running training loss: 0.9423]\u001b[A\n",
      "Training:  31%|███       | 548/1772 [01:21<02:53,  7.07it/s, running training loss: 0.9680]\u001b[A\n",
      "Training:  31%|███       | 549/1772 [01:21<02:47,  7.29it/s, running training loss: 0.9680]\u001b[A\n",
      "Training:  31%|███       | 549/1772 [01:21<02:47,  7.29it/s, running training loss: 0.9307]\u001b[A\n",
      "Training:  31%|███       | 550/1772 [01:21<02:40,  7.61it/s, running training loss: 0.9307]\u001b[A\n",
      "Training:  31%|███       | 550/1772 [01:21<02:40,  7.61it/s, running training loss: 1.0032]\u001b[A\n",
      "Training:  31%|███       | 551/1772 [01:21<02:33,  7.93it/s, running training loss: 1.0032]\u001b[A\n",
      "Training:  31%|███       | 551/1772 [01:21<02:33,  7.93it/s, running training loss: 0.9473]\u001b[A\n",
      "Training:  31%|███       | 552/1772 [01:21<02:30,  8.12it/s, running training loss: 0.9473]\u001b[A\n",
      "Training:  31%|███       | 552/1772 [01:21<02:30,  8.12it/s, running training loss: 1.1685]\u001b[A\n",
      "Training:  31%|███       | 553/1772 [01:21<02:22,  8.53it/s, running training loss: 1.1685]\u001b[A\n",
      "Training:  31%|███       | 553/1772 [01:22<02:22,  8.53it/s, running training loss: 1.3310]\u001b[A\n",
      "Training:  31%|███▏      | 554/1772 [01:22<02:25,  8.39it/s, running training loss: 1.3310]\u001b[A\n",
      "Training:  31%|███▏      | 554/1772 [01:22<02:25,  8.39it/s, running training loss: 1.1977]\u001b[A\n",
      "Training:  31%|███▏      | 555/1772 [01:22<02:21,  8.59it/s, running training loss: 1.1977]\u001b[A\n",
      "Training:  31%|███▏      | 555/1772 [01:22<02:21,  8.59it/s, running training loss: 1.2886]\u001b[A\n",
      "Training:  31%|███▏      | 556/1772 [01:22<02:30,  8.08it/s, running training loss: 1.2886]\u001b[A\n",
      "Training:  31%|███▏      | 556/1772 [01:22<02:30,  8.08it/s, running training loss: 1.3860]\u001b[A\n",
      "Training:  31%|███▏      | 557/1772 [01:22<02:41,  7.54it/s, running training loss: 1.3860]\u001b[A\n",
      "Training:  31%|███▏      | 557/1772 [01:22<02:41,  7.54it/s, running training loss: 1.2536]\u001b[A\n",
      "Training:  31%|███▏      | 558/1772 [01:22<02:33,  7.89it/s, running training loss: 1.2536]\u001b[A\n",
      "Training:  31%|███▏      | 558/1772 [01:22<02:33,  7.89it/s, running training loss: 1.1859]\u001b[A\n",
      "Training:  32%|███▏      | 559/1772 [01:22<02:37,  7.70it/s, running training loss: 1.1859]\u001b[A\n",
      "Training:  32%|███▏      | 559/1772 [01:22<02:37,  7.70it/s, running training loss: 0.9281]\u001b[A\n",
      "Training:  32%|███▏      | 560/1772 [01:22<02:37,  7.69it/s, running training loss: 0.9281]\u001b[A\n",
      "Training:  32%|███▏      | 560/1772 [01:22<02:37,  7.69it/s, running training loss: 0.9755]\u001b[A\n",
      "Training:  32%|███▏      | 561/1772 [01:22<02:28,  8.15it/s, running training loss: 0.9755]\u001b[A\n",
      "Training:  32%|███▏      | 561/1772 [01:23<02:28,  8.15it/s, running training loss: 1.5371]\u001b[A\n",
      "Training:  32%|███▏      | 562/1772 [01:23<02:51,  7.06it/s, running training loss: 1.5371]\u001b[A\n",
      "Training:  32%|███▏      | 562/1772 [01:23<02:51,  7.06it/s, running training loss: 1.0081]\u001b[A\n",
      "Training:  32%|███▏      | 563/1772 [01:23<03:01,  6.66it/s, running training loss: 1.0081]\u001b[A\n",
      "Training:  32%|███▏      | 563/1772 [01:23<03:01,  6.66it/s, running training loss: 1.1817]\u001b[A\n",
      "Training:  32%|███▏      | 564/1772 [01:23<02:53,  6.97it/s, running training loss: 1.1817]\u001b[A\n",
      "Training:  32%|███▏      | 564/1772 [01:23<02:53,  6.97it/s, running training loss: 1.1547]\u001b[A\n",
      "Training:  32%|███▏      | 565/1772 [01:23<02:45,  7.27it/s, running training loss: 1.1547]\u001b[A\n",
      "Training:  32%|███▏      | 565/1772 [01:23<02:45,  7.27it/s, running training loss: 1.0200]\u001b[A\n",
      "Training:  32%|███▏      | 566/1772 [01:23<02:51,  7.02it/s, running training loss: 1.0200]\u001b[A\n",
      "Training:  32%|███▏      | 566/1772 [01:23<02:51,  7.02it/s, running training loss: 0.9899]\u001b[A\n",
      "Training:  32%|███▏      | 567/1772 [01:23<02:45,  7.26it/s, running training loss: 0.9899]\u001b[A\n",
      "Training:  32%|███▏      | 567/1772 [01:23<02:45,  7.26it/s, running training loss: 1.0049]\u001b[A\n",
      "Training:  32%|███▏      | 568/1772 [01:23<02:41,  7.47it/s, running training loss: 1.0049]\u001b[A\n",
      "Training:  32%|███▏      | 568/1772 [01:24<02:41,  7.47it/s, running training loss: 1.0203]\u001b[A\n",
      "Training:  32%|███▏      | 569/1772 [01:24<02:37,  7.62it/s, running training loss: 1.0203]\u001b[A\n",
      "Training:  32%|███▏      | 569/1772 [01:24<02:37,  7.62it/s, running training loss: 1.0177]\u001b[A\n",
      "Training:  32%|███▏      | 570/1772 [01:24<02:35,  7.75it/s, running training loss: 1.0177]\u001b[A\n",
      "Training:  32%|███▏      | 570/1772 [01:24<02:35,  7.75it/s, running training loss: 0.8806]\u001b[A\n",
      "Training:  32%|███▏      | 571/1772 [01:24<02:34,  7.79it/s, running training loss: 0.8806]\u001b[A\n",
      "Training:  32%|███▏      | 571/1772 [01:24<02:34,  7.79it/s, running training loss: 1.0061]\u001b[A\n",
      "Training:  32%|███▏      | 572/1772 [01:24<02:37,  7.64it/s, running training loss: 1.0061]\u001b[A\n",
      "Training:  32%|███▏      | 572/1772 [01:24<02:37,  7.64it/s, running training loss: 0.9274]\u001b[A\n",
      "Training:  32%|███▏      | 573/1772 [01:24<02:41,  7.43it/s, running training loss: 0.9274]\u001b[A\n",
      "Training:  32%|███▏      | 573/1772 [01:24<02:41,  7.43it/s, running training loss: 0.8850]\u001b[A\n",
      "Training:  32%|███▏      | 574/1772 [01:24<02:43,  7.32it/s, running training loss: 0.8850]\u001b[A\n",
      "Training:  32%|███▏      | 574/1772 [01:24<02:43,  7.32it/s, running training loss: 1.0187]\u001b[A\n",
      "Training:  32%|███▏      | 575/1772 [01:24<02:37,  7.62it/s, running training loss: 1.0187]\u001b[A\n",
      "Training:  32%|███▏      | 575/1772 [01:24<02:37,  7.62it/s, running training loss: 1.1483]\u001b[A\n",
      "Training:  33%|███▎      | 576/1772 [01:24<02:30,  7.93it/s, running training loss: 1.1483]\u001b[A\n",
      "Training:  33%|███▎      | 576/1772 [01:25<02:30,  7.93it/s, running training loss: 1.0981]\u001b[A\n",
      "Training:  33%|███▎      | 577/1772 [01:25<02:32,  7.84it/s, running training loss: 1.0981]\u001b[A\n",
      "Training:  33%|███▎      | 577/1772 [01:25<02:32,  7.84it/s, running training loss: 1.1265]\u001b[A\n",
      "Training:  33%|███▎      | 578/1772 [01:25<02:37,  7.57it/s, running training loss: 1.1265]\u001b[A\n",
      "Training:  33%|███▎      | 578/1772 [01:25<02:37,  7.57it/s, running training loss: 1.0084]\u001b[A\n",
      "Training:  33%|███▎      | 579/1772 [01:25<02:41,  7.39it/s, running training loss: 1.0084]\u001b[A\n",
      "Training:  33%|███▎      | 579/1772 [01:25<02:41,  7.39it/s, running training loss: 1.2372]\u001b[A\n",
      "Training:  33%|███▎      | 580/1772 [01:25<02:34,  7.73it/s, running training loss: 1.2372]\u001b[A\n",
      "Training:  33%|███▎      | 580/1772 [01:25<02:34,  7.73it/s, running training loss: 0.9834]\u001b[A\n",
      "Training:  33%|███▎      | 581/1772 [01:25<02:32,  7.83it/s, running training loss: 0.9834]\u001b[A\n",
      "Training:  33%|███▎      | 581/1772 [01:25<02:32,  7.83it/s, running training loss: 0.9658]\u001b[A\n",
      "Training:  33%|███▎      | 582/1772 [01:25<02:36,  7.63it/s, running training loss: 0.9658]\u001b[A\n",
      "Training:  33%|███▎      | 582/1772 [01:25<02:36,  7.63it/s, running training loss: 0.8826]\u001b[A\n",
      "Training:  33%|███▎      | 583/1772 [01:25<02:29,  7.95it/s, running training loss: 0.8826]\u001b[A\n",
      "Training:  33%|███▎      | 583/1772 [01:26<02:29,  7.95it/s, running training loss: 1.2702]\u001b[A\n",
      "Training:  33%|███▎      | 584/1772 [01:26<02:28,  8.00it/s, running training loss: 1.2702]\u001b[A\n",
      "Training:  33%|███▎      | 584/1772 [01:26<02:28,  8.00it/s, running training loss: 1.0674]\u001b[A\n",
      "Training:  33%|███▎      | 585/1772 [01:26<02:46,  7.12it/s, running training loss: 1.0674]\u001b[A\n",
      "Training:  33%|███▎      | 585/1772 [01:26<02:46,  7.12it/s, running training loss: 0.9118]\u001b[A\n",
      "Training:  33%|███▎      | 586/1772 [01:26<02:41,  7.33it/s, running training loss: 0.9118]\u001b[A\n",
      "Training:  33%|███▎      | 586/1772 [01:26<02:41,  7.33it/s, running training loss: 0.9111]\u001b[A\n",
      "Training:  33%|███▎      | 587/1772 [01:26<02:48,  7.04it/s, running training loss: 0.9111]\u001b[A\n",
      "Training:  33%|███▎      | 587/1772 [01:26<02:48,  7.04it/s, running training loss: 0.9764]\u001b[A\n",
      "Training:  33%|███▎      | 588/1772 [01:26<02:49,  6.99it/s, running training loss: 0.9764]\u001b[A\n",
      "Training:  33%|███▎      | 588/1772 [01:26<02:49,  6.99it/s, running training loss: 0.9062]\u001b[A\n",
      "Training:  33%|███▎      | 589/1772 [01:26<02:48,  7.03it/s, running training loss: 0.9062]\u001b[A\n",
      "Training:  33%|███▎      | 589/1772 [01:26<02:48,  7.03it/s, running training loss: 0.9614]\u001b[A\n",
      "Training:  33%|███▎      | 590/1772 [01:26<02:48,  7.00it/s, running training loss: 0.9614]\u001b[A\n",
      "Training:  33%|███▎      | 590/1772 [01:27<02:48,  7.00it/s, running training loss: 0.9889]\u001b[A\n",
      "Training:  33%|███▎      | 591/1772 [01:27<02:46,  7.08it/s, running training loss: 0.9889]\u001b[A\n",
      "Training:  33%|███▎      | 591/1772 [01:27<02:46,  7.08it/s, running training loss: 1.2361]\u001b[A\n",
      "Training:  33%|███▎      | 592/1772 [01:27<02:41,  7.33it/s, running training loss: 1.2361]\u001b[A\n",
      "Training:  33%|███▎      | 592/1772 [01:27<02:41,  7.33it/s, running training loss: 1.3885]\u001b[A\n",
      "Training:  33%|███▎      | 593/1772 [01:27<03:10,  6.17it/s, running training loss: 1.3885]\u001b[A\n",
      "Training:  33%|███▎      | 593/1772 [01:27<03:10,  6.17it/s, running training loss: 1.3886]\u001b[A\n",
      "Training:  34%|███▎      | 594/1772 [01:27<03:08,  6.26it/s, running training loss: 1.3886]\u001b[A\n",
      "Training:  34%|███▎      | 594/1772 [01:27<03:08,  6.26it/s, running training loss: 1.2031]\u001b[A\n",
      "Training:  34%|███▎      | 595/1772 [01:27<02:59,  6.55it/s, running training loss: 1.2031]\u001b[A\n",
      "Training:  34%|███▎      | 595/1772 [01:27<02:59,  6.55it/s, running training loss: 0.9064]\u001b[A\n",
      "Training:  34%|███▎      | 596/1772 [01:27<02:51,  6.88it/s, running training loss: 0.9064]\u001b[A\n",
      "Training:  34%|███▎      | 596/1772 [01:27<02:51,  6.88it/s, running training loss: 1.1141]\u001b[A\n",
      "Training:  34%|███▎      | 597/1772 [01:27<02:38,  7.43it/s, running training loss: 1.1141]\u001b[A\n",
      "Training:  34%|███▎      | 597/1772 [01:28<02:38,  7.43it/s, running training loss: 1.0934]\u001b[A\n",
      "Training:  34%|███▎      | 598/1772 [01:28<02:34,  7.62it/s, running training loss: 1.0934]\u001b[A\n",
      "Training:  34%|███▎      | 598/1772 [01:28<02:34,  7.62it/s, running training loss: 1.0073]\u001b[A\n",
      "Training:  34%|███▍      | 599/1772 [01:28<02:52,  6.79it/s, running training loss: 1.0073]\u001b[A\n",
      "Training:  34%|███▍      | 599/1772 [01:28<02:52,  6.79it/s, running training loss: 1.1921]\u001b[A\n",
      "Training:  34%|███▍      | 600/1772 [01:28<02:43,  7.17it/s, running training loss: 1.1921]\u001b[A\n",
      "Training:  34%|███▍      | 600/1772 [01:28<02:43,  7.17it/s, running training loss: 1.1881]\u001b[A\n",
      "Training:  34%|███▍      | 601/1772 [01:28<02:38,  7.41it/s, running training loss: 1.1881]\u001b[A\n",
      "Training:  34%|███▍      | 601/1772 [01:28<02:38,  7.41it/s, running training loss: 1.5472]\u001b[A\n",
      "Training:  34%|███▍      | 602/1772 [01:28<02:30,  7.80it/s, running training loss: 1.5472]\u001b[A\n",
      "Training:  34%|███▍      | 602/1772 [01:28<02:30,  7.80it/s, running training loss: 1.1821]\u001b[A\n",
      "Training:  34%|███▍      | 603/1772 [01:28<02:24,  8.10it/s, running training loss: 1.1821]\u001b[A\n",
      "Training:  34%|███▍      | 603/1772 [01:28<02:24,  8.10it/s, running training loss: 0.8712]\u001b[A\n",
      "Training:  34%|███▍      | 604/1772 [01:28<02:23,  8.15it/s, running training loss: 0.8712]\u001b[A\n",
      "Training:  34%|███▍      | 604/1772 [01:28<02:23,  8.15it/s, running training loss: 1.0217]\u001b[A\n",
      "Training:  34%|███▍      | 605/1772 [01:28<02:25,  8.02it/s, running training loss: 1.0217]\u001b[A\n",
      "Training:  34%|███▍      | 605/1772 [01:29<02:25,  8.02it/s, running training loss: 0.9729]\u001b[A\n",
      "Training:  34%|███▍      | 606/1772 [01:29<02:40,  7.29it/s, running training loss: 0.9729]\u001b[A\n",
      "Training:  34%|███▍      | 606/1772 [01:29<02:40,  7.29it/s, running training loss: 1.0017]\u001b[A\n",
      "Training:  34%|███▍      | 607/1772 [01:29<02:40,  7.26it/s, running training loss: 1.0017]\u001b[A\n",
      "Training:  34%|███▍      | 607/1772 [01:29<02:40,  7.26it/s, running training loss: 1.0310]\u001b[A\n",
      "Training:  34%|███▍      | 608/1772 [01:29<02:42,  7.15it/s, running training loss: 1.0310]\u001b[A\n",
      "Training:  34%|███▍      | 608/1772 [01:29<02:42,  7.15it/s, running training loss: 1.2296]\u001b[A\n",
      "Training:  34%|███▍      | 609/1772 [01:29<02:39,  7.28it/s, running training loss: 1.2296]\u001b[A\n",
      "Training:  34%|███▍      | 609/1772 [01:29<02:39,  7.28it/s, running training loss: 0.8916]\u001b[A\n",
      "Training:  34%|███▍      | 610/1772 [01:29<02:42,  7.15it/s, running training loss: 0.8916]\u001b[A\n",
      "Training:  34%|███▍      | 610/1772 [01:29<02:42,  7.15it/s, running training loss: 0.9652]\u001b[A\n",
      "Training:  34%|███▍      | 611/1772 [01:29<02:49,  6.84it/s, running training loss: 0.9652]\u001b[A\n",
      "Training:  34%|███▍      | 611/1772 [01:29<02:49,  6.84it/s, running training loss: 0.9570]\u001b[A\n",
      "Training:  35%|███▍      | 612/1772 [01:29<02:37,  7.34it/s, running training loss: 0.9570]\u001b[A\n",
      "Training:  35%|███▍      | 612/1772 [01:30<02:37,  7.34it/s, running training loss: 1.1777]\u001b[A\n",
      "Training:  35%|███▍      | 613/1772 [01:30<02:39,  7.29it/s, running training loss: 1.1777]\u001b[A\n",
      "Training:  35%|███▍      | 613/1772 [01:30<02:39,  7.29it/s, running training loss: 1.1043]\u001b[A\n",
      "Training:  35%|███▍      | 614/1772 [01:30<02:42,  7.12it/s, running training loss: 1.1043]\u001b[A\n",
      "Training:  35%|███▍      | 614/1772 [01:30<02:42,  7.12it/s, running training loss: 0.9938]\u001b[A\n",
      "Training:  35%|███▍      | 615/1772 [01:30<02:52,  6.70it/s, running training loss: 0.9938]\u001b[A\n",
      "Training:  35%|███▍      | 615/1772 [01:30<02:52,  6.70it/s, running training loss: 1.2386]\u001b[A\n",
      "Training:  35%|███▍      | 616/1772 [01:30<02:57,  6.50it/s, running training loss: 1.2386]\u001b[A\n",
      "Training:  35%|███▍      | 616/1772 [01:30<02:57,  6.50it/s, running training loss: 1.0033]\u001b[A\n",
      "Training:  35%|███▍      | 617/1772 [01:30<02:48,  6.86it/s, running training loss: 1.0033]\u001b[A\n",
      "Training:  35%|███▍      | 617/1772 [01:30<02:48,  6.86it/s, running training loss: 1.0386]\u001b[A\n",
      "Training:  35%|███▍      | 618/1772 [01:30<02:59,  6.42it/s, running training loss: 1.0386]\u001b[A\n",
      "Training:  35%|███▍      | 618/1772 [01:30<02:59,  6.42it/s, running training loss: 0.8944]\u001b[A\n",
      "Training:  35%|███▍      | 619/1772 [01:30<02:49,  6.79it/s, running training loss: 0.8944]\u001b[A\n",
      "Training:  35%|███▍      | 619/1772 [01:31<02:49,  6.79it/s, running training loss: 0.8888]\u001b[A\n",
      "Training:  35%|███▍      | 620/1772 [01:31<02:37,  7.32it/s, running training loss: 0.8888]\u001b[A\n",
      "Training:  35%|███▍      | 620/1772 [01:31<02:37,  7.32it/s, running training loss: 0.9923]\u001b[A\n",
      "Training:  35%|███▌      | 621/1772 [01:31<02:32,  7.56it/s, running training loss: 0.9923]\u001b[A\n",
      "Training:  35%|███▌      | 621/1772 [01:31<02:32,  7.56it/s, running training loss: 1.7073]\u001b[A\n",
      "Training:  35%|███▌      | 622/1772 [01:31<02:29,  7.71it/s, running training loss: 1.7073]\u001b[A\n",
      "Training:  35%|███▌      | 622/1772 [01:31<02:29,  7.71it/s, running training loss: 0.8667]\u001b[A\n",
      "Training:  35%|███▌      | 623/1772 [01:31<02:24,  7.98it/s, running training loss: 0.8667]\u001b[A\n",
      "Training:  35%|███▌      | 623/1772 [01:31<02:24,  7.98it/s, running training loss: 0.9380]\u001b[A\n",
      "Training:  35%|███▌      | 624/1772 [01:31<02:23,  7.99it/s, running training loss: 0.9380]\u001b[A\n",
      "Training:  35%|███▌      | 624/1772 [01:31<02:23,  7.99it/s, running training loss: 1.0174]\u001b[A\n",
      "Training:  35%|███▌      | 625/1772 [01:31<02:44,  6.97it/s, running training loss: 1.0174]\u001b[A\n",
      "Training:  35%|███▌      | 625/1772 [01:31<02:44,  6.97it/s, running training loss: 1.0948]\u001b[A\n",
      "Training:  35%|███▌      | 626/1772 [01:31<03:04,  6.22it/s, running training loss: 1.0948]\u001b[A\n",
      "Training:  35%|███▌      | 626/1772 [01:32<03:04,  6.22it/s, running training loss: 1.1601]\u001b[A\n",
      "Training:  35%|███▌      | 627/1772 [01:32<02:52,  6.66it/s, running training loss: 1.1601]\u001b[A\n",
      "Training:  35%|███▌      | 627/1772 [01:32<02:52,  6.66it/s, running training loss: 1.3917]\u001b[A\n",
      "Training:  35%|███▌      | 628/1772 [01:32<02:43,  7.02it/s, running training loss: 1.3917]\u001b[A\n",
      "Training:  35%|███▌      | 628/1772 [01:32<02:43,  7.02it/s, running training loss: 1.0722]\u001b[A\n",
      "Training:  35%|███▌      | 629/1772 [01:32<02:37,  7.25it/s, running training loss: 1.0722]\u001b[A\n",
      "Training:  35%|███▌      | 629/1772 [01:32<02:37,  7.25it/s, running training loss: 1.0081]\u001b[A\n",
      "Training:  36%|███▌      | 630/1772 [01:32<02:31,  7.53it/s, running training loss: 1.0081]\u001b[A\n",
      "Training:  36%|███▌      | 630/1772 [01:32<02:31,  7.53it/s, running training loss: 0.9875]\u001b[A\n",
      "Training:  36%|███▌      | 631/1772 [01:32<02:28,  7.67it/s, running training loss: 0.9875]\u001b[A\n",
      "Training:  36%|███▌      | 631/1772 [01:32<02:28,  7.67it/s, running training loss: 0.9045]\u001b[A\n",
      "Training:  36%|███▌      | 632/1772 [01:32<02:36,  7.29it/s, running training loss: 0.9045]\u001b[A\n",
      "Training:  36%|███▌      | 632/1772 [01:32<02:36,  7.29it/s, running training loss: 1.2212]\u001b[A\n",
      "Training:  36%|███▌      | 633/1772 [01:32<02:57,  6.41it/s, running training loss: 1.2212]\u001b[A\n",
      "Training:  36%|███▌      | 633/1772 [01:33<02:57,  6.41it/s, running training loss: 0.9614]\u001b[A\n",
      "Training:  36%|███▌      | 634/1772 [01:33<02:50,  6.69it/s, running training loss: 0.9614]\u001b[A\n",
      "Training:  36%|███▌      | 634/1772 [01:33<02:50,  6.69it/s, running training loss: 1.0503]\u001b[A\n",
      "Training:  36%|███▌      | 635/1772 [01:33<02:37,  7.20it/s, running training loss: 1.0503]\u001b[A\n",
      "Training:  36%|███▌      | 635/1772 [01:33<02:37,  7.20it/s, running training loss: 0.9469]\u001b[A\n",
      "Training:  36%|███▌      | 636/1772 [01:33<02:38,  7.19it/s, running training loss: 0.9469]\u001b[A\n",
      "Training:  36%|███▌      | 636/1772 [01:33<02:38,  7.19it/s, running training loss: 0.9530]\u001b[A\n",
      "Training:  36%|███▌      | 637/1772 [01:33<02:34,  7.33it/s, running training loss: 0.9530]\u001b[A\n",
      "Training:  36%|███▌      | 637/1772 [01:33<02:34,  7.33it/s, running training loss: 0.9555]\u001b[A\n",
      "Training:  36%|███▌      | 638/1772 [01:33<02:27,  7.71it/s, running training loss: 0.9555]\u001b[A\n",
      "Training:  36%|███▌      | 638/1772 [01:33<02:27,  7.71it/s, running training loss: 1.1088]\u001b[A\n",
      "Training:  36%|███▌      | 639/1772 [01:33<02:19,  8.12it/s, running training loss: 1.1088]\u001b[A\n",
      "Training:  36%|███▌      | 639/1772 [01:33<02:19,  8.12it/s, running training loss: 1.0815]\u001b[A\n",
      "Training:  36%|███▌      | 640/1772 [01:33<02:16,  8.31it/s, running training loss: 1.0815]\u001b[A\n",
      "Training:  36%|███▌      | 640/1772 [01:33<02:16,  8.31it/s, running training loss: 0.8154]\u001b[A\n",
      "Training:  36%|███▌      | 641/1772 [01:33<02:19,  8.10it/s, running training loss: 0.8154]\u001b[A\n",
      "Training:  36%|███▌      | 641/1772 [01:34<02:19,  8.10it/s, running training loss: 1.0390]\u001b[A\n",
      "Training:  36%|███▌      | 642/1772 [01:34<02:16,  8.28it/s, running training loss: 1.0390]\u001b[A\n",
      "Training:  36%|███▌      | 642/1772 [01:34<02:16,  8.28it/s, running training loss: 1.0624]\u001b[A\n",
      "Training:  36%|███▋      | 643/1772 [01:34<02:18,  8.15it/s, running training loss: 1.0624]\u001b[A\n",
      "Training:  36%|███▋      | 643/1772 [01:34<02:18,  8.15it/s, running training loss: 0.9141]\u001b[A\n",
      "Training:  36%|███▋      | 644/1772 [01:34<02:17,  8.18it/s, running training loss: 0.9141]\u001b[A\n",
      "Training:  36%|███▋      | 644/1772 [01:34<02:17,  8.18it/s, running training loss: 0.9354]\u001b[A\n",
      "Training:  36%|███▋      | 645/1772 [01:34<02:17,  8.18it/s, running training loss: 0.9354]\u001b[A\n",
      "Training:  36%|███▋      | 645/1772 [01:34<02:17,  8.18it/s, running training loss: 0.9571]\u001b[A\n",
      "Training:  36%|███▋      | 646/1772 [01:34<02:14,  8.35it/s, running training loss: 0.9571]\u001b[A\n",
      "Training:  36%|███▋      | 646/1772 [01:34<02:14,  8.35it/s, running training loss: 1.2788]\u001b[A\n",
      "Training:  37%|███▋      | 647/1772 [01:34<02:22,  7.88it/s, running training loss: 1.2788]\u001b[A\n",
      "Training:  37%|███▋      | 647/1772 [01:34<02:22,  7.88it/s, running training loss: 0.9970]\u001b[A\n",
      "Training:  37%|███▋      | 648/1772 [01:34<02:33,  7.34it/s, running training loss: 0.9970]\u001b[A\n",
      "Training:  37%|███▋      | 648/1772 [01:34<02:33,  7.34it/s, running training loss: 0.9352]\u001b[A\n",
      "Training:  37%|███▋      | 649/1772 [01:34<02:29,  7.50it/s, running training loss: 0.9352]\u001b[A\n",
      "Training:  37%|███▋      | 649/1772 [01:35<02:29,  7.50it/s, running training loss: 1.0097]\u001b[A\n",
      "Training:  37%|███▋      | 650/1772 [01:35<02:46,  6.73it/s, running training loss: 1.0097]\u001b[A\n",
      "Training:  37%|███▋      | 650/1772 [01:35<02:46,  6.73it/s, running training loss: 1.0768]\u001b[A\n",
      "Training:  37%|███▋      | 651/1772 [01:35<02:44,  6.81it/s, running training loss: 1.0768]\u001b[A\n",
      "Training:  37%|███▋      | 651/1772 [01:35<02:44,  6.81it/s, running training loss: 0.9919]\u001b[A\n",
      "Training:  37%|███▋      | 652/1772 [01:35<02:37,  7.13it/s, running training loss: 0.9919]\u001b[A\n",
      "Training:  37%|███▋      | 652/1772 [01:35<02:37,  7.13it/s, running training loss: 1.0661]\u001b[A\n",
      "Training:  37%|███▋      | 653/1772 [01:35<02:37,  7.09it/s, running training loss: 1.0661]\u001b[A\n",
      "Training:  37%|███▋      | 653/1772 [01:35<02:37,  7.09it/s, running training loss: 0.9817]\u001b[A\n",
      "Training:  37%|███▋      | 654/1772 [01:35<02:52,  6.47it/s, running training loss: 0.9817]\u001b[A\n",
      "Training:  37%|███▋      | 654/1772 [01:35<02:52,  6.47it/s, running training loss: 0.8522]\u001b[A\n",
      "Training:  37%|███▋      | 655/1772 [01:35<02:52,  6.48it/s, running training loss: 0.8522]\u001b[A\n",
      "Training:  37%|███▋      | 655/1772 [01:36<02:52,  6.48it/s, running training loss: 1.0490]\u001b[A\n",
      "Training:  37%|███▋      | 656/1772 [01:36<02:45,  6.75it/s, running training loss: 1.0490]\u001b[A\n",
      "Training:  37%|███▋      | 656/1772 [01:36<02:45,  6.75it/s, running training loss: 0.9346]\u001b[A\n",
      "Training:  37%|███▋      | 657/1772 [01:36<02:41,  6.91it/s, running training loss: 0.9346]\u001b[A\n",
      "Training:  37%|███▋      | 657/1772 [01:36<02:41,  6.91it/s, running training loss: 1.1818]\u001b[A\n",
      "Training:  37%|███▋      | 658/1772 [01:36<02:59,  6.22it/s, running training loss: 1.1818]\u001b[A\n",
      "Training:  37%|███▋      | 658/1772 [01:36<02:59,  6.22it/s, running training loss: 1.1430]\u001b[A\n",
      "Training:  37%|███▋      | 659/1772 [01:36<02:54,  6.38it/s, running training loss: 1.1430]\u001b[A\n",
      "Training:  37%|███▋      | 659/1772 [01:36<02:54,  6.38it/s, running training loss: 1.3868]\u001b[A\n",
      "Training:  37%|███▋      | 660/1772 [01:36<02:44,  6.76it/s, running training loss: 1.3868]\u001b[A\n",
      "Training:  37%|███▋      | 660/1772 [01:36<02:44,  6.76it/s, running training loss: 1.3470]\u001b[A\n",
      "Training:  37%|███▋      | 661/1772 [01:36<02:29,  7.41it/s, running training loss: 1.3470]\u001b[A\n",
      "Training:  37%|███▋      | 661/1772 [01:36<02:29,  7.41it/s, running training loss: 0.9181]\u001b[A\n",
      "Training:  37%|███▋      | 662/1772 [01:36<02:26,  7.59it/s, running training loss: 0.9181]\u001b[A\n",
      "Training:  37%|███▋      | 662/1772 [01:36<02:26,  7.59it/s, running training loss: 1.3173]\u001b[A\n",
      "Training:  37%|███▋      | 663/1772 [01:36<02:20,  7.91it/s, running training loss: 1.3173]\u001b[A\n",
      "Training:  37%|███▋      | 663/1772 [01:37<02:20,  7.91it/s, running training loss: 0.9255]\u001b[A\n",
      "Training:  37%|███▋      | 664/1772 [01:37<02:34,  7.18it/s, running training loss: 0.9255]\u001b[A\n",
      "Training:  37%|███▋      | 664/1772 [01:37<02:34,  7.18it/s, running training loss: 1.5826]\u001b[A\n",
      "Training:  38%|███▊      | 665/1772 [01:37<02:29,  7.39it/s, running training loss: 1.5826]\u001b[A\n",
      "Training:  38%|███▊      | 665/1772 [01:37<02:29,  7.39it/s, running training loss: 1.0554]\u001b[A\n",
      "Training:  38%|███▊      | 666/1772 [01:37<02:26,  7.56it/s, running training loss: 1.0554]\u001b[A\n",
      "Training:  38%|███▊      | 666/1772 [01:37<02:26,  7.56it/s, running training loss: 1.0786]\u001b[A\n",
      "Training:  38%|███▊      | 667/1772 [01:37<02:33,  7.19it/s, running training loss: 1.0786]\u001b[A\n",
      "Training:  38%|███▊      | 667/1772 [01:37<02:33,  7.19it/s, running training loss: 0.9183]\u001b[A\n",
      "Training:  38%|███▊      | 668/1772 [01:37<02:34,  7.16it/s, running training loss: 0.9183]\u001b[A\n",
      "Training:  38%|███▊      | 668/1772 [01:37<02:34,  7.16it/s, running training loss: 0.8707]\u001b[A\n",
      "Training:  38%|███▊      | 669/1772 [01:37<02:31,  7.30it/s, running training loss: 0.8707]\u001b[A\n",
      "Training:  38%|███▊      | 669/1772 [01:37<02:31,  7.30it/s, running training loss: 1.0177]\u001b[A\n",
      "Training:  38%|███▊      | 670/1772 [01:37<02:24,  7.65it/s, running training loss: 1.0177]\u001b[A\n",
      "Training:  38%|███▊      | 670/1772 [01:38<02:24,  7.65it/s, running training loss: 0.8676]\u001b[A\n",
      "Training:  38%|███▊      | 671/1772 [01:38<02:22,  7.71it/s, running training loss: 0.8676]\u001b[A\n",
      "Training:  38%|███▊      | 671/1772 [01:38<02:22,  7.71it/s, running training loss: 1.1697]\u001b[A\n",
      "Training:  38%|███▊      | 672/1772 [01:38<02:20,  7.82it/s, running training loss: 1.1697]\u001b[A\n",
      "Training:  38%|███▊      | 672/1772 [01:38<02:20,  7.82it/s, running training loss: 1.0199]\u001b[A\n",
      "Training:  38%|███▊      | 673/1772 [01:38<02:35,  7.09it/s, running training loss: 1.0199]\u001b[A\n",
      "Training:  38%|███▊      | 673/1772 [01:38<02:35,  7.09it/s, running training loss: 1.1164]\u001b[A\n",
      "Training:  38%|███▊      | 674/1772 [01:38<02:29,  7.37it/s, running training loss: 1.1164]\u001b[A\n",
      "Training:  38%|███▊      | 674/1772 [01:38<02:29,  7.37it/s, running training loss: 1.0403]\u001b[A\n",
      "Training:  38%|███▊      | 675/1772 [01:38<02:24,  7.59it/s, running training loss: 1.0403]\u001b[A\n",
      "Training:  38%|███▊      | 675/1772 [01:38<02:24,  7.59it/s, running training loss: 0.8474]\u001b[A\n",
      "Training:  38%|███▊      | 676/1772 [01:38<02:18,  7.90it/s, running training loss: 0.8474]\u001b[A\n",
      "Training:  38%|███▊      | 676/1772 [01:38<02:18,  7.90it/s, running training loss: 0.9447]\u001b[A\n",
      "Training:  38%|███▊      | 677/1772 [01:38<02:17,  7.98it/s, running training loss: 0.9447]\u001b[A\n",
      "Training:  38%|███▊      | 677/1772 [01:39<02:17,  7.98it/s, running training loss: 1.0196]\u001b[A\n",
      "Training:  38%|███▊      | 678/1772 [01:39<02:28,  7.36it/s, running training loss: 1.0196]\u001b[A\n",
      "Training:  38%|███▊      | 678/1772 [01:39<02:28,  7.36it/s, running training loss: 0.8872]\u001b[A\n",
      "Training:  38%|███▊      | 679/1772 [01:39<02:41,  6.78it/s, running training loss: 0.8872]\u001b[A\n",
      "Training:  38%|███▊      | 679/1772 [01:39<02:41,  6.78it/s, running training loss: 1.1363]\u001b[A\n",
      "Training:  38%|███▊      | 680/1772 [01:39<02:29,  7.30it/s, running training loss: 1.1363]\u001b[A\n",
      "Training:  38%|███▊      | 680/1772 [01:39<02:29,  7.30it/s, running training loss: 1.0297]\u001b[A\n",
      "Training:  38%|███▊      | 681/1772 [01:39<02:30,  7.27it/s, running training loss: 1.0297]\u001b[A\n",
      "Training:  38%|███▊      | 681/1772 [01:39<02:30,  7.27it/s, running training loss: 1.0261]\u001b[A\n",
      "Training:  38%|███▊      | 682/1772 [01:39<02:24,  7.52it/s, running training loss: 1.0261]\u001b[A\n",
      "Training:  38%|███▊      | 682/1772 [01:39<02:24,  7.52it/s, running training loss: 1.3817]\u001b[A\n",
      "Training:  39%|███▊      | 683/1772 [01:39<02:42,  6.70it/s, running training loss: 1.3817]\u001b[A\n",
      "Training:  39%|███▊      | 683/1772 [01:39<02:42,  6.70it/s, running training loss: 0.9793]\u001b[A\n",
      "Training:  39%|███▊      | 684/1772 [01:39<02:37,  6.89it/s, running training loss: 0.9793]\u001b[A\n",
      "Training:  39%|███▊      | 684/1772 [01:40<02:37,  6.89it/s, running training loss: 0.8804]\u001b[A\n",
      "Training:  39%|███▊      | 685/1772 [01:40<02:48,  6.43it/s, running training loss: 0.8804]\u001b[A\n",
      "Training:  39%|███▊      | 685/1772 [01:40<02:48,  6.43it/s, running training loss: 0.9998]\u001b[A\n",
      "Training:  39%|███▊      | 686/1772 [01:40<02:37,  6.90it/s, running training loss: 0.9998]\u001b[A\n",
      "Training:  39%|███▊      | 686/1772 [01:40<02:37,  6.90it/s, running training loss: 0.9708]\u001b[A\n",
      "Training:  39%|███▉      | 687/1772 [01:40<02:39,  6.80it/s, running training loss: 0.9708]\u001b[A\n",
      "Training:  39%|███▉      | 687/1772 [01:40<02:39,  6.80it/s, running training loss: 1.2728]\u001b[A\n",
      "Training:  39%|███▉      | 688/1772 [01:40<02:41,  6.72it/s, running training loss: 1.2728]\u001b[A\n",
      "Training:  39%|███▉      | 688/1772 [01:40<02:41,  6.72it/s, running training loss: 1.1907]\u001b[A\n",
      "Training:  39%|███▉      | 689/1772 [01:40<02:32,  7.12it/s, running training loss: 1.1907]\u001b[A\n",
      "Training:  39%|███▉      | 689/1772 [01:40<02:32,  7.12it/s, running training loss: 1.1399]\u001b[A\n",
      "Training:  39%|███▉      | 690/1772 [01:40<02:30,  7.18it/s, running training loss: 1.1399]\u001b[A\n",
      "Training:  39%|███▉      | 690/1772 [01:40<02:30,  7.18it/s, running training loss: 0.9105]\u001b[A\n",
      "Training:  39%|███▉      | 691/1772 [01:40<02:22,  7.60it/s, running training loss: 0.9105]\u001b[A\n",
      "Training:  39%|███▉      | 691/1772 [01:40<02:22,  7.60it/s, running training loss: 1.0928]\u001b[A\n",
      "Training:  39%|███▉      | 692/1772 [01:40<02:18,  7.80it/s, running training loss: 1.0928]\u001b[A\n",
      "Training:  39%|███▉      | 692/1772 [01:41<02:18,  7.80it/s, running training loss: 1.0851]\u001b[A\n",
      "Training:  39%|███▉      | 693/1772 [01:41<02:12,  8.14it/s, running training loss: 1.0851]\u001b[A\n",
      "Training:  39%|███▉      | 693/1772 [01:41<02:12,  8.14it/s, running training loss: 1.1336]\u001b[A\n",
      "Training:  39%|███▉      | 694/1772 [01:41<02:07,  8.46it/s, running training loss: 1.1336]\u001b[A\n",
      "Training:  39%|███▉      | 694/1772 [01:41<02:07,  8.46it/s, running training loss: 0.8789]\u001b[A\n",
      "Training:  39%|███▉      | 695/1772 [01:41<02:19,  7.74it/s, running training loss: 0.8789]\u001b[A\n",
      "Training:  39%|███▉      | 695/1772 [01:41<02:19,  7.74it/s, running training loss: 0.9990]\u001b[A\n",
      "Training:  39%|███▉      | 696/1772 [01:41<02:24,  7.46it/s, running training loss: 0.9990]\u001b[A\n",
      "Training:  39%|███▉      | 696/1772 [01:41<02:24,  7.46it/s, running training loss: 0.9925]\u001b[A\n",
      "Training:  39%|███▉      | 697/1772 [01:41<02:20,  7.67it/s, running training loss: 0.9925]\u001b[A\n",
      "Training:  39%|███▉      | 697/1772 [01:41<02:20,  7.67it/s, running training loss: 1.0003]\u001b[A\n",
      "Training:  39%|███▉      | 698/1772 [01:41<02:19,  7.68it/s, running training loss: 1.0003]\u001b[A\n",
      "Training:  39%|███▉      | 698/1772 [01:41<02:19,  7.68it/s, running training loss: 0.9119]\u001b[A\n",
      "Training:  39%|███▉      | 699/1772 [01:41<02:15,  7.89it/s, running training loss: 0.9119]\u001b[A\n",
      "Training:  39%|███▉      | 699/1772 [01:41<02:15,  7.89it/s, running training loss: 1.0483]\u001b[A\n",
      "Training:  40%|███▉      | 700/1772 [01:41<02:13,  8.01it/s, running training loss: 1.0483]\u001b[A\n",
      "Training:  40%|███▉      | 700/1772 [01:42<02:13,  8.01it/s, running training loss: 0.9373]\u001b[A\n",
      "Training:  40%|███▉      | 701/1772 [01:42<02:10,  8.19it/s, running training loss: 0.9373]\u001b[A\n",
      "Training:  40%|███▉      | 701/1772 [01:42<02:10,  8.19it/s, running training loss: 0.8959]\u001b[A\n",
      "Training:  40%|███▉      | 702/1772 [01:42<02:17,  7.77it/s, running training loss: 0.8959]\u001b[A\n",
      "Training:  40%|███▉      | 702/1772 [01:42<02:17,  7.77it/s, running training loss: 0.9467]\u001b[A\n",
      "Training:  40%|███▉      | 703/1772 [01:42<02:29,  7.17it/s, running training loss: 0.9467]\u001b[A\n",
      "Training:  40%|███▉      | 703/1772 [01:42<02:29,  7.17it/s, running training loss: 0.9205]\u001b[A\n",
      "Training:  40%|███▉      | 704/1772 [01:42<02:35,  6.89it/s, running training loss: 0.9205]\u001b[A\n",
      "Training:  40%|███▉      | 704/1772 [01:42<02:35,  6.89it/s, running training loss: 1.0432]\u001b[A\n",
      "Training:  40%|███▉      | 705/1772 [01:42<02:35,  6.87it/s, running training loss: 1.0432]\u001b[A\n",
      "Training:  40%|███▉      | 705/1772 [01:42<02:35,  6.87it/s, running training loss: 1.0242]\u001b[A\n",
      "Training:  40%|███▉      | 706/1772 [01:42<02:29,  7.13it/s, running training loss: 1.0242]\u001b[A\n",
      "Training:  40%|███▉      | 706/1772 [01:42<02:29,  7.13it/s, running training loss: 0.9554]\u001b[A\n",
      "Training:  40%|███▉      | 707/1772 [01:42<02:24,  7.36it/s, running training loss: 0.9554]\u001b[A\n",
      "Training:  40%|███▉      | 707/1772 [01:43<02:24,  7.36it/s, running training loss: 0.9533]\u001b[A\n",
      "Training:  40%|███▉      | 708/1772 [01:43<02:20,  7.57it/s, running training loss: 0.9533]\u001b[A\n",
      "Training:  40%|███▉      | 708/1772 [01:43<02:20,  7.57it/s, running training loss: 1.1439]\u001b[A\n",
      "Training:  40%|████      | 709/1772 [01:43<02:23,  7.40it/s, running training loss: 1.1439]\u001b[A\n",
      "Training:  40%|████      | 709/1772 [01:43<02:23,  7.40it/s, running training loss: 0.9562]\u001b[A\n",
      "Training:  40%|████      | 710/1772 [01:43<02:21,  7.52it/s, running training loss: 0.9562]\u001b[A\n",
      "Training:  40%|████      | 710/1772 [01:43<02:21,  7.52it/s, running training loss: 0.9942]\u001b[A\n",
      "Training:  40%|████      | 711/1772 [01:43<02:12,  8.01it/s, running training loss: 0.9942]\u001b[A\n",
      "Training:  40%|████      | 711/1772 [01:43<02:12,  8.01it/s, running training loss: 1.1429]\u001b[A\n",
      "Training:  40%|████      | 712/1772 [01:43<02:12,  8.01it/s, running training loss: 1.1429]\u001b[A\n",
      "Training:  40%|████      | 712/1772 [01:43<02:12,  8.01it/s, running training loss: 0.9299]\u001b[A\n",
      "Training:  40%|████      | 713/1772 [01:43<02:09,  8.17it/s, running training loss: 0.9299]\u001b[A\n",
      "Training:  40%|████      | 713/1772 [01:43<02:09,  8.17it/s, running training loss: 0.8678]\u001b[A\n",
      "Training:  40%|████      | 714/1772 [01:43<02:19,  7.59it/s, running training loss: 0.8678]\u001b[A\n",
      "Training:  40%|████      | 714/1772 [01:44<02:19,  7.59it/s, running training loss: 1.3752]\u001b[A\n",
      "Training:  40%|████      | 715/1772 [01:44<02:23,  7.36it/s, running training loss: 1.3752]\u001b[A\n",
      "Training:  40%|████      | 715/1772 [01:44<02:23,  7.36it/s, running training loss: 0.9136]\u001b[A\n",
      "Training:  40%|████      | 716/1772 [01:44<02:22,  7.39it/s, running training loss: 0.9136]\u001b[A\n",
      "Training:  40%|████      | 716/1772 [01:44<02:22,  7.39it/s, running training loss: 0.9643]\u001b[A\n",
      "Training:  40%|████      | 717/1772 [01:44<02:20,  7.51it/s, running training loss: 0.9643]\u001b[A\n",
      "Training:  40%|████      | 717/1772 [01:44<02:20,  7.51it/s, running training loss: 1.8082]\u001b[A\n",
      "Training:  41%|████      | 718/1772 [01:44<02:16,  7.74it/s, running training loss: 1.8082]\u001b[A\n",
      "Training:  41%|████      | 718/1772 [01:44<02:16,  7.74it/s, running training loss: 1.0064]\u001b[A\n",
      "Training:  41%|████      | 719/1772 [01:44<02:11,  8.03it/s, running training loss: 1.0064]\u001b[A\n",
      "Training:  41%|████      | 719/1772 [01:44<02:11,  8.03it/s, running training loss: 1.0094]\u001b[A\n",
      "Training:  41%|████      | 720/1772 [01:44<02:13,  7.90it/s, running training loss: 1.0094]\u001b[A\n",
      "Training:  41%|████      | 720/1772 [01:44<02:13,  7.90it/s, running training loss: 0.9092]\u001b[A\n",
      "Training:  41%|████      | 721/1772 [01:44<02:14,  7.82it/s, running training loss: 0.9092]\u001b[A\n",
      "Training:  41%|████      | 721/1772 [01:44<02:14,  7.82it/s, running training loss: 1.1648]\u001b[A\n",
      "Training:  41%|████      | 722/1772 [01:44<02:16,  7.71it/s, running training loss: 1.1648]\u001b[A\n",
      "Training:  41%|████      | 722/1772 [01:45<02:16,  7.71it/s, running training loss: 0.9692]\u001b[A\n",
      "Training:  41%|████      | 723/1772 [01:45<02:26,  7.18it/s, running training loss: 0.9692]\u001b[A\n",
      "Training:  41%|████      | 723/1772 [01:45<02:26,  7.18it/s, running training loss: 0.8571]\u001b[A\n",
      "Training:  41%|████      | 724/1772 [01:45<02:24,  7.25it/s, running training loss: 0.8571]\u001b[A\n",
      "Training:  41%|████      | 724/1772 [01:45<02:24,  7.25it/s, running training loss: 0.8418]\u001b[A\n",
      "Training:  41%|████      | 725/1772 [01:45<02:17,  7.61it/s, running training loss: 0.8418]\u001b[A\n",
      "Training:  41%|████      | 725/1772 [01:45<02:17,  7.61it/s, running training loss: 0.8715]\u001b[A\n",
      "Training:  41%|████      | 726/1772 [01:45<02:24,  7.25it/s, running training loss: 0.8715]\u001b[A\n",
      "Training:  41%|████      | 726/1772 [01:45<02:24,  7.25it/s, running training loss: 1.0733]\u001b[A\n",
      "Training:  41%|████      | 727/1772 [01:45<02:35,  6.72it/s, running training loss: 1.0733]\u001b[A\n",
      "Training:  41%|████      | 727/1772 [01:45<02:35,  6.72it/s, running training loss: 1.3705]\u001b[A\n",
      "Training:  41%|████      | 728/1772 [01:45<02:33,  6.78it/s, running training loss: 1.3705]\u001b[A\n",
      "Training:  41%|████      | 728/1772 [01:45<02:33,  6.78it/s, running training loss: 0.8312]\u001b[A\n",
      "Training:  41%|████      | 729/1772 [01:45<02:31,  6.89it/s, running training loss: 0.8312]\u001b[A\n",
      "Training:  41%|████      | 729/1772 [01:46<02:31,  6.89it/s, running training loss: 1.0478]\u001b[A\n",
      "Training:  41%|████      | 730/1772 [01:46<02:24,  7.19it/s, running training loss: 1.0478]\u001b[A\n",
      "Training:  41%|████      | 730/1772 [01:46<02:24,  7.19it/s, running training loss: 0.9910]\u001b[A\n",
      "Training:  41%|████▏     | 731/1772 [01:46<02:19,  7.47it/s, running training loss: 0.9910]\u001b[A\n",
      "Training:  41%|████▏     | 731/1772 [01:46<02:19,  7.47it/s, running training loss: 1.0222]\u001b[A\n",
      "Training:  41%|████▏     | 732/1772 [01:46<02:26,  7.08it/s, running training loss: 1.0222]\u001b[A\n",
      "Training:  41%|████▏     | 732/1772 [01:46<02:26,  7.08it/s, running training loss: 1.6213]\u001b[A\n",
      "Training:  41%|████▏     | 733/1772 [01:46<02:18,  7.49it/s, running training loss: 1.6213]\u001b[A\n",
      "Training:  41%|████▏     | 733/1772 [01:46<02:18,  7.49it/s, running training loss: 1.5490]\u001b[A\n",
      "Training:  41%|████▏     | 734/1772 [01:46<02:16,  7.59it/s, running training loss: 1.5490]\u001b[A\n",
      "Training:  41%|████▏     | 734/1772 [01:46<02:16,  7.59it/s, running training loss: 1.5421]\u001b[A\n",
      "Training:  41%|████▏     | 735/1772 [01:46<02:15,  7.64it/s, running training loss: 1.5421]\u001b[A\n",
      "Training:  41%|████▏     | 735/1772 [01:46<02:15,  7.64it/s, running training loss: 1.1659]\u001b[A\n",
      "Training:  42%|████▏     | 736/1772 [01:46<02:13,  7.77it/s, running training loss: 1.1659]\u001b[A\n",
      "Training:  42%|████▏     | 736/1772 [01:46<02:13,  7.77it/s, running training loss: 0.9523]\u001b[A\n",
      "Training:  42%|████▏     | 737/1772 [01:46<02:12,  7.81it/s, running training loss: 0.9523]\u001b[A\n",
      "Training:  42%|████▏     | 737/1772 [01:47<02:12,  7.81it/s, running training loss: 1.1216]\u001b[A\n",
      "Training:  42%|████▏     | 738/1772 [01:47<02:12,  7.81it/s, running training loss: 1.1216]\u001b[A\n",
      "Training:  42%|████▏     | 738/1772 [01:47<02:12,  7.81it/s, running training loss: 1.3011]\u001b[A\n",
      "Training:  42%|████▏     | 739/1772 [01:47<02:13,  7.73it/s, running training loss: 1.3011]\u001b[A\n",
      "Training:  42%|████▏     | 739/1772 [01:47<02:13,  7.73it/s, running training loss: 0.8806]\u001b[A\n",
      "Training:  42%|████▏     | 740/1772 [01:47<02:13,  7.74it/s, running training loss: 0.8806]\u001b[A\n",
      "Training:  42%|████▏     | 740/1772 [01:47<02:13,  7.74it/s, running training loss: 0.9259]\u001b[A\n",
      "Training:  42%|████▏     | 741/1772 [01:47<02:10,  7.90it/s, running training loss: 0.9259]\u001b[A\n",
      "Training:  42%|████▏     | 741/1772 [01:47<02:10,  7.90it/s, running training loss: 0.9901]\u001b[A\n",
      "Training:  42%|████▏     | 742/1772 [01:47<02:14,  7.65it/s, running training loss: 0.9901]\u001b[A\n",
      "Training:  42%|████▏     | 742/1772 [01:47<02:14,  7.65it/s, running training loss: 0.8499]\u001b[A\n",
      "Training:  42%|████▏     | 743/1772 [01:47<02:09,  7.98it/s, running training loss: 0.8499]\u001b[A\n",
      "Training:  42%|████▏     | 743/1772 [01:47<02:09,  7.98it/s, running training loss: 1.0486]\u001b[A\n",
      "Training:  42%|████▏     | 744/1772 [01:47<02:07,  8.07it/s, running training loss: 1.0486]\u001b[A\n",
      "Training:  42%|████▏     | 744/1772 [01:47<02:07,  8.07it/s, running training loss: 0.8813]\u001b[A\n",
      "Training:  42%|████▏     | 745/1772 [01:47<02:07,  8.04it/s, running training loss: 0.8813]\u001b[A\n",
      "Training:  42%|████▏     | 745/1772 [01:48<02:07,  8.04it/s, running training loss: 1.0416]\u001b[A\n",
      "Training:  42%|████▏     | 746/1772 [01:48<02:10,  7.85it/s, running training loss: 1.0416]\u001b[A\n",
      "Training:  42%|████▏     | 746/1772 [01:48<02:10,  7.85it/s, running training loss: 0.9642]\u001b[A\n",
      "Training:  42%|████▏     | 747/1772 [01:48<02:06,  8.09it/s, running training loss: 0.9642]\u001b[A\n",
      "Training:  42%|████▏     | 747/1772 [01:48<02:06,  8.09it/s, running training loss: 0.8085]\u001b[A\n",
      "Training:  42%|████▏     | 748/1772 [01:48<02:14,  7.59it/s, running training loss: 0.8085]\u001b[A\n",
      "Training:  42%|████▏     | 748/1772 [01:48<02:14,  7.59it/s, running training loss: 0.9604]\u001b[A\n",
      "Training:  42%|████▏     | 749/1772 [01:48<02:10,  7.85it/s, running training loss: 0.9604]\u001b[A\n",
      "Training:  42%|████▏     | 749/1772 [01:48<02:10,  7.85it/s, running training loss: 0.8841]\u001b[A\n",
      "Training:  42%|████▏     | 750/1772 [01:48<02:13,  7.66it/s, running training loss: 0.8841]\u001b[A\n",
      "Training:  42%|████▏     | 750/1772 [01:48<02:13,  7.66it/s, running training loss: 1.1372]\u001b[A\n",
      "Training:  42%|████▏     | 751/1772 [01:48<02:19,  7.31it/s, running training loss: 1.1372]\u001b[A\n",
      "Training:  42%|████▏     | 751/1772 [01:48<02:19,  7.31it/s, running training loss: 0.9687]\u001b[A\n",
      "Training:  42%|████▏     | 752/1772 [01:48<02:16,  7.47it/s, running training loss: 0.9687]\u001b[A\n",
      "Training:  42%|████▏     | 752/1772 [01:49<02:16,  7.47it/s, running training loss: 0.9904]\u001b[A\n",
      "Training:  42%|████▏     | 753/1772 [01:49<02:18,  7.38it/s, running training loss: 0.9904]\u001b[A\n",
      "Training:  42%|████▏     | 753/1772 [01:49<02:18,  7.38it/s, running training loss: 1.0501]\u001b[A\n",
      "Training:  43%|████▎     | 754/1772 [01:49<02:27,  6.92it/s, running training loss: 1.0501]\u001b[A\n",
      "Training:  43%|████▎     | 754/1772 [01:49<02:27,  6.92it/s, running training loss: 0.9544]\u001b[A\n",
      "Training:  43%|████▎     | 755/1772 [01:49<02:28,  6.83it/s, running training loss: 0.9544]\u001b[A\n",
      "Training:  43%|████▎     | 755/1772 [01:49<02:28,  6.83it/s, running training loss: 1.0186]\u001b[A\n",
      "Training:  43%|████▎     | 756/1772 [01:49<02:20,  7.21it/s, running training loss: 1.0186]\u001b[A\n",
      "Training:  43%|████▎     | 756/1772 [01:49<02:20,  7.21it/s, running training loss: 1.2181]\u001b[A\n",
      "Training:  43%|████▎     | 757/1772 [01:49<02:16,  7.44it/s, running training loss: 1.2181]\u001b[A\n",
      "Training:  43%|████▎     | 757/1772 [01:49<02:16,  7.44it/s, running training loss: 0.8930]\u001b[A\n",
      "Training:  43%|████▎     | 758/1772 [01:49<02:24,  7.02it/s, running training loss: 0.8930]\u001b[A\n",
      "Training:  43%|████▎     | 758/1772 [01:49<02:24,  7.02it/s, running training loss: 1.1042]\u001b[A\n",
      "Training:  43%|████▎     | 759/1772 [01:49<02:30,  6.74it/s, running training loss: 1.1042]\u001b[A\n",
      "Training:  43%|████▎     | 759/1772 [01:50<02:30,  6.74it/s, running training loss: 0.8400]\u001b[A\n",
      "Training:  43%|████▎     | 760/1772 [01:50<02:42,  6.23it/s, running training loss: 0.8400]\u001b[A\n",
      "Training:  43%|████▎     | 760/1772 [01:50<02:42,  6.23it/s, running training loss: 1.3604]\u001b[A\n",
      "Training:  43%|████▎     | 761/1772 [01:50<02:35,  6.52it/s, running training loss: 1.3604]\u001b[A\n",
      "Training:  43%|████▎     | 761/1772 [01:50<02:35,  6.52it/s, running training loss: 0.9827]\u001b[A\n",
      "Training:  43%|████▎     | 762/1772 [01:50<02:33,  6.57it/s, running training loss: 0.9827]\u001b[A\n",
      "Training:  43%|████▎     | 762/1772 [01:50<02:33,  6.57it/s, running training loss: 0.9112]\u001b[A\n",
      "Training:  43%|████▎     | 763/1772 [01:50<02:24,  6.99it/s, running training loss: 0.9112]\u001b[A\n",
      "Training:  43%|████▎     | 763/1772 [01:50<02:24,  6.99it/s, running training loss: 1.2305]\u001b[A\n",
      "Training:  43%|████▎     | 764/1772 [01:50<02:19,  7.23it/s, running training loss: 1.2305]\u001b[A\n",
      "Training:  43%|████▎     | 764/1772 [01:50<02:19,  7.23it/s, running training loss: 1.9940]\u001b[A\n",
      "Training:  43%|████▎     | 765/1772 [01:50<02:17,  7.30it/s, running training loss: 1.9940]\u001b[A\n",
      "Training:  43%|████▎     | 765/1772 [01:50<02:17,  7.30it/s, running training loss: 1.3646]\u001b[A\n",
      "Training:  43%|████▎     | 766/1772 [01:50<02:14,  7.47it/s, running training loss: 1.3646]\u001b[A\n",
      "Training:  43%|████▎     | 766/1772 [01:51<02:14,  7.47it/s, running training loss: 1.3696]\u001b[A\n",
      "Training:  43%|████▎     | 767/1772 [01:51<02:12,  7.61it/s, running training loss: 1.3696]\u001b[A\n",
      "Training:  43%|████▎     | 767/1772 [01:51<02:12,  7.61it/s, running training loss: 0.9321]\u001b[A\n",
      "Training:  43%|████▎     | 768/1772 [01:51<02:16,  7.36it/s, running training loss: 0.9321]\u001b[A\n",
      "Training:  43%|████▎     | 768/1772 [01:51<02:16,  7.36it/s, running training loss: 1.5047]\u001b[A\n",
      "Training:  43%|████▎     | 769/1772 [01:51<02:17,  7.27it/s, running training loss: 1.5047]\u001b[A\n",
      "Training:  43%|████▎     | 769/1772 [01:51<02:17,  7.27it/s, running training loss: 1.4376]\u001b[A\n",
      "Training:  43%|████▎     | 770/1772 [01:51<02:18,  7.25it/s, running training loss: 1.4376]\u001b[A\n",
      "Training:  43%|████▎     | 770/1772 [01:51<02:18,  7.25it/s, running training loss: 1.2661]\u001b[A\n",
      "Training:  44%|████▎     | 771/1772 [01:51<02:11,  7.60it/s, running training loss: 1.2661]\u001b[A\n",
      "Training:  44%|████▎     | 771/1772 [01:51<02:11,  7.60it/s, running training loss: 1.2009]\u001b[A\n",
      "Training:  44%|████▎     | 772/1772 [01:51<02:22,  7.02it/s, running training loss: 1.2009]\u001b[A\n",
      "Training:  44%|████▎     | 772/1772 [01:51<02:22,  7.02it/s, running training loss: 0.8767]\u001b[A\n",
      "Training:  44%|████▎     | 773/1772 [01:51<02:23,  6.94it/s, running training loss: 0.8767]\u001b[A\n",
      "Training:  44%|████▎     | 773/1772 [01:52<02:23,  6.94it/s, running training loss: 1.0706]\u001b[A\n",
      "Training:  44%|████▎     | 774/1772 [01:52<02:18,  7.23it/s, running training loss: 1.0706]\u001b[A\n",
      "Training:  44%|████▎     | 774/1772 [01:52<02:18,  7.23it/s, running training loss: 1.1012]\u001b[A\n",
      "Training:  44%|████▎     | 775/1772 [01:52<02:10,  7.67it/s, running training loss: 1.1012]\u001b[A\n",
      "Training:  44%|████▎     | 775/1772 [01:52<02:10,  7.67it/s, running training loss: 1.1038]\u001b[A\n",
      "Training:  44%|████▍     | 776/1772 [01:52<02:08,  7.74it/s, running training loss: 1.1038]\u001b[A\n",
      "Training:  44%|████▍     | 776/1772 [01:52<02:08,  7.74it/s, running training loss: 0.9094]\u001b[A\n",
      "Training:  44%|████▍     | 777/1772 [01:52<02:07,  7.79it/s, running training loss: 0.9094]\u001b[A\n",
      "Training:  44%|████▍     | 777/1772 [01:52<02:07,  7.79it/s, running training loss: 0.9229]\u001b[A\n",
      "Training:  44%|████▍     | 778/1772 [01:52<02:03,  8.08it/s, running training loss: 0.9229]\u001b[A\n",
      "Training:  44%|████▍     | 778/1772 [01:52<02:03,  8.08it/s, running training loss: 0.9532]\u001b[A\n",
      "Training:  44%|████▍     | 779/1772 [01:52<02:02,  8.10it/s, running training loss: 0.9532]\u001b[A\n",
      "Training:  44%|████▍     | 779/1772 [01:52<02:02,  8.10it/s, running training loss: 1.2199]\u001b[A\n",
      "Training:  44%|████▍     | 780/1772 [01:52<01:59,  8.31it/s, running training loss: 1.2199]\u001b[A\n",
      "Training:  44%|████▍     | 780/1772 [01:52<01:59,  8.31it/s, running training loss: 1.0916]\u001b[A\n",
      "Training:  44%|████▍     | 781/1772 [01:52<02:00,  8.25it/s, running training loss: 1.0916]\u001b[A\n",
      "Training:  44%|████▍     | 781/1772 [01:52<02:00,  8.25it/s, running training loss: 1.0230]\u001b[A\n",
      "Training:  44%|████▍     | 782/1772 [01:52<02:03,  8.05it/s, running training loss: 1.0230]\u001b[A\n",
      "Training:  44%|████▍     | 782/1772 [01:53<02:03,  8.05it/s, running training loss: 0.9664]\u001b[A\n",
      "Training:  44%|████▍     | 783/1772 [01:53<02:25,  6.79it/s, running training loss: 0.9664]\u001b[A\n",
      "Training:  44%|████▍     | 783/1772 [01:53<02:25,  6.79it/s, running training loss: 0.8990]\u001b[A\n",
      "Training:  44%|████▍     | 784/1772 [01:53<02:19,  7.08it/s, running training loss: 0.8990]\u001b[A\n",
      "Training:  44%|████▍     | 784/1772 [01:53<02:19,  7.08it/s, running training loss: 1.2043]\u001b[A\n",
      "Training:  44%|████▍     | 785/1772 [01:53<02:21,  6.95it/s, running training loss: 1.2043]\u001b[A\n",
      "Training:  44%|████▍     | 785/1772 [01:53<02:21,  6.95it/s, running training loss: 0.9057]\u001b[A\n",
      "Training:  44%|████▍     | 786/1772 [01:53<02:15,  7.29it/s, running training loss: 0.9057]\u001b[A\n",
      "Training:  44%|████▍     | 786/1772 [01:53<02:15,  7.29it/s, running training loss: 1.7043]\u001b[A\n",
      "Training:  44%|████▍     | 787/1772 [01:53<02:17,  7.14it/s, running training loss: 1.7043]\u001b[A\n",
      "Training:  44%|████▍     | 787/1772 [01:53<02:17,  7.14it/s, running training loss: 0.9497]\u001b[A\n",
      "Training:  44%|████▍     | 788/1772 [01:53<02:10,  7.55it/s, running training loss: 0.9497]\u001b[A\n",
      "Training:  44%|████▍     | 788/1772 [01:53<02:10,  7.55it/s, running training loss: 1.2775]\u001b[A\n",
      "Training:  45%|████▍     | 789/1772 [01:53<02:08,  7.67it/s, running training loss: 1.2775]\u001b[A\n",
      "Training:  45%|████▍     | 789/1772 [01:54<02:08,  7.67it/s, running training loss: 1.2857]\u001b[A\n",
      "Training:  45%|████▍     | 790/1772 [01:54<02:05,  7.84it/s, running training loss: 1.2857]\u001b[A\n",
      "Training:  45%|████▍     | 790/1772 [01:54<02:05,  7.84it/s, running training loss: 1.2720]\u001b[A\n",
      "Training:  45%|████▍     | 791/1772 [01:54<02:11,  7.48it/s, running training loss: 1.2720]\u001b[A\n",
      "Training:  45%|████▍     | 791/1772 [01:54<02:11,  7.48it/s, running training loss: 1.0746]\u001b[A\n",
      "Training:  45%|████▍     | 792/1772 [01:54<02:09,  7.59it/s, running training loss: 1.0746]\u001b[A\n",
      "Training:  45%|████▍     | 792/1772 [01:54<02:09,  7.59it/s, running training loss: 0.9878]\u001b[A\n",
      "Training:  45%|████▍     | 793/1772 [01:54<02:11,  7.44it/s, running training loss: 0.9878]\u001b[A\n",
      "Training:  45%|████▍     | 793/1772 [01:54<02:11,  7.44it/s, running training loss: 1.2981]\u001b[A\n",
      "Training:  45%|████▍     | 794/1772 [01:54<02:12,  7.39it/s, running training loss: 1.2981]\u001b[A\n",
      "Training:  45%|████▍     | 794/1772 [01:54<02:12,  7.39it/s, running training loss: 0.8935]\u001b[A\n",
      "Training:  45%|████▍     | 795/1772 [01:54<02:14,  7.27it/s, running training loss: 0.8935]\u001b[A\n",
      "Training:  45%|████▍     | 795/1772 [01:54<02:14,  7.27it/s, running training loss: 1.2148]\u001b[A\n",
      "Training:  45%|████▍     | 796/1772 [01:54<02:15,  7.20it/s, running training loss: 1.2148]\u001b[A\n",
      "Training:  45%|████▍     | 796/1772 [01:55<02:15,  7.20it/s, running training loss: 0.8337]\u001b[A\n",
      "Training:  45%|████▍     | 797/1772 [01:55<02:25,  6.70it/s, running training loss: 0.8337]\u001b[A\n",
      "Training:  45%|████▍     | 797/1772 [01:55<02:25,  6.70it/s, running training loss: 1.3140]\u001b[A\n",
      "Training:  45%|████▌     | 798/1772 [01:55<02:19,  6.96it/s, running training loss: 1.3140]\u001b[A\n",
      "Training:  45%|████▌     | 798/1772 [01:55<02:19,  6.96it/s, running training loss: 1.2878]\u001b[A\n",
      "Training:  45%|████▌     | 799/1772 [01:55<02:13,  7.27it/s, running training loss: 1.2878]\u001b[A\n",
      "Training:  45%|████▌     | 799/1772 [01:55<02:13,  7.27it/s, running training loss: 1.1801]\u001b[A\n",
      "\n",
      "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> EMA starting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Evaluation:   0%|          | 1/270 [00:00<02:39,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   2%|▏         | 6/270 [00:00<01:51,  2.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   5%|▍         | 13/270 [00:00<01:17,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   7%|▋         | 19/270 [00:00<00:54,  4.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   9%|▉         | 25/270 [00:01<00:38,  6.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  11%|█▏        | 31/270 [00:01<00:27,  8.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  14%|█▎        | 37/270 [00:01<00:19, 11.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  16%|█▌        | 43/270 [00:01<00:14, 15.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  18%|█▊        | 49/270 [00:01<00:11, 19.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  20%|██        | 55/270 [00:01<00:08, 24.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  23%|██▎       | 61/270 [00:01<00:07, 29.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  25%|██▍       | 67/270 [00:01<00:05, 34.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  27%|██▋       | 73/270 [00:01<00:05, 39.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  29%|██▉       | 79/270 [00:01<00:04, 43.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  31%|███▏      | 85/270 [00:02<00:03, 46.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  34%|███▎      | 91/270 [00:02<00:03, 48.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  36%|███▋      | 98/270 [00:02<00:03, 52.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  39%|███▊      | 104/270 [00:02<00:03, 53.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  41%|████      | 110/270 [00:02<00:02, 54.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  43%|████▎     | 116/270 [00:02<00:02, 56.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  45%|████▌     | 122/270 [00:02<00:02, 56.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  47%|████▋     | 128/270 [00:02<00:02, 55.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  50%|████▉     | 134/270 [00:02<00:02, 55.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  52%|█████▏    | 141/270 [00:03<00:02, 56.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  54%|█████▍    | 147/270 [00:03<00:02, 55.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  57%|█████▋    | 153/270 [00:03<00:02, 55.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  59%|█████▉    | 160/270 [00:03<00:01, 56.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  61%|██████▏   | 166/270 [00:03<00:01, 56.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  64%|██████▎   | 172/270 [00:03<00:01, 56.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  66%|██████▌   | 178/270 [00:03<00:01, 55.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  68%|██████▊   | 184/270 [00:03<00:01, 54.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  70%|███████   | 190/270 [00:03<00:01, 55.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  73%|███████▎  | 196/270 [00:04<00:01, 54.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  75%|███████▍  | 202/270 [00:04<00:01, 53.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  77%|███████▋  | 208/270 [00:04<00:01, 54.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  79%|███████▉  | 214/270 [00:04<00:01, 54.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  81%|████████▏ | 220/270 [00:04<00:00, 56.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  84%|████████▍ | 227/270 [00:04<00:00, 57.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  86%|████████▋ | 233/270 [00:04<00:00, 56.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  89%|████████▊ | 239/270 [00:04<00:00, 57.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  91%|█████████ | 245/270 [00:04<00:00, 55.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  93%|█████████▎| 251/270 [00:05<00:00, 53.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  95%|█████████▌| 257/270 [00:05<00:00, 53.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  97%|█████████▋| 263/270 [00:05<00:00, 54.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation: 100%|██████████| 270/270 [00:05<00:00, 48.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Training:  45%|████▌     | 800/1772 [02:01<31:58,  1.97s/it, running training loss: 1.1801]\u001b[A\n",
      "Training:  45%|████▌     | 800/1772 [02:01<31:58,  1.97s/it, running training loss: 1.1589]\u001b[A\n",
      "Training:  45%|████▌     | 801/1772 [02:01<23:12,  1.43s/it, running training loss: 1.1589]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> training loss: 1.054030, valid loss: 0.626248, valid f1: 0.374742, valid acc: 0.648981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  45%|████▌     | 801/1772 [02:01<23:12,  1.43s/it, running training loss: 1.0178]\u001b[A\n",
      "Training:  45%|████▌     | 802/1772 [02:01<16:55,  1.05s/it, running training loss: 1.0178]\u001b[A\n",
      "Training:  45%|████▌     | 802/1772 [02:02<16:55,  1.05s/it, running training loss: 1.0446]\u001b[A\n",
      "Training:  45%|████▌     | 803/1772 [02:02<12:31,  1.29it/s, running training loss: 1.0446]\u001b[A\n",
      "Training:  45%|████▌     | 803/1772 [02:02<12:31,  1.29it/s, running training loss: 1.1339]\u001b[A\n",
      "Training:  45%|████▌     | 804/1772 [02:02<09:32,  1.69it/s, running training loss: 1.1339]\u001b[A\n",
      "Training:  45%|████▌     | 804/1772 [02:02<09:32,  1.69it/s, running training loss: 1.1925]\u001b[A\n",
      "Training:  45%|████▌     | 805/1772 [02:02<07:22,  2.18it/s, running training loss: 1.1925]\u001b[A\n",
      "Training:  45%|████▌     | 805/1772 [02:02<07:22,  2.18it/s, running training loss: 0.9109]\u001b[A\n",
      "Training:  45%|████▌     | 806/1772 [02:02<06:08,  2.62it/s, running training loss: 0.9109]\u001b[A\n",
      "Training:  45%|████▌     | 806/1772 [02:02<06:08,  2.62it/s, running training loss: 0.9884]\u001b[A\n",
      "Training:  46%|████▌     | 807/1772 [02:02<05:04,  3.17it/s, running training loss: 0.9884]\u001b[A\n",
      "Training:  46%|████▌     | 807/1772 [02:02<05:04,  3.17it/s, running training loss: 1.0081]\u001b[A\n",
      "Training:  46%|████▌     | 808/1772 [02:02<04:13,  3.80it/s, running training loss: 1.0081]\u001b[A\n",
      "Training:  46%|████▌     | 808/1772 [02:03<04:13,  3.80it/s, running training loss: 1.0042]\u001b[A\n",
      "Training:  46%|████▌     | 809/1772 [02:03<03:40,  4.36it/s, running training loss: 1.0042]\u001b[A\n",
      "Training:  46%|████▌     | 809/1772 [02:03<03:40,  4.36it/s, running training loss: 0.7950]\u001b[A\n",
      "Training:  46%|████▌     | 810/1772 [02:03<03:11,  5.03it/s, running training loss: 0.7950]\u001b[A\n",
      "Training:  46%|████▌     | 810/1772 [02:03<03:11,  5.03it/s, running training loss: 0.8646]\u001b[A\n",
      "Training:  46%|████▌     | 811/1772 [02:03<02:58,  5.39it/s, running training loss: 0.8646]\u001b[A\n",
      "Training:  46%|████▌     | 811/1772 [02:03<02:58,  5.39it/s, running training loss: 0.8470]\u001b[A\n",
      "Training:  46%|████▌     | 812/1772 [02:03<02:44,  5.85it/s, running training loss: 0.8470]\u001b[A\n",
      "Training:  46%|████▌     | 812/1772 [02:03<02:44,  5.85it/s, running training loss: 0.8720]\u001b[A\n",
      "Training:  46%|████▌     | 813/1772 [02:03<02:30,  6.36it/s, running training loss: 0.8720]\u001b[A\n",
      "Training:  46%|████▌     | 813/1772 [02:03<02:30,  6.36it/s, running training loss: 0.9123]\u001b[A\n",
      "Training:  46%|████▌     | 814/1772 [02:03<02:25,  6.59it/s, running training loss: 0.9123]\u001b[A\n",
      "Training:  46%|████▌     | 814/1772 [02:03<02:25,  6.59it/s, running training loss: 1.1237]\u001b[A\n",
      "Training:  46%|████▌     | 815/1772 [02:03<02:18,  6.90it/s, running training loss: 1.1237]\u001b[A\n",
      "Training:  46%|████▌     | 815/1772 [02:04<02:18,  6.90it/s, running training loss: 1.0633]\u001b[A\n",
      "Training:  46%|████▌     | 816/1772 [02:04<02:19,  6.84it/s, running training loss: 1.0633]\u001b[A\n",
      "Training:  46%|████▌     | 816/1772 [02:04<02:19,  6.84it/s, running training loss: 1.0420]\u001b[A\n",
      "Training:  46%|████▌     | 817/1772 [02:04<02:14,  7.09it/s, running training loss: 1.0420]\u001b[A\n",
      "Training:  46%|████▌     | 817/1772 [02:04<02:14,  7.09it/s, running training loss: 1.2230]\u001b[A\n",
      "Training:  46%|████▌     | 818/1772 [02:04<02:11,  7.27it/s, running training loss: 1.2230]\u001b[A\n",
      "Training:  46%|████▌     | 818/1772 [02:04<02:11,  7.27it/s, running training loss: 1.1075]\u001b[A\n",
      "Training:  46%|████▌     | 819/1772 [02:04<02:21,  6.74it/s, running training loss: 1.1075]\u001b[A\n",
      "Training:  46%|████▌     | 819/1772 [02:04<02:21,  6.74it/s, running training loss: 0.9813]\u001b[A\n",
      "Training:  46%|████▋     | 820/1772 [02:04<02:24,  6.58it/s, running training loss: 0.9813]\u001b[A\n",
      "Training:  46%|████▋     | 820/1772 [02:04<02:24,  6.58it/s, running training loss: 1.1566]\u001b[A\n",
      "Training:  46%|████▋     | 821/1772 [02:04<02:30,  6.32it/s, running training loss: 1.1566]\u001b[A\n",
      "Training:  46%|████▋     | 821/1772 [02:04<02:30,  6.32it/s, running training loss: 1.1093]\u001b[A\n",
      "Training:  46%|████▋     | 822/1772 [02:04<02:23,  6.60it/s, running training loss: 1.1093]\u001b[A\n",
      "Training:  46%|████▋     | 822/1772 [02:05<02:23,  6.60it/s, running training loss: 1.1203]\u001b[A\n",
      "Training:  46%|████▋     | 823/1772 [02:05<02:25,  6.53it/s, running training loss: 1.1203]\u001b[A\n",
      "Training:  46%|████▋     | 823/1772 [02:05<02:25,  6.53it/s, running training loss: 1.0804]\u001b[A\n",
      "Training:  47%|████▋     | 824/1772 [02:05<02:14,  7.03it/s, running training loss: 1.0804]\u001b[A\n",
      "Training:  47%|████▋     | 824/1772 [02:05<02:14,  7.03it/s, running training loss: 0.8687]\u001b[A\n",
      "Training:  47%|████▋     | 825/1772 [02:05<02:22,  6.66it/s, running training loss: 0.8687]\u001b[A\n",
      "Training:  47%|████▋     | 825/1772 [02:05<02:22,  6.66it/s, running training loss: 0.9378]\u001b[A\n",
      "Training:  47%|████▋     | 826/1772 [02:05<02:17,  6.90it/s, running training loss: 0.9378]\u001b[A\n",
      "Training:  47%|████▋     | 826/1772 [02:05<02:17,  6.90it/s, running training loss: 0.8639]\u001b[A\n",
      "Training:  47%|████▋     | 827/1772 [02:05<02:13,  7.10it/s, running training loss: 0.8639]\u001b[A\n",
      "Training:  47%|████▋     | 827/1772 [02:05<02:13,  7.10it/s, running training loss: 0.9327]\u001b[A\n",
      "Training:  47%|████▋     | 828/1772 [02:05<02:13,  7.09it/s, running training loss: 0.9327]\u001b[A\n",
      "Training:  47%|████▋     | 828/1772 [02:05<02:13,  7.09it/s, running training loss: 0.9454]\u001b[A\n",
      "Training:  47%|████▋     | 829/1772 [02:05<02:10,  7.24it/s, running training loss: 0.9454]\u001b[A\n",
      "Training:  47%|████▋     | 829/1772 [02:06<02:10,  7.24it/s, running training loss: 1.1756]\u001b[A\n",
      "Training:  47%|████▋     | 830/1772 [02:06<02:29,  6.31it/s, running training loss: 1.1756]\u001b[A\n",
      "Training:  47%|████▋     | 830/1772 [02:06<02:29,  6.31it/s, running training loss: 1.2102]\u001b[A\n",
      "Training:  47%|████▋     | 831/1772 [02:06<02:41,  5.83it/s, running training loss: 1.2102]\u001b[A\n",
      "Training:  47%|████▋     | 831/1772 [02:06<02:41,  5.83it/s, running training loss: 1.1330]\u001b[A\n",
      "Training:  47%|████▋     | 832/1772 [02:06<02:34,  6.10it/s, running training loss: 1.1330]\u001b[A\n",
      "Training:  47%|████▋     | 832/1772 [02:06<02:34,  6.10it/s, running training loss: 0.9034]\u001b[A\n",
      "Training:  47%|████▋     | 833/1772 [02:06<02:25,  6.43it/s, running training loss: 0.9034]\u001b[A\n",
      "Training:  47%|████▋     | 833/1772 [02:06<02:25,  6.43it/s, running training loss: 0.9414]\u001b[A\n",
      "Training:  47%|████▋     | 834/1772 [02:06<02:18,  6.77it/s, running training loss: 0.9414]\u001b[A\n",
      "Training:  47%|████▋     | 834/1772 [02:06<02:18,  6.77it/s, running training loss: 1.0830]\u001b[A\n",
      "Training:  47%|████▋     | 835/1772 [02:06<02:14,  6.98it/s, running training loss: 1.0830]\u001b[A\n",
      "Training:  47%|████▋     | 835/1772 [02:06<02:14,  6.98it/s, running training loss: 0.9309]\u001b[A\n",
      "Training:  47%|████▋     | 836/1772 [02:06<02:14,  6.97it/s, running training loss: 0.9309]\u001b[A\n",
      "Training:  47%|████▋     | 836/1772 [02:07<02:14,  6.97it/s, running training loss: 0.8289]\u001b[A\n",
      "Training:  47%|████▋     | 837/1772 [02:07<02:12,  7.05it/s, running training loss: 0.8289]\u001b[A\n",
      "Training:  47%|████▋     | 837/1772 [02:07<02:12,  7.05it/s, running training loss: 0.8751]\u001b[A\n",
      "Training:  47%|████▋     | 838/1772 [02:07<02:10,  7.16it/s, running training loss: 0.8751]\u001b[A\n",
      "Training:  47%|████▋     | 838/1772 [02:07<02:10,  7.16it/s, running training loss: 0.8577]\u001b[A\n",
      "Training:  47%|████▋     | 839/1772 [02:07<02:10,  7.16it/s, running training loss: 0.8577]\u001b[A\n",
      "Training:  47%|████▋     | 839/1772 [02:07<02:10,  7.16it/s, running training loss: 0.9347]\u001b[A\n",
      "Training:  47%|████▋     | 840/1772 [02:07<02:06,  7.35it/s, running training loss: 0.9347]\u001b[A\n",
      "Training:  47%|████▋     | 840/1772 [02:07<02:06,  7.35it/s, running training loss: 0.9546]\u001b[A\n",
      "Training:  47%|████▋     | 841/1772 [02:07<02:12,  7.04it/s, running training loss: 0.9546]\u001b[A\n",
      "Training:  47%|████▋     | 841/1772 [02:07<02:12,  7.04it/s, running training loss: 0.9964]\u001b[A\n",
      "Training:  48%|████▊     | 842/1772 [02:07<02:26,  6.34it/s, running training loss: 0.9964]\u001b[A\n",
      "Training:  48%|████▊     | 842/1772 [02:08<02:26,  6.34it/s, running training loss: 0.9554]\u001b[A\n",
      "Training:  48%|████▊     | 843/1772 [02:08<02:27,  6.28it/s, running training loss: 0.9554]\u001b[A\n",
      "Training:  48%|████▊     | 843/1772 [02:08<02:27,  6.28it/s, running training loss: 1.0994]\u001b[A\n",
      "Training:  48%|████▊     | 844/1772 [02:08<02:21,  6.55it/s, running training loss: 1.0994]\u001b[A\n",
      "Training:  48%|████▊     | 844/1772 [02:08<02:21,  6.55it/s, running training loss: 1.0242]\u001b[A\n",
      "Training:  48%|████▊     | 845/1772 [02:08<02:15,  6.82it/s, running training loss: 1.0242]\u001b[A\n",
      "Training:  48%|████▊     | 845/1772 [02:08<02:15,  6.82it/s, running training loss: 0.8464]\u001b[A\n",
      "Training:  48%|████▊     | 846/1772 [02:08<02:14,  6.88it/s, running training loss: 0.8464]\u001b[A\n",
      "Training:  48%|████▊     | 846/1772 [02:08<02:14,  6.88it/s, running training loss: 1.1530]\u001b[A\n",
      "Training:  48%|████▊     | 847/1772 [02:08<02:18,  6.68it/s, running training loss: 1.1530]\u001b[A\n",
      "Training:  48%|████▊     | 847/1772 [02:08<02:18,  6.68it/s, running training loss: 0.9985]\u001b[A\n",
      "Training:  48%|████▊     | 848/1772 [02:08<02:21,  6.54it/s, running training loss: 0.9985]\u001b[A\n",
      "Training:  48%|████▊     | 848/1772 [02:08<02:21,  6.54it/s, running training loss: 1.1244]\u001b[A\n",
      "Training:  48%|████▊     | 849/1772 [02:08<02:27,  6.27it/s, running training loss: 1.1244]\u001b[A\n",
      "Training:  48%|████▊     | 849/1772 [02:09<02:27,  6.27it/s, running training loss: 0.9813]\u001b[A\n",
      "Training:  48%|████▊     | 850/1772 [02:09<02:22,  6.45it/s, running training loss: 0.9813]\u001b[A\n",
      "Training:  48%|████▊     | 850/1772 [02:09<02:22,  6.45it/s, running training loss: 0.8835]\u001b[A\n",
      "Training:  48%|████▊     | 851/1772 [02:09<02:17,  6.70it/s, running training loss: 0.8835]\u001b[A\n",
      "Training:  48%|████▊     | 851/1772 [02:09<02:17,  6.70it/s, running training loss: 1.1259]\u001b[A\n",
      "Training:  48%|████▊     | 852/1772 [02:09<02:30,  6.11it/s, running training loss: 1.1259]\u001b[A\n",
      "Training:  48%|████▊     | 852/1772 [02:09<02:30,  6.11it/s, running training loss: 1.0171]\u001b[A\n",
      "Training:  48%|████▊     | 853/1772 [02:09<02:22,  6.47it/s, running training loss: 1.0171]\u001b[A\n",
      "Training:  48%|████▊     | 853/1772 [02:09<02:22,  6.47it/s, running training loss: 0.9729]\u001b[A\n",
      "Training:  48%|████▊     | 854/1772 [02:09<02:14,  6.85it/s, running training loss: 0.9729]\u001b[A\n",
      "Training:  48%|████▊     | 854/1772 [02:09<02:14,  6.85it/s, running training loss: 0.8973]\u001b[A\n",
      "Training:  48%|████▊     | 855/1772 [02:09<02:10,  7.01it/s, running training loss: 0.8973]\u001b[A\n",
      "Training:  48%|████▊     | 855/1772 [02:09<02:10,  7.01it/s, running training loss: 1.0096]\u001b[A\n",
      "Training:  48%|████▊     | 856/1772 [02:09<02:17,  6.67it/s, running training loss: 1.0096]\u001b[A\n",
      "Training:  48%|████▊     | 856/1772 [02:10<02:17,  6.67it/s, running training loss: 0.9643]\u001b[A\n",
      "Training:  48%|████▊     | 857/1772 [02:10<02:15,  6.75it/s, running training loss: 0.9643]\u001b[A\n",
      "Training:  48%|████▊     | 857/1772 [02:10<02:15,  6.75it/s, running training loss: 0.9070]\u001b[A\n",
      "Training:  48%|████▊     | 858/1772 [02:10<02:11,  6.97it/s, running training loss: 0.9070]\u001b[A\n",
      "Training:  48%|████▊     | 858/1772 [02:10<02:11,  6.97it/s, running training loss: 0.8315]\u001b[A\n",
      "Training:  48%|████▊     | 859/1772 [02:10<02:09,  7.07it/s, running training loss: 0.8315]\u001b[A\n",
      "Training:  48%|████▊     | 859/1772 [02:10<02:09,  7.07it/s, running training loss: 0.8476]\u001b[A\n",
      "Training:  49%|████▊     | 860/1772 [02:10<02:19,  6.54it/s, running training loss: 0.8476]\u001b[A\n",
      "Training:  49%|████▊     | 860/1772 [02:10<02:19,  6.54it/s, running training loss: 1.3833]\u001b[A\n",
      "Training:  49%|████▊     | 861/1772 [02:10<02:26,  6.23it/s, running training loss: 1.3833]\u001b[A\n",
      "Training:  49%|████▊     | 861/1772 [02:10<02:26,  6.23it/s, running training loss: 1.1638]\u001b[A\n",
      "Training:  49%|████▊     | 862/1772 [02:10<02:21,  6.45it/s, running training loss: 1.1638]\u001b[A\n",
      "Training:  49%|████▊     | 862/1772 [02:11<02:21,  6.45it/s, running training loss: 1.0609]\u001b[A\n",
      "Training:  49%|████▊     | 863/1772 [02:11<02:26,  6.21it/s, running training loss: 1.0609]\u001b[A\n",
      "Training:  49%|████▊     | 863/1772 [02:11<02:26,  6.21it/s, running training loss: 1.2178]\u001b[A\n",
      "Training:  49%|████▉     | 864/1772 [02:11<02:20,  6.45it/s, running training loss: 1.2178]\u001b[A\n",
      "Training:  49%|████▉     | 864/1772 [02:11<02:20,  6.45it/s, running training loss: 1.1289]\u001b[A\n",
      "Training:  49%|████▉     | 865/1772 [02:11<02:13,  6.77it/s, running training loss: 1.1289]\u001b[A\n",
      "Training:  49%|████▉     | 865/1772 [02:11<02:13,  6.77it/s, running training loss: 1.1944]\u001b[A\n",
      "Training:  49%|████▉     | 866/1772 [02:11<02:08,  7.03it/s, running training loss: 1.1944]\u001b[A\n",
      "Training:  49%|████▉     | 866/1772 [02:11<02:08,  7.03it/s, running training loss: 0.9591]\u001b[A\n",
      "Training:  49%|████▉     | 867/1772 [02:11<02:05,  7.22it/s, running training loss: 0.9591]\u001b[A\n",
      "Training:  49%|████▉     | 867/1772 [02:11<02:05,  7.22it/s, running training loss: 0.8236]\u001b[A\n",
      "Training:  49%|████▉     | 868/1772 [02:11<02:01,  7.45it/s, running training loss: 0.8236]\u001b[A\n",
      "Training:  49%|████▉     | 868/1772 [02:11<02:01,  7.45it/s, running training loss: 0.8649]\u001b[A\n",
      "Training:  49%|████▉     | 869/1772 [02:11<02:02,  7.38it/s, running training loss: 0.8649]\u001b[A\n",
      "Training:  49%|████▉     | 869/1772 [02:11<02:02,  7.38it/s, running training loss: 1.0924]\u001b[A\n",
      "Training:  49%|████▉     | 870/1772 [02:11<01:58,  7.59it/s, running training loss: 1.0924]\u001b[A\n",
      "Training:  49%|████▉     | 870/1772 [02:12<01:58,  7.59it/s, running training loss: 0.9313]\u001b[A\n",
      "Training:  49%|████▉     | 871/1772 [02:12<01:59,  7.54it/s, running training loss: 0.9313]\u001b[A\n",
      "Training:  49%|████▉     | 871/1772 [02:12<01:59,  7.54it/s, running training loss: 1.1865]\u001b[A\n",
      "Training:  49%|████▉     | 872/1772 [02:12<02:06,  7.11it/s, running training loss: 1.1865]\u001b[A\n",
      "Training:  49%|████▉     | 872/1772 [02:12<02:06,  7.11it/s, running training loss: 0.9961]\u001b[A\n",
      "Training:  49%|████▉     | 873/1772 [02:12<02:03,  7.30it/s, running training loss: 0.9961]\u001b[A\n",
      "Training:  49%|████▉     | 873/1772 [02:12<02:03,  7.30it/s, running training loss: 1.2413]\u001b[A\n",
      "Training:  49%|████▉     | 874/1772 [02:12<02:06,  7.11it/s, running training loss: 1.2413]\u001b[A\n",
      "Training:  49%|████▉     | 874/1772 [02:12<02:06,  7.11it/s, running training loss: 1.4703]\u001b[A\n",
      "Training:  49%|████▉     | 875/1772 [02:12<02:09,  6.94it/s, running training loss: 1.4703]\u001b[A\n",
      "Training:  49%|████▉     | 875/1772 [02:12<02:09,  6.94it/s, running training loss: 0.9800]\u001b[A\n",
      "Training:  49%|████▉     | 876/1772 [02:12<02:04,  7.18it/s, running training loss: 0.9800]\u001b[A\n",
      "Training:  49%|████▉     | 876/1772 [02:12<02:04,  7.18it/s, running training loss: 0.9015]\u001b[A\n",
      "Training:  49%|████▉     | 877/1772 [02:12<02:02,  7.30it/s, running training loss: 0.9015]\u001b[A\n",
      "Training:  49%|████▉     | 877/1772 [02:13<02:02,  7.30it/s, running training loss: 1.1653]\u001b[A\n",
      "Training:  50%|████▉     | 878/1772 [02:13<01:57,  7.61it/s, running training loss: 1.1653]\u001b[A\n",
      "Training:  50%|████▉     | 878/1772 [02:13<01:57,  7.61it/s, running training loss: 1.1607]\u001b[A\n",
      "Training:  50%|████▉     | 879/1772 [02:13<02:05,  7.11it/s, running training loss: 1.1607]\u001b[A\n",
      "Training:  50%|████▉     | 879/1772 [02:13<02:05,  7.11it/s, running training loss: 0.8814]\u001b[A\n",
      "Training:  50%|████▉     | 880/1772 [02:13<02:07,  7.02it/s, running training loss: 0.8814]\u001b[A\n",
      "Training:  50%|████▉     | 880/1772 [02:13<02:07,  7.02it/s, running training loss: 1.0424]\u001b[A\n",
      "Training:  50%|████▉     | 881/1772 [02:13<02:04,  7.13it/s, running training loss: 1.0424]\u001b[A\n",
      "Training:  50%|████▉     | 881/1772 [02:13<02:04,  7.13it/s, running training loss: 0.9386]\u001b[A\n",
      "Training:  50%|████▉     | 882/1772 [02:13<02:02,  7.26it/s, running training loss: 0.9386]\u001b[A\n",
      "Training:  50%|████▉     | 882/1772 [02:13<02:02,  7.26it/s, running training loss: 0.9552]\u001b[A\n",
      "Training:  50%|████▉     | 883/1772 [02:13<02:01,  7.31it/s, running training loss: 0.9552]\u001b[A\n",
      "Training:  50%|████▉     | 883/1772 [02:13<02:01,  7.31it/s, running training loss: 1.0992]\u001b[A\n",
      "Training:  50%|████▉     | 884/1772 [02:13<02:02,  7.27it/s, running training loss: 1.0992]\u001b[A\n",
      "Training:  50%|████▉     | 884/1772 [02:14<02:02,  7.27it/s, running training loss: 1.2992]\u001b[A\n",
      "Training:  50%|████▉     | 885/1772 [02:14<02:03,  7.18it/s, running training loss: 1.2992]\u001b[A\n",
      "Training:  50%|████▉     | 885/1772 [02:14<02:03,  7.18it/s, running training loss: 0.9476]\u001b[A\n",
      "Training:  50%|█████     | 886/1772 [02:14<02:02,  7.24it/s, running training loss: 0.9476]\u001b[A\n",
      "Training:  50%|█████     | 886/1772 [02:14<02:02,  7.24it/s, running training loss: 1.0016]\u001b[A\n",
      "Training:  50%|█████     | 887/1772 [02:14<02:01,  7.26it/s, running training loss: 1.0016]\u001b[A\n",
      "Training:  50%|█████     | 887/1772 [02:14<02:01,  7.26it/s, running training loss: 0.9294]\u001b[A\n",
      "Training:  50%|█████     | 888/1772 [02:14<02:01,  7.26it/s, running training loss: 0.9294]\u001b[A\n",
      "Training:  50%|█████     | 888/1772 [02:14<02:01,  7.26it/s, running training loss: 0.9817]\u001b[A\n",
      "Training:  50%|█████     | 889/1772 [02:14<02:01,  7.27it/s, running training loss: 0.9817]\u001b[A\n",
      "Training:  50%|█████     | 889/1772 [02:14<02:01,  7.27it/s, running training loss: 0.9047]\u001b[A\n",
      "Training:  50%|█████     | 890/1772 [02:14<02:06,  6.95it/s, running training loss: 0.9047]\u001b[A\n",
      "Training:  50%|█████     | 890/1772 [02:14<02:06,  6.95it/s, running training loss: 0.9528]\u001b[A\n",
      "Training:  50%|█████     | 891/1772 [02:14<02:05,  7.04it/s, running training loss: 0.9528]\u001b[A\n",
      "Training:  50%|█████     | 891/1772 [02:15<02:05,  7.04it/s, running training loss: 1.3468]\u001b[A\n",
      "Training:  50%|█████     | 892/1772 [02:15<02:03,  7.15it/s, running training loss: 1.3468]\u001b[A\n",
      "Training:  50%|█████     | 892/1772 [02:15<02:03,  7.15it/s, running training loss: 0.9968]\u001b[A\n",
      "Training:  50%|█████     | 893/1772 [02:15<02:02,  7.17it/s, running training loss: 0.9968]\u001b[A\n",
      "Training:  50%|█████     | 893/1772 [02:15<02:02,  7.17it/s, running training loss: 1.1306]\u001b[A\n",
      "Training:  50%|█████     | 894/1772 [02:15<02:14,  6.54it/s, running training loss: 1.1306]\u001b[A\n",
      "Training:  50%|█████     | 894/1772 [02:15<02:14,  6.54it/s, running training loss: 1.4166]\u001b[A\n",
      "Training:  51%|█████     | 895/1772 [02:15<02:16,  6.44it/s, running training loss: 1.4166]\u001b[A\n",
      "Training:  51%|█████     | 895/1772 [02:15<02:16,  6.44it/s, running training loss: 1.2808]\u001b[A\n",
      "Training:  51%|█████     | 896/1772 [02:15<02:09,  6.78it/s, running training loss: 1.2808]\u001b[A\n",
      "Training:  51%|█████     | 896/1772 [02:15<02:09,  6.78it/s, running training loss: 1.1581]\u001b[A\n",
      "Training:  51%|█████     | 897/1772 [02:15<02:06,  6.90it/s, running training loss: 1.1581]\u001b[A\n",
      "Training:  51%|█████     | 897/1772 [02:15<02:06,  6.90it/s, running training loss: 1.0122]\u001b[A\n",
      "Training:  51%|█████     | 898/1772 [02:15<02:05,  6.97it/s, running training loss: 1.0122]\u001b[A\n",
      "Training:  51%|█████     | 898/1772 [02:16<02:05,  6.97it/s, running training loss: 0.8220]\u001b[A\n",
      "Training:  51%|█████     | 899/1772 [02:16<02:11,  6.62it/s, running training loss: 0.8220]\u001b[A\n",
      "Training:  51%|█████     | 899/1772 [02:16<02:11,  6.62it/s, running training loss: 1.0148]\u001b[A\n",
      "Training:  51%|█████     | 900/1772 [02:16<02:04,  6.99it/s, running training loss: 1.0148]\u001b[A\n",
      "Training:  51%|█████     | 900/1772 [02:16<02:04,  6.99it/s, running training loss: 1.4305]\u001b[A\n",
      "Training:  51%|█████     | 901/1772 [02:16<02:06,  6.88it/s, running training loss: 1.4305]\u001b[A\n",
      "Training:  51%|█████     | 901/1772 [02:16<02:06,  6.88it/s, running training loss: 0.8176]\u001b[A\n",
      "Training:  51%|█████     | 902/1772 [02:16<02:03,  7.05it/s, running training loss: 0.8176]\u001b[A\n",
      "Training:  51%|█████     | 902/1772 [02:16<02:03,  7.05it/s, running training loss: 0.9582]\u001b[A\n",
      "Training:  51%|█████     | 903/1772 [02:16<02:04,  6.98it/s, running training loss: 0.9582]\u001b[A\n",
      "Training:  51%|█████     | 903/1772 [02:16<02:04,  6.98it/s, running training loss: 0.8838]\u001b[A\n",
      "Training:  51%|█████     | 904/1772 [02:16<02:04,  6.98it/s, running training loss: 0.8838]\u001b[A\n",
      "Training:  51%|█████     | 904/1772 [02:16<02:04,  6.98it/s, running training loss: 0.8586]\u001b[A\n",
      "Training:  51%|█████     | 905/1772 [02:16<02:01,  7.15it/s, running training loss: 0.8586]\u001b[A\n",
      "Training:  51%|█████     | 905/1772 [02:17<02:01,  7.15it/s, running training loss: 1.1651]\u001b[A\n",
      "Training:  51%|█████     | 906/1772 [02:17<02:01,  7.14it/s, running training loss: 1.1651]\u001b[A\n",
      "Training:  51%|█████     | 906/1772 [02:17<02:01,  7.14it/s, running training loss: 0.9154]\u001b[A\n",
      "Training:  51%|█████     | 907/1772 [02:17<02:00,  7.17it/s, running training loss: 0.9154]\u001b[A\n",
      "Training:  51%|█████     | 907/1772 [02:17<02:00,  7.17it/s, running training loss: 1.0347]\u001b[A\n",
      "Training:  51%|█████     | 908/1772 [02:17<01:56,  7.39it/s, running training loss: 1.0347]\u001b[A\n",
      "Training:  51%|█████     | 908/1772 [02:17<01:56,  7.39it/s, running training loss: 1.4185]\u001b[A\n",
      "Training:  51%|█████▏    | 909/1772 [02:17<01:59,  7.25it/s, running training loss: 1.4185]\u001b[A\n",
      "Training:  51%|█████▏    | 909/1772 [02:17<01:59,  7.25it/s, running training loss: 1.2213]\u001b[A\n",
      "Training:  51%|█████▏    | 910/1772 [02:17<02:17,  6.26it/s, running training loss: 1.2213]\u001b[A\n",
      "Training:  51%|█████▏    | 910/1772 [02:17<02:17,  6.26it/s, running training loss: 0.9913]\u001b[A\n",
      "Training:  51%|█████▏    | 911/1772 [02:17<02:11,  6.53it/s, running training loss: 0.9913]\u001b[A\n",
      "Training:  51%|█████▏    | 911/1772 [02:17<02:11,  6.53it/s, running training loss: 1.0939]\u001b[A\n",
      "Training:  51%|█████▏    | 912/1772 [02:17<02:04,  6.88it/s, running training loss: 1.0939]\u001b[A\n",
      "Training:  51%|█████▏    | 912/1772 [02:18<02:04,  6.88it/s, running training loss: 0.9564]\u001b[A\n",
      "Training:  52%|█████▏    | 913/1772 [02:18<02:05,  6.83it/s, running training loss: 0.9564]\u001b[A\n",
      "Training:  52%|█████▏    | 913/1772 [02:18<02:05,  6.83it/s, running training loss: 1.1134]\u001b[A\n",
      "Training:  52%|█████▏    | 914/1772 [02:18<02:03,  6.96it/s, running training loss: 1.1134]\u001b[A\n",
      "Training:  52%|█████▏    | 914/1772 [02:18<02:03,  6.96it/s, running training loss: 1.1662]\u001b[A\n",
      "Training:  52%|█████▏    | 915/1772 [02:18<02:07,  6.70it/s, running training loss: 1.1662]\u001b[A\n",
      "Training:  52%|█████▏    | 915/1772 [02:18<02:07,  6.70it/s, running training loss: 1.0140]\u001b[A\n",
      "Training:  52%|█████▏    | 916/1772 [02:18<02:00,  7.09it/s, running training loss: 1.0140]\u001b[A\n",
      "Training:  52%|█████▏    | 916/1772 [02:18<02:00,  7.09it/s, running training loss: 0.8717]\u001b[A\n",
      "Training:  52%|█████▏    | 917/1772 [02:18<02:03,  6.94it/s, running training loss: 0.8717]\u001b[A\n",
      "Training:  52%|█████▏    | 917/1772 [02:18<02:03,  6.94it/s, running training loss: 0.9913]\u001b[A\n",
      "Training:  52%|█████▏    | 918/1772 [02:18<02:03,  6.92it/s, running training loss: 0.9913]\u001b[A\n",
      "Training:  52%|█████▏    | 918/1772 [02:18<02:03,  6.92it/s, running training loss: 0.9369]\u001b[A\n",
      "Training:  52%|█████▏    | 919/1772 [02:18<02:00,  7.09it/s, running training loss: 0.9369]\u001b[A\n",
      "Training:  52%|█████▏    | 919/1772 [02:19<02:00,  7.09it/s, running training loss: 0.8980]\u001b[A\n",
      "Training:  52%|█████▏    | 920/1772 [02:19<02:17,  6.17it/s, running training loss: 0.8980]\u001b[A\n",
      "Training:  52%|█████▏    | 920/1772 [02:19<02:17,  6.17it/s, running training loss: 0.9048]\u001b[A\n",
      "Training:  52%|█████▏    | 921/1772 [02:19<02:11,  6.47it/s, running training loss: 0.9048]\u001b[A\n",
      "Training:  52%|█████▏    | 921/1772 [02:19<02:11,  6.47it/s, running training loss: 1.0005]\u001b[A\n",
      "Training:  52%|█████▏    | 922/1772 [02:19<02:03,  6.88it/s, running training loss: 1.0005]\u001b[A\n",
      "Training:  52%|█████▏    | 922/1772 [02:19<02:03,  6.88it/s, running training loss: 1.0092]\u001b[A\n",
      "Training:  52%|█████▏    | 923/1772 [02:19<02:01,  6.98it/s, running training loss: 1.0092]\u001b[A\n",
      "Training:  52%|█████▏    | 923/1772 [02:19<02:01,  6.98it/s, running training loss: 0.9610]\u001b[A\n",
      "Training:  52%|█████▏    | 924/1772 [02:19<01:58,  7.18it/s, running training loss: 0.9610]\u001b[A\n",
      "Training:  52%|█████▏    | 924/1772 [02:19<01:58,  7.18it/s, running training loss: 0.9483]\u001b[A\n",
      "Training:  52%|█████▏    | 925/1772 [02:19<02:06,  6.69it/s, running training loss: 0.9483]\u001b[A\n",
      "Training:  52%|█████▏    | 925/1772 [02:20<02:06,  6.69it/s, running training loss: 1.0624]\u001b[A\n",
      "Training:  52%|█████▏    | 926/1772 [02:20<02:02,  6.89it/s, running training loss: 1.0624]\u001b[A\n",
      "Training:  52%|█████▏    | 926/1772 [02:20<02:02,  6.89it/s, running training loss: 0.9914]\u001b[A\n",
      "Training:  52%|█████▏    | 927/1772 [02:20<01:59,  7.04it/s, running training loss: 0.9914]\u001b[A\n",
      "Training:  52%|█████▏    | 927/1772 [02:20<01:59,  7.04it/s, running training loss: 0.8698]\u001b[A\n",
      "Training:  52%|█████▏    | 928/1772 [02:20<01:55,  7.31it/s, running training loss: 0.8698]\u001b[A\n",
      "Training:  52%|█████▏    | 928/1772 [02:20<01:55,  7.31it/s, running training loss: 0.9889]\u001b[A\n",
      "Training:  52%|█████▏    | 929/1772 [02:20<01:49,  7.71it/s, running training loss: 0.9889]\u001b[A\n",
      "Training:  52%|█████▏    | 929/1772 [02:20<01:49,  7.71it/s, running training loss: 0.9604]\u001b[A\n",
      "Training:  52%|█████▏    | 930/1772 [02:20<01:59,  7.03it/s, running training loss: 0.9604]\u001b[A\n",
      "Training:  52%|█████▏    | 930/1772 [02:20<01:59,  7.03it/s, running training loss: 1.0521]\u001b[A\n",
      "Training:  53%|█████▎    | 931/1772 [02:20<01:56,  7.21it/s, running training loss: 1.0521]\u001b[A\n",
      "Training:  53%|█████▎    | 931/1772 [02:20<01:56,  7.21it/s, running training loss: 1.0316]\u001b[A\n",
      "Training:  53%|█████▎    | 932/1772 [02:20<01:54,  7.32it/s, running training loss: 1.0316]\u001b[A\n",
      "Training:  53%|█████▎    | 932/1772 [02:20<01:54,  7.32it/s, running training loss: 1.0191]\u001b[A\n",
      "Training:  53%|█████▎    | 933/1772 [02:20<01:57,  7.16it/s, running training loss: 1.0191]\u001b[A\n",
      "Training:  53%|█████▎    | 933/1772 [02:21<01:57,  7.16it/s, running training loss: 1.0455]\u001b[A\n",
      "Training:  53%|█████▎    | 934/1772 [02:21<02:11,  6.36it/s, running training loss: 1.0455]\u001b[A\n",
      "Training:  53%|█████▎    | 934/1772 [02:21<02:11,  6.36it/s, running training loss: 0.9525]\u001b[A\n",
      "Training:  53%|█████▎    | 935/1772 [02:21<02:07,  6.58it/s, running training loss: 0.9525]\u001b[A\n",
      "Training:  53%|█████▎    | 935/1772 [02:21<02:07,  6.58it/s, running training loss: 0.8736]\u001b[A\n",
      "Training:  53%|█████▎    | 936/1772 [02:21<02:02,  6.85it/s, running training loss: 0.8736]\u001b[A\n",
      "Training:  53%|█████▎    | 936/1772 [02:21<02:02,  6.85it/s, running training loss: 1.0689]\u001b[A\n",
      "Training:  53%|█████▎    | 937/1772 [02:21<02:01,  6.89it/s, running training loss: 1.0689]\u001b[A\n",
      "Training:  53%|█████▎    | 937/1772 [02:21<02:01,  6.89it/s, running training loss: 1.0968]\u001b[A\n",
      "Training:  53%|█████▎    | 938/1772 [02:21<02:08,  6.49it/s, running training loss: 1.0968]\u001b[A\n",
      "Training:  53%|█████▎    | 938/1772 [02:21<02:08,  6.49it/s, running training loss: 1.0784]\u001b[A\n",
      "Training:  53%|█████▎    | 939/1772 [02:21<02:03,  6.77it/s, running training loss: 1.0784]\u001b[A\n",
      "Training:  53%|█████▎    | 939/1772 [02:22<02:03,  6.77it/s, running training loss: 1.0816]\u001b[A\n",
      "Training:  53%|█████▎    | 940/1772 [02:22<01:58,  7.04it/s, running training loss: 1.0816]\u001b[A\n",
      "Training:  53%|█████▎    | 940/1772 [02:22<01:58,  7.04it/s, running training loss: 0.8717]\u001b[A\n",
      "Training:  53%|█████▎    | 941/1772 [02:22<01:59,  6.97it/s, running training loss: 0.8717]\u001b[A\n",
      "Training:  53%|█████▎    | 941/1772 [02:22<01:59,  6.97it/s, running training loss: 0.9632]\u001b[A\n",
      "Training:  53%|█████▎    | 942/1772 [02:22<01:54,  7.24it/s, running training loss: 0.9632]\u001b[A\n",
      "Training:  53%|█████▎    | 942/1772 [02:22<01:54,  7.24it/s, running training loss: 0.9565]\u001b[A\n",
      "Training:  53%|█████▎    | 943/1772 [02:22<01:54,  7.22it/s, running training loss: 0.9565]\u001b[A\n",
      "Training:  53%|█████▎    | 943/1772 [02:22<01:54,  7.22it/s, running training loss: 0.9944]\u001b[A\n",
      "Training:  53%|█████▎    | 944/1772 [02:22<01:58,  6.99it/s, running training loss: 0.9944]\u001b[A\n",
      "Training:  53%|█████▎    | 944/1772 [02:22<01:58,  6.99it/s, running training loss: 1.0135]\u001b[A\n",
      "Training:  53%|█████▎    | 945/1772 [02:22<01:56,  7.07it/s, running training loss: 1.0135]\u001b[A\n",
      "Training:  53%|█████▎    | 945/1772 [02:22<01:56,  7.07it/s, running training loss: 1.0394]\u001b[A\n",
      "Training:  53%|█████▎    | 946/1772 [02:22<01:58,  6.98it/s, running training loss: 1.0394]\u001b[A\n",
      "Training:  53%|█████▎    | 946/1772 [02:23<01:58,  6.98it/s, running training loss: 1.2630]\u001b[A\n",
      "Training:  53%|█████▎    | 947/1772 [02:23<02:07,  6.49it/s, running training loss: 1.2630]\u001b[A\n",
      "Training:  53%|█████▎    | 947/1772 [02:23<02:07,  6.49it/s, running training loss: 1.1369]\u001b[A\n",
      "Training:  53%|█████▎    | 948/1772 [02:23<02:10,  6.33it/s, running training loss: 1.1369]\u001b[A\n",
      "Training:  53%|█████▎    | 948/1772 [02:23<02:10,  6.33it/s, running training loss: 1.0604]\u001b[A\n",
      "Training:  54%|█████▎    | 949/1772 [02:23<02:05,  6.55it/s, running training loss: 1.0604]\u001b[A\n",
      "Training:  54%|█████▎    | 949/1772 [02:23<02:05,  6.55it/s, running training loss: 0.9231]\u001b[A\n",
      "Training:  54%|█████▎    | 950/1772 [02:23<02:01,  6.74it/s, running training loss: 0.9231]\u001b[A\n",
      "Training:  54%|█████▎    | 950/1772 [02:23<02:01,  6.74it/s, running training loss: 0.9798]\u001b[A\n",
      "Training:  54%|█████▎    | 951/1772 [02:23<01:58,  6.95it/s, running training loss: 0.9798]\u001b[A\n",
      "Training:  54%|█████▎    | 951/1772 [02:23<01:58,  6.95it/s, running training loss: 0.8970]\u001b[A\n",
      "Training:  54%|█████▎    | 952/1772 [02:23<02:00,  6.83it/s, running training loss: 0.8970]\u001b[A\n",
      "Training:  54%|█████▎    | 952/1772 [02:23<02:00,  6.83it/s, running training loss: 0.9564]\u001b[A\n",
      "Training:  54%|█████▍    | 953/1772 [02:23<02:08,  6.38it/s, running training loss: 0.9564]\u001b[A\n",
      "Training:  54%|█████▍    | 953/1772 [02:24<02:08,  6.38it/s, running training loss: 0.9716]\u001b[A\n",
      "Training:  54%|█████▍    | 954/1772 [02:24<02:05,  6.53it/s, running training loss: 0.9716]\u001b[A\n",
      "Training:  54%|█████▍    | 954/1772 [02:24<02:05,  6.53it/s, running training loss: 0.8719]\u001b[A\n",
      "Training:  54%|█████▍    | 955/1772 [02:24<02:03,  6.63it/s, running training loss: 0.8719]\u001b[A\n",
      "Training:  54%|█████▍    | 955/1772 [02:24<02:03,  6.63it/s, running training loss: 0.9588]\u001b[A\n",
      "Training:  54%|█████▍    | 956/1772 [02:24<02:03,  6.60it/s, running training loss: 0.9588]\u001b[A\n",
      "Training:  54%|█████▍    | 956/1772 [02:24<02:03,  6.60it/s, running training loss: 1.1099]\u001b[A\n",
      "Training:  54%|█████▍    | 957/1772 [02:24<01:56,  6.99it/s, running training loss: 1.1099]\u001b[A\n",
      "Training:  54%|█████▍    | 957/1772 [02:24<01:56,  6.99it/s, running training loss: 1.0659]\u001b[A\n",
      "Training:  54%|█████▍    | 958/1772 [02:24<02:00,  6.78it/s, running training loss: 1.0659]\u001b[A\n",
      "Training:  54%|█████▍    | 958/1772 [02:24<02:00,  6.78it/s, running training loss: 1.0215]\u001b[A\n",
      "Training:  54%|█████▍    | 959/1772 [02:24<02:13,  6.10it/s, running training loss: 1.0215]\u001b[A\n",
      "Training:  54%|█████▍    | 959/1772 [02:25<02:13,  6.10it/s, running training loss: 0.9930]\u001b[A\n",
      "Training:  54%|█████▍    | 960/1772 [02:25<02:06,  6.39it/s, running training loss: 0.9930]\u001b[A\n",
      "Training:  54%|█████▍    | 960/1772 [02:25<02:06,  6.39it/s, running training loss: 0.9674]\u001b[A\n",
      "Training:  54%|█████▍    | 961/1772 [02:25<01:57,  6.89it/s, running training loss: 0.9674]\u001b[A\n",
      "Training:  54%|█████▍    | 961/1772 [02:25<01:57,  6.89it/s, running training loss: 0.8646]\u001b[A\n",
      "Training:  54%|█████▍    | 962/1772 [02:25<01:52,  7.17it/s, running training loss: 0.8646]\u001b[A\n",
      "Training:  54%|█████▍    | 962/1772 [02:25<01:52,  7.17it/s, running training loss: 0.8649]\u001b[A\n",
      "Training:  54%|█████▍    | 963/1772 [02:25<01:52,  7.17it/s, running training loss: 0.8649]\u001b[A\n",
      "Training:  54%|█████▍    | 963/1772 [02:25<01:52,  7.17it/s, running training loss: 1.0301]\u001b[A\n",
      "Training:  54%|█████▍    | 964/1772 [02:25<01:56,  6.92it/s, running training loss: 1.0301]\u001b[A\n",
      "Training:  54%|█████▍    | 964/1772 [02:25<01:56,  6.92it/s, running training loss: 1.1265]\u001b[A\n",
      "Training:  54%|█████▍    | 965/1772 [02:25<01:59,  6.76it/s, running training loss: 1.1265]\u001b[A\n",
      "Training:  54%|█████▍    | 965/1772 [02:25<01:59,  6.76it/s, running training loss: 0.9284]\u001b[A\n",
      "Training:  55%|█████▍    | 966/1772 [02:25<02:01,  6.65it/s, running training loss: 0.9284]\u001b[A\n",
      "Training:  55%|█████▍    | 966/1772 [02:26<02:01,  6.65it/s, running training loss: 1.0168]\u001b[A\n",
      "Training:  55%|█████▍    | 967/1772 [02:26<02:00,  6.67it/s, running training loss: 1.0168]\u001b[A\n",
      "Training:  55%|█████▍    | 967/1772 [02:26<02:00,  6.67it/s, running training loss: 1.0573]\u001b[A\n",
      "Training:  55%|█████▍    | 968/1772 [02:26<02:01,  6.60it/s, running training loss: 1.0573]\u001b[A\n",
      "Training:  55%|█████▍    | 968/1772 [02:26<02:01,  6.60it/s, running training loss: 1.0397]\u001b[A\n",
      "Training:  55%|█████▍    | 969/1772 [02:26<01:59,  6.72it/s, running training loss: 1.0397]\u001b[A\n",
      "Training:  55%|█████▍    | 969/1772 [02:26<01:59,  6.72it/s, running training loss: 0.9107]\u001b[A\n",
      "Training:  55%|█████▍    | 970/1772 [02:26<02:00,  6.64it/s, running training loss: 0.9107]\u001b[A\n",
      "Training:  55%|█████▍    | 970/1772 [02:26<02:00,  6.64it/s, running training loss: 0.9607]\u001b[A\n",
      "Training:  55%|█████▍    | 971/1772 [02:26<01:57,  6.82it/s, running training loss: 0.9607]\u001b[A\n",
      "Training:  55%|█████▍    | 971/1772 [02:26<01:57,  6.82it/s, running training loss: 0.9515]\u001b[A\n",
      "Training:  55%|█████▍    | 972/1772 [02:26<01:54,  6.97it/s, running training loss: 0.9515]\u001b[A\n",
      "Training:  55%|█████▍    | 972/1772 [02:26<01:54,  6.97it/s, running training loss: 0.9455]\u001b[A\n",
      "Training:  55%|█████▍    | 973/1772 [02:26<01:49,  7.29it/s, running training loss: 0.9455]\u001b[A\n",
      "Training:  55%|█████▍    | 973/1772 [02:27<01:49,  7.29it/s, running training loss: 0.8388]\u001b[A\n",
      "Training:  55%|█████▍    | 974/1772 [02:27<01:55,  6.94it/s, running training loss: 0.8388]\u001b[A\n",
      "Training:  55%|█████▍    | 974/1772 [02:27<01:55,  6.94it/s, running training loss: 0.8749]\u001b[A\n",
      "Training:  55%|█████▌    | 975/1772 [02:27<02:00,  6.62it/s, running training loss: 0.8749]\u001b[A\n",
      "Training:  55%|█████▌    | 975/1772 [02:27<02:00,  6.62it/s, running training loss: 0.9081]\u001b[A\n",
      "Training:  55%|█████▌    | 976/1772 [02:27<02:08,  6.19it/s, running training loss: 0.9081]\u001b[A\n",
      "Training:  55%|█████▌    | 976/1772 [02:27<02:08,  6.19it/s, running training loss: 1.0652]\u001b[A\n",
      "Training:  55%|█████▌    | 977/1772 [02:27<02:13,  5.95it/s, running training loss: 1.0652]\u001b[A\n",
      "Training:  55%|█████▌    | 977/1772 [02:27<02:13,  5.95it/s, running training loss: 0.9544]\u001b[A\n",
      "Training:  55%|█████▌    | 978/1772 [02:27<02:12,  6.00it/s, running training loss: 0.9544]\u001b[A\n",
      "Training:  55%|█████▌    | 978/1772 [02:27<02:12,  6.00it/s, running training loss: 0.9057]\u001b[A\n",
      "Training:  55%|█████▌    | 979/1772 [02:27<02:15,  5.87it/s, running training loss: 0.9057]\u001b[A\n",
      "Training:  55%|█████▌    | 979/1772 [02:28<02:15,  5.87it/s, running training loss: 0.9843]\u001b[A\n",
      "Training:  55%|█████▌    | 980/1772 [02:28<02:06,  6.28it/s, running training loss: 0.9843]\u001b[A\n",
      "Training:  55%|█████▌    | 980/1772 [02:28<02:06,  6.28it/s, running training loss: 1.2455]\u001b[A\n",
      "Training:  55%|█████▌    | 981/1772 [02:28<02:00,  6.56it/s, running training loss: 1.2455]\u001b[A\n",
      "Training:  55%|█████▌    | 981/1772 [02:28<02:00,  6.56it/s, running training loss: 0.8529]\u001b[A\n",
      "Training:  55%|█████▌    | 982/1772 [02:28<01:52,  7.04it/s, running training loss: 0.8529]\u001b[A\n",
      "Training:  55%|█████▌    | 982/1772 [02:28<01:52,  7.04it/s, running training loss: 0.9309]\u001b[A\n",
      "Training:  55%|█████▌    | 983/1772 [02:28<01:50,  7.14it/s, running training loss: 0.9309]\u001b[A\n",
      "Training:  55%|█████▌    | 983/1772 [02:28<01:50,  7.14it/s, running training loss: 0.9259]\u001b[A\n",
      "Training:  56%|█████▌    | 984/1772 [02:28<01:47,  7.34it/s, running training loss: 0.9259]\u001b[A\n",
      "Training:  56%|█████▌    | 984/1772 [02:28<01:47,  7.34it/s, running training loss: 0.9793]\u001b[A\n",
      "Training:  56%|█████▌    | 985/1772 [02:28<02:00,  6.54it/s, running training loss: 0.9793]\u001b[A\n",
      "Training:  56%|█████▌    | 985/1772 [02:28<02:00,  6.54it/s, running training loss: 1.0294]\u001b[A\n",
      "Training:  56%|█████▌    | 986/1772 [02:28<01:56,  6.72it/s, running training loss: 1.0294]\u001b[A\n",
      "Training:  56%|█████▌    | 986/1772 [02:29<01:56,  6.72it/s, running training loss: 0.8779]\u001b[A\n",
      "Training:  56%|█████▌    | 987/1772 [02:29<01:55,  6.81it/s, running training loss: 0.8779]\u001b[A\n",
      "Training:  56%|█████▌    | 987/1772 [02:29<01:55,  6.81it/s, running training loss: 0.9197]\u001b[A\n",
      "Training:  56%|█████▌    | 988/1772 [02:29<01:52,  6.97it/s, running training loss: 0.9197]\u001b[A\n",
      "Training:  56%|█████▌    | 988/1772 [02:29<01:52,  6.97it/s, running training loss: 0.8602]\u001b[A\n",
      "Training:  56%|█████▌    | 989/1772 [02:29<01:48,  7.22it/s, running training loss: 0.8602]\u001b[A\n",
      "Training:  56%|█████▌    | 989/1772 [02:29<01:48,  7.22it/s, running training loss: 1.0774]\u001b[A\n",
      "Training:  56%|█████▌    | 990/1772 [02:29<01:46,  7.33it/s, running training loss: 1.0774]\u001b[A\n",
      "Training:  56%|█████▌    | 990/1772 [02:29<01:46,  7.33it/s, running training loss: 0.9863]\u001b[A\n",
      "Training:  56%|█████▌    | 991/1772 [02:29<01:49,  7.12it/s, running training loss: 0.9863]\u001b[A\n",
      "Training:  56%|█████▌    | 991/1772 [02:29<01:49,  7.12it/s, running training loss: 0.8797]\u001b[A\n",
      "Training:  56%|█████▌    | 992/1772 [02:29<01:48,  7.16it/s, running training loss: 0.8797]\u001b[A\n",
      "Training:  56%|█████▌    | 992/1772 [02:29<01:48,  7.16it/s, running training loss: 1.0859]\u001b[A\n",
      "Training:  56%|█████▌    | 993/1772 [02:29<01:59,  6.50it/s, running training loss: 1.0859]\u001b[A\n",
      "Training:  56%|█████▌    | 993/1772 [02:30<01:59,  6.50it/s, running training loss: 1.0513]\u001b[A\n",
      "Training:  56%|█████▌    | 994/1772 [02:30<01:58,  6.55it/s, running training loss: 1.0513]\u001b[A\n",
      "Training:  56%|█████▌    | 994/1772 [02:30<01:58,  6.55it/s, running training loss: 0.8704]\u001b[A\n",
      "Training:  56%|█████▌    | 995/1772 [02:30<01:53,  6.83it/s, running training loss: 0.8704]\u001b[A\n",
      "Training:  56%|█████▌    | 995/1772 [02:30<01:53,  6.83it/s, running training loss: 1.1485]\u001b[A\n",
      "Training:  56%|█████▌    | 996/1772 [02:30<01:55,  6.71it/s, running training loss: 1.1485]\u001b[A\n",
      "Training:  56%|█████▌    | 996/1772 [02:30<01:55,  6.71it/s, running training loss: 0.8841]\u001b[A\n",
      "Training:  56%|█████▋    | 997/1772 [02:30<01:57,  6.60it/s, running training loss: 0.8841]\u001b[A\n",
      "Training:  56%|█████▋    | 997/1772 [02:30<01:57,  6.60it/s, running training loss: 1.2894]\u001b[A\n",
      "Training:  56%|█████▋    | 998/1772 [02:30<01:59,  6.50it/s, running training loss: 1.2894]\u001b[A\n",
      "Training:  56%|█████▋    | 998/1772 [02:30<01:59,  6.50it/s, running training loss: 1.0164]\u001b[A\n",
      "Training:  56%|█████▋    | 999/1772 [02:30<02:12,  5.83it/s, running training loss: 1.0164]\u001b[A\n",
      "Training:  56%|█████▋    | 999/1772 [02:31<02:12,  5.83it/s, running training loss: 1.2336]\u001b[A\n",
      "Training:  56%|█████▋    | 1000/1772 [02:31<02:02,  6.28it/s, running training loss: 1.2336]\u001b[A\n",
      "Training:  56%|█████▋    | 1000/1772 [02:31<02:02,  6.28it/s, running training loss: 1.0607]\u001b[A\n",
      "Training:  56%|█████▋    | 1001/1772 [02:31<01:54,  6.73it/s, running training loss: 1.0607]\u001b[A\n",
      "Training:  56%|█████▋    | 1001/1772 [02:31<01:54,  6.73it/s, running training loss: 1.4354]\u001b[A\n",
      "Training:  57%|█████▋    | 1002/1772 [02:31<01:54,  6.74it/s, running training loss: 1.4354]\u001b[A\n",
      "Training:  57%|█████▋    | 1002/1772 [02:31<01:54,  6.74it/s, running training loss: 0.9631]\u001b[A\n",
      "Training:  57%|█████▋    | 1003/1772 [02:31<01:55,  6.64it/s, running training loss: 0.9631]\u001b[A\n",
      "Training:  57%|█████▋    | 1003/1772 [02:31<01:55,  6.64it/s, running training loss: 1.2744]\u001b[A\n",
      "Training:  57%|█████▋    | 1004/1772 [02:31<02:01,  6.30it/s, running training loss: 1.2744]\u001b[A\n",
      "Training:  57%|█████▋    | 1004/1772 [02:31<02:01,  6.30it/s, running training loss: 1.2728]\u001b[A\n",
      "Training:  57%|█████▋    | 1005/1772 [02:31<02:04,  6.16it/s, running training loss: 1.2728]\u001b[A\n",
      "Training:  57%|█████▋    | 1005/1772 [02:31<02:04,  6.16it/s, running training loss: 1.0349]\u001b[A\n",
      "Training:  57%|█████▋    | 1006/1772 [02:31<02:02,  6.26it/s, running training loss: 1.0349]\u001b[A\n",
      "Training:  57%|█████▋    | 1006/1772 [02:32<02:02,  6.26it/s, running training loss: 0.9224]\u001b[A\n",
      "Training:  57%|█████▋    | 1007/1772 [02:32<01:58,  6.47it/s, running training loss: 0.9224]\u001b[A\n",
      "Training:  57%|█████▋    | 1007/1772 [02:32<01:58,  6.47it/s, running training loss: 0.9306]\u001b[A\n",
      "Training:  57%|█████▋    | 1008/1772 [02:32<02:02,  6.22it/s, running training loss: 0.9306]\u001b[A\n",
      "Training:  57%|█████▋    | 1008/1772 [02:32<02:02,  6.22it/s, running training loss: 0.9742]\u001b[A\n",
      "Training:  57%|█████▋    | 1009/1772 [02:32<01:55,  6.62it/s, running training loss: 0.9742]\u001b[A\n",
      "Training:  57%|█████▋    | 1009/1772 [02:32<01:55,  6.62it/s, running training loss: 0.9211]\u001b[A\n",
      "Training:  57%|█████▋    | 1010/1772 [02:32<01:50,  6.91it/s, running training loss: 0.9211]\u001b[A\n",
      "Training:  57%|█████▋    | 1010/1772 [02:32<01:50,  6.91it/s, running training loss: 1.2594]\u001b[A\n",
      "Training:  57%|█████▋    | 1011/1772 [02:32<01:54,  6.62it/s, running training loss: 1.2594]\u001b[A\n",
      "Training:  57%|█████▋    | 1011/1772 [02:32<01:54,  6.62it/s, running training loss: 0.8137]\u001b[A\n",
      "Training:  57%|█████▋    | 1012/1772 [02:32<01:49,  6.93it/s, running training loss: 0.8137]\u001b[A\n",
      "Training:  57%|█████▋    | 1012/1772 [02:32<01:49,  6.93it/s, running training loss: 0.9195]\u001b[A\n",
      "Training:  57%|█████▋    | 1013/1772 [02:32<01:47,  7.04it/s, running training loss: 0.9195]\u001b[A\n",
      "Training:  57%|█████▋    | 1013/1772 [02:33<01:47,  7.04it/s, running training loss: 0.9669]\u001b[A\n",
      "Training:  57%|█████▋    | 1014/1772 [02:33<01:43,  7.29it/s, running training loss: 0.9669]\u001b[A\n",
      "Training:  57%|█████▋    | 1014/1772 [02:33<01:43,  7.29it/s, running training loss: 0.8859]\u001b[A\n",
      "Training:  57%|█████▋    | 1015/1772 [02:33<01:44,  7.25it/s, running training loss: 0.8859]\u001b[A\n",
      "Training:  57%|█████▋    | 1015/1772 [02:33<01:44,  7.25it/s, running training loss: 1.2225]\u001b[A\n",
      "Training:  57%|█████▋    | 1016/1772 [02:33<01:44,  7.24it/s, running training loss: 1.2225]\u001b[A\n",
      "Training:  57%|█████▋    | 1016/1772 [02:33<01:44,  7.24it/s, running training loss: 1.2586]\u001b[A\n",
      "Training:  57%|█████▋    | 1017/1772 [02:33<02:01,  6.19it/s, running training loss: 1.2586]\u001b[A\n",
      "Training:  57%|█████▋    | 1017/1772 [02:33<02:01,  6.19it/s, running training loss: 1.5277]\u001b[A\n",
      "Training:  57%|█████▋    | 1018/1772 [02:33<02:02,  6.18it/s, running training loss: 1.5277]\u001b[A\n",
      "Training:  57%|█████▋    | 1018/1772 [02:33<02:02,  6.18it/s, running training loss: 1.0873]\u001b[A\n",
      "Training:  58%|█████▊    | 1019/1772 [02:33<02:13,  5.64it/s, running training loss: 1.0873]\u001b[A\n",
      "Training:  58%|█████▊    | 1019/1772 [02:34<02:13,  5.64it/s, running training loss: 1.2634]\u001b[A\n",
      "Training:  58%|█████▊    | 1020/1772 [02:34<02:10,  5.75it/s, running training loss: 1.2634]\u001b[A\n",
      "Training:  58%|█████▊    | 1020/1772 [02:34<02:10,  5.75it/s, running training loss: 1.1071]\u001b[A\n",
      "Training:  58%|█████▊    | 1021/1772 [02:34<02:08,  5.86it/s, running training loss: 1.1071]\u001b[A\n",
      "Training:  58%|█████▊    | 1021/1772 [02:34<02:08,  5.86it/s, running training loss: 1.1974]\u001b[A\n",
      "Training:  58%|█████▊    | 1022/1772 [02:34<02:00,  6.23it/s, running training loss: 1.1974]\u001b[A\n",
      "Training:  58%|█████▊    | 1022/1772 [02:34<02:00,  6.23it/s, running training loss: 1.2343]\u001b[A\n",
      "Training:  58%|█████▊    | 1023/1772 [02:34<01:55,  6.50it/s, running training loss: 1.2343]\u001b[A\n",
      "Training:  58%|█████▊    | 1023/1772 [02:34<01:55,  6.50it/s, running training loss: 1.2180]\u001b[A\n",
      "Training:  58%|█████▊    | 1024/1772 [02:34<01:49,  6.83it/s, running training loss: 1.2180]\u001b[A\n",
      "Training:  58%|█████▊    | 1024/1772 [02:34<01:49,  6.83it/s, running training loss: 1.0908]\u001b[A\n",
      "Training:  58%|█████▊    | 1025/1772 [02:34<01:48,  6.86it/s, running training loss: 1.0908]\u001b[A\n",
      "Training:  58%|█████▊    | 1025/1772 [02:35<01:48,  6.86it/s, running training loss: 1.0350]\u001b[A\n",
      "Training:  58%|█████▊    | 1026/1772 [02:35<01:57,  6.34it/s, running training loss: 1.0350]\u001b[A\n",
      "Training:  58%|█████▊    | 1026/1772 [02:35<01:57,  6.34it/s, running training loss: 0.8673]\u001b[A\n",
      "Training:  58%|█████▊    | 1027/1772 [02:35<02:04,  5.96it/s, running training loss: 0.8673]\u001b[A\n",
      "Training:  58%|█████▊    | 1027/1772 [02:35<02:04,  5.96it/s, running training loss: 0.8940]\u001b[A\n",
      "Training:  58%|█████▊    | 1028/1772 [02:35<01:58,  6.30it/s, running training loss: 0.8940]\u001b[A\n",
      "Training:  58%|█████▊    | 1028/1772 [02:35<01:58,  6.30it/s, running training loss: 1.0628]\u001b[A\n",
      "Training:  58%|█████▊    | 1029/1772 [02:35<01:57,  6.34it/s, running training loss: 1.0628]\u001b[A\n",
      "Training:  58%|█████▊    | 1029/1772 [02:35<01:57,  6.34it/s, running training loss: 0.9135]\u001b[A\n",
      "Training:  58%|█████▊    | 1030/1772 [02:35<01:56,  6.35it/s, running training loss: 0.9135]\u001b[A\n",
      "Training:  58%|█████▊    | 1030/1772 [02:35<01:56,  6.35it/s, running training loss: 1.0677]\u001b[A\n",
      "Training:  58%|█████▊    | 1031/1772 [02:35<01:57,  6.28it/s, running training loss: 1.0677]\u001b[A\n",
      "Training:  58%|█████▊    | 1031/1772 [02:35<01:57,  6.28it/s, running training loss: 1.0681]\u001b[A\n",
      "Training:  58%|█████▊    | 1032/1772 [02:35<01:52,  6.56it/s, running training loss: 1.0681]\u001b[A\n",
      "Training:  58%|█████▊    | 1032/1772 [02:36<01:52,  6.56it/s, running training loss: 1.0626]\u001b[A\n",
      "Training:  58%|█████▊    | 1033/1772 [02:36<01:49,  6.72it/s, running training loss: 1.0626]\u001b[A\n",
      "Training:  58%|█████▊    | 1033/1772 [02:36<01:49,  6.72it/s, running training loss: 0.9819]\u001b[A\n",
      "Training:  58%|█████▊    | 1034/1772 [02:36<01:51,  6.61it/s, running training loss: 0.9819]\u001b[A\n",
      "Training:  58%|█████▊    | 1034/1772 [02:36<01:51,  6.61it/s, running training loss: 0.8911]\u001b[A\n",
      "Training:  58%|█████▊    | 1035/1772 [02:36<01:48,  6.77it/s, running training loss: 0.8911]\u001b[A\n",
      "Training:  58%|█████▊    | 1035/1772 [02:36<01:48,  6.77it/s, running training loss: 0.8306]\u001b[A\n",
      "Training:  58%|█████▊    | 1036/1772 [02:36<01:51,  6.63it/s, running training loss: 0.8306]\u001b[A\n",
      "Training:  58%|█████▊    | 1036/1772 [02:36<01:51,  6.63it/s, running training loss: 1.1133]\u001b[A\n",
      "Training:  59%|█████▊    | 1037/1772 [02:36<01:51,  6.60it/s, running training loss: 1.1133]\u001b[A\n",
      "Training:  59%|█████▊    | 1037/1772 [02:36<01:51,  6.60it/s, running training loss: 0.9239]\u001b[A\n",
      "Training:  59%|█████▊    | 1038/1772 [02:36<01:48,  6.78it/s, running training loss: 0.9239]\u001b[A\n",
      "Training:  59%|█████▊    | 1038/1772 [02:36<01:48,  6.78it/s, running training loss: 0.9643]\u001b[A\n",
      "Training:  59%|█████▊    | 1039/1772 [02:36<01:49,  6.68it/s, running training loss: 0.9643]\u001b[A\n",
      "Training:  59%|█████▊    | 1039/1772 [02:37<01:49,  6.68it/s, running training loss: 1.1393]\u001b[A\n",
      "Training:  59%|█████▊    | 1040/1772 [02:37<01:46,  6.86it/s, running training loss: 1.1393]\u001b[A\n",
      "Training:  59%|█████▊    | 1040/1772 [02:37<01:46,  6.86it/s, running training loss: 1.3046]\u001b[A\n",
      "Training:  59%|█████▊    | 1041/1772 [02:37<01:42,  7.13it/s, running training loss: 1.3046]\u001b[A\n",
      "Training:  59%|█████▊    | 1041/1772 [02:37<01:42,  7.13it/s, running training loss: 0.9500]\u001b[A\n",
      "Training:  59%|█████▉    | 1042/1772 [02:37<01:41,  7.21it/s, running training loss: 0.9500]\u001b[A\n",
      "Training:  59%|█████▉    | 1042/1772 [02:37<01:41,  7.21it/s, running training loss: 0.9956]\u001b[A\n",
      "Training:  59%|█████▉    | 1043/1772 [02:37<01:42,  7.08it/s, running training loss: 0.9956]\u001b[A\n",
      "Training:  59%|█████▉    | 1043/1772 [02:37<01:42,  7.08it/s, running training loss: 1.0290]\u001b[A\n",
      "Training:  59%|█████▉    | 1044/1772 [02:37<01:43,  7.01it/s, running training loss: 1.0290]\u001b[A\n",
      "Training:  59%|█████▉    | 1044/1772 [02:37<01:43,  7.01it/s, running training loss: 1.2105]\u001b[A\n",
      "Training:  59%|█████▉    | 1045/1772 [02:37<01:50,  6.60it/s, running training loss: 1.2105]\u001b[A\n",
      "Training:  59%|█████▉    | 1045/1772 [02:38<01:50,  6.60it/s, running training loss: 1.3973]\u001b[A\n",
      "Training:  59%|█████▉    | 1046/1772 [02:38<02:01,  5.97it/s, running training loss: 1.3973]\u001b[A\n",
      "Training:  59%|█████▉    | 1046/1772 [02:38<02:01,  5.97it/s, running training loss: 1.3382]\u001b[A\n",
      "Training:  59%|█████▉    | 1047/1772 [02:38<01:55,  6.26it/s, running training loss: 1.3382]\u001b[A\n",
      "Training:  59%|█████▉    | 1047/1772 [02:38<01:55,  6.26it/s, running training loss: 1.0070]\u001b[A\n",
      "Training:  59%|█████▉    | 1048/1772 [02:38<01:48,  6.65it/s, running training loss: 1.0070]\u001b[A\n",
      "Training:  59%|█████▉    | 1048/1772 [02:38<01:48,  6.65it/s, running training loss: 1.1177]\u001b[A\n",
      "Training:  59%|█████▉    | 1049/1772 [02:38<01:48,  6.65it/s, running training loss: 1.1177]\u001b[A\n",
      "Training:  59%|█████▉    | 1049/1772 [02:38<01:48,  6.65it/s, running training loss: 0.9291]\u001b[A\n",
      "Training:  59%|█████▉    | 1050/1772 [02:38<01:46,  6.77it/s, running training loss: 0.9291]\u001b[A\n",
      "Training:  59%|█████▉    | 1050/1772 [02:38<01:46,  6.77it/s, running training loss: 0.9518]\u001b[A\n",
      "Training:  59%|█████▉    | 1051/1772 [02:38<01:49,  6.56it/s, running training loss: 0.9518]\u001b[A\n",
      "Training:  59%|█████▉    | 1051/1772 [02:38<01:49,  6.56it/s, running training loss: 0.7771]\u001b[A\n",
      "Training:  59%|█████▉    | 1052/1772 [02:38<01:50,  6.51it/s, running training loss: 0.7771]\u001b[A\n",
      "Training:  59%|█████▉    | 1052/1772 [02:39<01:50,  6.51it/s, running training loss: 1.0904]\u001b[A\n",
      "Training:  59%|█████▉    | 1053/1772 [02:39<01:44,  6.86it/s, running training loss: 1.0904]\u001b[A\n",
      "Training:  59%|█████▉    | 1053/1772 [02:39<01:44,  6.86it/s, running training loss: 0.8487]\u001b[A\n",
      "Training:  59%|█████▉    | 1054/1772 [02:39<01:41,  7.05it/s, running training loss: 0.8487]\u001b[A\n",
      "Training:  59%|█████▉    | 1054/1772 [02:39<01:41,  7.05it/s, running training loss: 0.8062]\u001b[A\n",
      "Training:  60%|█████▉    | 1055/1772 [02:39<01:39,  7.21it/s, running training loss: 0.8062]\u001b[A\n",
      "Training:  60%|█████▉    | 1055/1772 [02:39<01:39,  7.21it/s, running training loss: 0.8374]\u001b[A\n",
      "Training:  60%|█████▉    | 1056/1772 [02:39<01:38,  7.28it/s, running training loss: 0.8374]\u001b[A\n",
      "Training:  60%|█████▉    | 1056/1772 [02:39<01:38,  7.28it/s, running training loss: 1.0362]\u001b[A\n",
      "Training:  60%|█████▉    | 1057/1772 [02:39<01:38,  7.27it/s, running training loss: 1.0362]\u001b[A\n",
      "Training:  60%|█████▉    | 1057/1772 [02:39<01:38,  7.27it/s, running training loss: 1.3655]\u001b[A\n",
      "Training:  60%|█████▉    | 1058/1772 [02:39<01:41,  7.07it/s, running training loss: 1.3655]\u001b[A\n",
      "Training:  60%|█████▉    | 1058/1772 [02:39<01:41,  7.07it/s, running training loss: 1.1833]\u001b[A\n",
      "Training:  60%|█████▉    | 1059/1772 [02:39<01:37,  7.32it/s, running training loss: 1.1833]\u001b[A\n",
      "Training:  60%|█████▉    | 1059/1772 [02:40<01:37,  7.32it/s, running training loss: 1.1589]\u001b[A\n",
      "Training:  60%|█████▉    | 1060/1772 [02:40<01:37,  7.28it/s, running training loss: 1.1589]\u001b[A\n",
      "Training:  60%|█████▉    | 1060/1772 [02:40<01:37,  7.28it/s, running training loss: 1.1295]\u001b[A\n",
      "Training:  60%|█████▉    | 1061/1772 [02:40<01:41,  7.03it/s, running training loss: 1.1295]\u001b[A\n",
      "Training:  60%|█████▉    | 1061/1772 [02:40<01:41,  7.03it/s, running training loss: 1.1884]\u001b[A\n",
      "Training:  60%|█████▉    | 1062/1772 [02:40<01:40,  7.03it/s, running training loss: 1.1884]\u001b[A\n",
      "Training:  60%|█████▉    | 1062/1772 [02:40<01:40,  7.03it/s, running training loss: 1.0422]\u001b[A\n",
      "Training:  60%|█████▉    | 1063/1772 [02:40<01:39,  7.10it/s, running training loss: 1.0422]\u001b[A\n",
      "Training:  60%|█████▉    | 1063/1772 [02:40<01:39,  7.10it/s, running training loss: 1.0160]\u001b[A\n",
      "Training:  60%|██████    | 1064/1772 [02:40<01:35,  7.39it/s, running training loss: 1.0160]\u001b[A\n",
      "Training:  60%|██████    | 1064/1772 [02:40<01:35,  7.39it/s, running training loss: 0.8302]\u001b[A\n",
      "Training:  60%|██████    | 1065/1772 [02:40<01:37,  7.26it/s, running training loss: 0.8302]\u001b[A\n",
      "Training:  60%|██████    | 1065/1772 [02:40<01:37,  7.26it/s, running training loss: 0.9120]\u001b[A\n",
      "Training:  60%|██████    | 1066/1772 [02:40<01:33,  7.51it/s, running training loss: 0.9120]\u001b[A\n",
      "Training:  60%|██████    | 1066/1772 [02:40<01:33,  7.51it/s, running training loss: 1.0318]\u001b[A\n",
      "Training:  60%|██████    | 1067/1772 [02:40<01:36,  7.31it/s, running training loss: 1.0318]\u001b[A\n",
      "Training:  60%|██████    | 1067/1772 [02:41<01:36,  7.31it/s, running training loss: 1.0149]\u001b[A\n",
      "Training:  60%|██████    | 1068/1772 [02:41<01:35,  7.36it/s, running training loss: 1.0149]\u001b[A\n",
      "Training:  60%|██████    | 1068/1772 [02:41<01:35,  7.36it/s, running training loss: 0.8354]\u001b[A\n",
      "Training:  60%|██████    | 1069/1772 [02:41<01:35,  7.34it/s, running training loss: 0.8354]\u001b[A\n",
      "Training:  60%|██████    | 1069/1772 [02:41<01:35,  7.34it/s, running training loss: 1.1195]\u001b[A\n",
      "Training:  60%|██████    | 1070/1772 [02:41<01:40,  6.96it/s, running training loss: 1.1195]\u001b[A\n",
      "Training:  60%|██████    | 1070/1772 [02:41<01:40,  6.96it/s, running training loss: 0.9016]\u001b[A\n",
      "Training:  60%|██████    | 1071/1772 [02:41<01:55,  6.08it/s, running training loss: 0.9016]\u001b[A\n",
      "Training:  60%|██████    | 1071/1772 [02:41<01:55,  6.08it/s, running training loss: 1.1631]\u001b[A\n",
      "Training:  60%|██████    | 1072/1772 [02:41<01:55,  6.05it/s, running training loss: 1.1631]\u001b[A\n",
      "Training:  60%|██████    | 1072/1772 [02:41<01:55,  6.05it/s, running training loss: 0.9990]\u001b[A\n",
      "Training:  61%|██████    | 1073/1772 [02:41<01:47,  6.53it/s, running training loss: 0.9990]\u001b[A\n",
      "Training:  61%|██████    | 1073/1772 [02:42<01:47,  6.53it/s, running training loss: 0.9902]\u001b[A\n",
      "Training:  61%|██████    | 1074/1772 [02:42<01:45,  6.59it/s, running training loss: 0.9902]\u001b[A\n",
      "Training:  61%|██████    | 1074/1772 [02:42<01:45,  6.59it/s, running training loss: 1.0867]\u001b[A\n",
      "Training:  61%|██████    | 1075/1772 [02:42<01:43,  6.72it/s, running training loss: 1.0867]\u001b[A\n",
      "Training:  61%|██████    | 1075/1772 [02:42<01:43,  6.72it/s, running training loss: 0.9890]\u001b[A\n",
      "Training:  61%|██████    | 1076/1772 [02:42<01:39,  6.99it/s, running training loss: 0.9890]\u001b[A\n",
      "Training:  61%|██████    | 1076/1772 [02:42<01:39,  6.99it/s, running training loss: 1.2888]\u001b[A\n",
      "Training:  61%|██████    | 1077/1772 [02:42<01:38,  7.07it/s, running training loss: 1.2888]\u001b[A\n",
      "Training:  61%|██████    | 1077/1772 [02:42<01:38,  7.07it/s, running training loss: 0.8508]\u001b[A\n",
      "Training:  61%|██████    | 1078/1772 [02:42<01:36,  7.16it/s, running training loss: 0.8508]\u001b[A\n",
      "Training:  61%|██████    | 1078/1772 [02:42<01:36,  7.16it/s, running training loss: 0.8569]\u001b[A\n",
      "Training:  61%|██████    | 1079/1772 [02:42<01:40,  6.88it/s, running training loss: 0.8569]\u001b[A\n",
      "Training:  61%|██████    | 1079/1772 [02:42<01:40,  6.88it/s, running training loss: 1.0194]\u001b[A\n",
      "Training:  61%|██████    | 1080/1772 [02:42<01:39,  6.95it/s, running training loss: 1.0194]\u001b[A\n",
      "Training:  61%|██████    | 1080/1772 [02:43<01:39,  6.95it/s, running training loss: 0.9014]\u001b[A\n",
      "Training:  61%|██████    | 1081/1772 [02:43<01:37,  7.09it/s, running training loss: 0.9014]\u001b[A\n",
      "Training:  61%|██████    | 1081/1772 [02:43<01:37,  7.09it/s, running training loss: 0.8364]\u001b[A\n",
      "Training:  61%|██████    | 1082/1772 [02:43<01:40,  6.86it/s, running training loss: 0.8364]\u001b[A\n",
      "Training:  61%|██████    | 1082/1772 [02:43<01:40,  6.86it/s, running training loss: 0.8793]\u001b[A\n",
      "Training:  61%|██████    | 1083/1772 [02:43<01:39,  6.95it/s, running training loss: 0.8793]\u001b[A\n",
      "Training:  61%|██████    | 1083/1772 [02:43<01:39,  6.95it/s, running training loss: 1.0798]\u001b[A\n",
      "Training:  61%|██████    | 1084/1772 [02:43<01:42,  6.74it/s, running training loss: 1.0798]\u001b[A\n",
      "Training:  61%|██████    | 1084/1772 [02:43<01:42,  6.74it/s, running training loss: 1.3041]\u001b[A\n",
      "Training:  61%|██████    | 1085/1772 [02:43<01:38,  6.96it/s, running training loss: 1.3041]\u001b[A\n",
      "Training:  61%|██████    | 1085/1772 [02:43<01:38,  6.96it/s, running training loss: 1.5629]\u001b[A\n",
      "Training:  61%|██████▏   | 1086/1772 [02:43<01:43,  6.63it/s, running training loss: 1.5629]\u001b[A\n",
      "Training:  61%|██████▏   | 1086/1772 [02:43<01:43,  6.63it/s, running training loss: 1.2692]\u001b[A\n",
      "Training:  61%|██████▏   | 1087/1772 [02:43<01:42,  6.69it/s, running training loss: 1.2692]\u001b[A\n",
      "Training:  61%|██████▏   | 1087/1772 [02:44<01:42,  6.69it/s, running training loss: 1.6351]\u001b[A\n",
      "Training:  61%|██████▏   | 1088/1772 [02:44<01:42,  6.66it/s, running training loss: 1.6351]\u001b[A\n",
      "Training:  61%|██████▏   | 1088/1772 [02:44<01:42,  6.66it/s, running training loss: 1.1827]\u001b[A\n",
      "Training:  61%|██████▏   | 1089/1772 [02:44<01:43,  6.62it/s, running training loss: 1.1827]\u001b[A\n",
      "Training:  61%|██████▏   | 1089/1772 [02:44<01:43,  6.62it/s, running training loss: 1.0654]\u001b[A\n",
      "Training:  62%|██████▏   | 1090/1772 [02:44<01:42,  6.65it/s, running training loss: 1.0654]\u001b[A\n",
      "Training:  62%|██████▏   | 1090/1772 [02:44<01:42,  6.65it/s, running training loss: 1.2412]\u001b[A\n",
      "Training:  62%|██████▏   | 1091/1772 [02:44<01:38,  6.95it/s, running training loss: 1.2412]\u001b[A\n",
      "Training:  62%|██████▏   | 1091/1772 [02:44<01:38,  6.95it/s, running training loss: 1.1863]\u001b[A\n",
      "Training:  62%|██████▏   | 1092/1772 [02:44<01:50,  6.14it/s, running training loss: 1.1863]\u001b[A\n",
      "Training:  62%|██████▏   | 1092/1772 [02:44<01:50,  6.14it/s, running training loss: 0.8858]\u001b[A\n",
      "Training:  62%|██████▏   | 1093/1772 [02:44<01:54,  5.92it/s, running training loss: 0.8858]\u001b[A\n",
      "Training:  62%|██████▏   | 1093/1772 [02:45<01:54,  5.92it/s, running training loss: 0.9397]\u001b[A\n",
      "Training:  62%|██████▏   | 1094/1772 [02:45<01:48,  6.23it/s, running training loss: 0.9397]\u001b[A\n",
      "Training:  62%|██████▏   | 1094/1772 [02:45<01:48,  6.23it/s, running training loss: 0.9812]\u001b[A\n",
      "Training:  62%|██████▏   | 1095/1772 [02:45<01:41,  6.68it/s, running training loss: 0.9812]\u001b[A\n",
      "Training:  62%|██████▏   | 1095/1772 [02:45<01:41,  6.68it/s, running training loss: 0.9333]\u001b[A\n",
      "Training:  62%|██████▏   | 1096/1772 [02:45<01:48,  6.24it/s, running training loss: 0.9333]\u001b[A\n",
      "Training:  62%|██████▏   | 1096/1772 [02:45<01:48,  6.24it/s, running training loss: 0.8236]\u001b[A\n",
      "Training:  62%|██████▏   | 1097/1772 [02:45<01:43,  6.54it/s, running training loss: 0.8236]\u001b[A\n",
      "Training:  62%|██████▏   | 1097/1772 [02:45<01:43,  6.54it/s, running training loss: 0.9208]\u001b[A\n",
      "Training:  62%|██████▏   | 1098/1772 [02:45<01:43,  6.52it/s, running training loss: 0.9208]\u001b[A\n",
      "Training:  62%|██████▏   | 1098/1772 [02:45<01:43,  6.52it/s, running training loss: 0.9699]\u001b[A\n",
      "Training:  62%|██████▏   | 1099/1772 [02:45<01:44,  6.44it/s, running training loss: 0.9699]\u001b[A\n",
      "Training:  62%|██████▏   | 1099/1772 [02:45<01:44,  6.44it/s, running training loss: 0.8260]\u001b[A\n",
      "Training:  62%|██████▏   | 1100/1772 [02:45<01:45,  6.39it/s, running training loss: 0.8260]\u001b[A\n",
      "Training:  62%|██████▏   | 1100/1772 [02:46<01:45,  6.39it/s, running training loss: 0.9587]\u001b[A\n",
      "Training:  62%|██████▏   | 1101/1772 [02:46<01:51,  6.03it/s, running training loss: 0.9587]\u001b[A\n",
      "Training:  62%|██████▏   | 1101/1772 [02:46<01:51,  6.03it/s, running training loss: 0.9497]\u001b[A\n",
      "Training:  62%|██████▏   | 1102/1772 [02:46<01:41,  6.58it/s, running training loss: 0.9497]\u001b[A\n",
      "Training:  62%|██████▏   | 1102/1772 [02:46<01:41,  6.58it/s, running training loss: 1.0132]\u001b[A\n",
      "Training:  62%|██████▏   | 1103/1772 [02:46<01:36,  6.94it/s, running training loss: 1.0132]\u001b[A\n",
      "Training:  62%|██████▏   | 1103/1772 [02:46<01:36,  6.94it/s, running training loss: 0.9071]\u001b[A\n",
      "Training:  62%|██████▏   | 1104/1772 [02:46<01:41,  6.55it/s, running training loss: 0.9071]\u001b[A\n",
      "Training:  62%|██████▏   | 1104/1772 [02:46<01:41,  6.55it/s, running training loss: 0.8271]\u001b[A\n",
      "Training:  62%|██████▏   | 1105/1772 [02:46<01:40,  6.64it/s, running training loss: 0.8271]\u001b[A\n",
      "Training:  62%|██████▏   | 1105/1772 [02:46<01:40,  6.64it/s, running training loss: 0.9082]\u001b[A\n",
      "Training:  62%|██████▏   | 1106/1772 [02:46<01:38,  6.79it/s, running training loss: 0.9082]\u001b[A\n",
      "Training:  62%|██████▏   | 1106/1772 [02:47<01:38,  6.79it/s, running training loss: 1.1085]\u001b[A\n",
      "Training:  62%|██████▏   | 1107/1772 [02:47<01:43,  6.43it/s, running training loss: 1.1085]\u001b[A\n",
      "Training:  62%|██████▏   | 1107/1772 [02:47<01:43,  6.43it/s, running training loss: 0.9017]\u001b[A\n",
      "Training:  63%|██████▎   | 1108/1772 [02:47<01:49,  6.08it/s, running training loss: 0.9017]\u001b[A\n",
      "Training:  63%|██████▎   | 1108/1772 [02:47<01:49,  6.08it/s, running training loss: 1.0226]\u001b[A\n",
      "Training:  63%|██████▎   | 1109/1772 [02:47<01:47,  6.19it/s, running training loss: 1.0226]\u001b[A\n",
      "Training:  63%|██████▎   | 1109/1772 [02:47<01:47,  6.19it/s, running training loss: 0.8500]\u001b[A\n",
      "Training:  63%|██████▎   | 1110/1772 [02:47<01:40,  6.60it/s, running training loss: 0.8500]\u001b[A\n",
      "Training:  63%|██████▎   | 1110/1772 [02:47<01:40,  6.60it/s, running training loss: 1.1772]\u001b[A\n",
      "Training:  63%|██████▎   | 1111/1772 [02:47<01:49,  6.02it/s, running training loss: 1.1772]\u001b[A\n",
      "Training:  63%|██████▎   | 1111/1772 [02:47<01:49,  6.02it/s, running training loss: 0.8682]\u001b[A\n",
      "Training:  63%|██████▎   | 1112/1772 [02:47<01:41,  6.50it/s, running training loss: 0.8682]\u001b[A\n",
      "Training:  63%|██████▎   | 1112/1772 [02:47<01:41,  6.50it/s, running training loss: 1.0258]\u001b[A\n",
      "Training:  63%|██████▎   | 1113/1772 [02:47<01:38,  6.71it/s, running training loss: 1.0258]\u001b[A\n",
      "Training:  63%|██████▎   | 1113/1772 [02:48<01:38,  6.71it/s, running training loss: 0.9251]\u001b[A\n",
      "Training:  63%|██████▎   | 1114/1772 [02:48<01:33,  7.01it/s, running training loss: 0.9251]\u001b[A\n",
      "Training:  63%|██████▎   | 1114/1772 [02:48<01:33,  7.01it/s, running training loss: 1.0356]\u001b[A\n",
      "Training:  63%|██████▎   | 1115/1772 [02:48<01:36,  6.79it/s, running training loss: 1.0356]\u001b[A\n",
      "Training:  63%|██████▎   | 1115/1772 [02:48<01:36,  6.79it/s, running training loss: 0.9558]\u001b[A\n",
      "Training:  63%|██████▎   | 1116/1772 [02:48<01:37,  6.70it/s, running training loss: 0.9558]\u001b[A\n",
      "Training:  63%|██████▎   | 1116/1772 [02:48<01:37,  6.70it/s, running training loss: 0.9173]\u001b[A\n",
      "Training:  63%|██████▎   | 1117/1772 [02:48<01:38,  6.62it/s, running training loss: 0.9173]\u001b[A\n",
      "Training:  63%|██████▎   | 1117/1772 [02:48<01:38,  6.62it/s, running training loss: 0.9565]\u001b[A\n",
      "Training:  63%|██████▎   | 1118/1772 [02:48<01:36,  6.80it/s, running training loss: 0.9565]\u001b[A\n",
      "Training:  63%|██████▎   | 1118/1772 [02:48<01:36,  6.80it/s, running training loss: 1.0204]\u001b[A\n",
      "Training:  63%|██████▎   | 1119/1772 [02:48<01:34,  6.94it/s, running training loss: 1.0204]\u001b[A\n",
      "Training:  63%|██████▎   | 1119/1772 [02:49<01:34,  6.94it/s, running training loss: 0.8835]\u001b[A\n",
      "Training:  63%|██████▎   | 1120/1772 [02:49<01:37,  6.70it/s, running training loss: 0.8835]\u001b[A\n",
      "Training:  63%|██████▎   | 1120/1772 [02:49<01:37,  6.70it/s, running training loss: 0.9986]\u001b[A\n",
      "Training:  63%|██████▎   | 1121/1772 [02:49<01:34,  6.91it/s, running training loss: 0.9986]\u001b[A\n",
      "Training:  63%|██████▎   | 1121/1772 [02:49<01:34,  6.91it/s, running training loss: 1.2013]\u001b[A\n",
      "Training:  63%|██████▎   | 1122/1772 [02:49<01:30,  7.20it/s, running training loss: 1.2013]\u001b[A\n",
      "Training:  63%|██████▎   | 1122/1772 [02:49<01:30,  7.20it/s, running training loss: 1.1088]\u001b[A\n",
      "Training:  63%|██████▎   | 1123/1772 [02:49<01:35,  6.80it/s, running training loss: 1.1088]\u001b[A\n",
      "Training:  63%|██████▎   | 1123/1772 [02:49<01:35,  6.80it/s, running training loss: 1.2136]\u001b[A\n",
      "Training:  63%|██████▎   | 1124/1772 [02:49<01:33,  6.92it/s, running training loss: 1.2136]\u001b[A\n",
      "Training:  63%|██████▎   | 1124/1772 [02:49<01:33,  6.92it/s, running training loss: 1.1941]\u001b[A\n",
      "Training:  63%|██████▎   | 1125/1772 [02:49<01:30,  7.19it/s, running training loss: 1.1941]\u001b[A\n",
      "Training:  63%|██████▎   | 1125/1772 [02:49<01:30,  7.19it/s, running training loss: 1.1711]\u001b[A\n",
      "Training:  64%|██████▎   | 1126/1772 [02:49<01:28,  7.27it/s, running training loss: 1.1711]\u001b[A\n",
      "Training:  64%|██████▎   | 1126/1772 [02:49<01:28,  7.27it/s, running training loss: 0.8528]\u001b[A\n",
      "Training:  64%|██████▎   | 1127/1772 [02:49<01:27,  7.35it/s, running training loss: 0.8528]\u001b[A\n",
      "Training:  64%|██████▎   | 1127/1772 [02:50<01:27,  7.35it/s, running training loss: 1.0114]\u001b[A\n",
      "Training:  64%|██████▎   | 1128/1772 [02:50<01:33,  6.90it/s, running training loss: 1.0114]\u001b[A\n",
      "Training:  64%|██████▎   | 1128/1772 [02:50<01:33,  6.90it/s, running training loss: 1.0280]\u001b[A\n",
      "Training:  64%|██████▎   | 1129/1772 [02:50<01:38,  6.52it/s, running training loss: 1.0280]\u001b[A\n",
      "Training:  64%|██████▎   | 1129/1772 [02:50<01:38,  6.52it/s, running training loss: 1.0002]\u001b[A\n",
      "Training:  64%|██████▍   | 1130/1772 [02:50<01:36,  6.62it/s, running training loss: 1.0002]\u001b[A\n",
      "Training:  64%|██████▍   | 1130/1772 [02:50<01:36,  6.62it/s, running training loss: 0.9897]\u001b[A\n",
      "Training:  64%|██████▍   | 1131/1772 [02:50<01:31,  6.99it/s, running training loss: 0.9897]\u001b[A\n",
      "Training:  64%|██████▍   | 1131/1772 [02:50<01:31,  6.99it/s, running training loss: 1.0019]\u001b[A\n",
      "Training:  64%|██████▍   | 1132/1772 [02:50<01:36,  6.65it/s, running training loss: 1.0019]\u001b[A\n",
      "Training:  64%|██████▍   | 1132/1772 [02:50<01:36,  6.65it/s, running training loss: 1.2400]\u001b[A\n",
      "Training:  64%|██████▍   | 1133/1772 [02:50<01:35,  6.68it/s, running training loss: 1.2400]\u001b[A\n",
      "Training:  64%|██████▍   | 1133/1772 [02:51<01:35,  6.68it/s, running training loss: 1.2739]\u001b[A\n",
      "Training:  64%|██████▍   | 1134/1772 [02:51<01:47,  5.95it/s, running training loss: 1.2739]\u001b[A\n",
      "Training:  64%|██████▍   | 1134/1772 [02:51<01:47,  5.95it/s, running training loss: 1.0688]\u001b[A\n",
      "Training:  64%|██████▍   | 1135/1772 [02:51<01:42,  6.22it/s, running training loss: 1.0688]\u001b[A\n",
      "Training:  64%|██████▍   | 1135/1772 [02:51<01:42,  6.22it/s, running training loss: 1.0172]\u001b[A\n",
      "Training:  64%|██████▍   | 1136/1772 [02:51<01:36,  6.56it/s, running training loss: 1.0172]\u001b[A\n",
      "Training:  64%|██████▍   | 1136/1772 [02:51<01:36,  6.56it/s, running training loss: 0.8878]\u001b[A\n",
      "Training:  64%|██████▍   | 1137/1772 [02:51<01:32,  6.85it/s, running training loss: 0.8878]\u001b[A\n",
      "Training:  64%|██████▍   | 1137/1772 [02:51<01:32,  6.85it/s, running training loss: 1.3297]\u001b[A\n",
      "Training:  64%|██████▍   | 1138/1772 [02:51<01:42,  6.21it/s, running training loss: 1.3297]\u001b[A\n",
      "Training:  64%|██████▍   | 1138/1772 [02:51<01:42,  6.21it/s, running training loss: 0.7974]\u001b[A\n",
      "Training:  64%|██████▍   | 1139/1772 [02:51<01:35,  6.62it/s, running training loss: 0.7974]\u001b[A\n",
      "Training:  64%|██████▍   | 1139/1772 [02:51<01:35,  6.62it/s, running training loss: 0.7907]\u001b[A\n",
      "Training:  64%|██████▍   | 1140/1772 [02:51<01:30,  7.00it/s, running training loss: 0.7907]\u001b[A\n",
      "Training:  64%|██████▍   | 1140/1772 [02:52<01:30,  7.00it/s, running training loss: 0.7946]\u001b[A\n",
      "Training:  64%|██████▍   | 1141/1772 [02:52<01:26,  7.27it/s, running training loss: 0.7946]\u001b[A\n",
      "Training:  64%|██████▍   | 1141/1772 [02:52<01:26,  7.27it/s, running training loss: 0.8089]\u001b[A\n",
      "Training:  64%|██████▍   | 1142/1772 [02:52<01:26,  7.25it/s, running training loss: 0.8089]\u001b[A\n",
      "Training:  64%|██████▍   | 1142/1772 [02:52<01:26,  7.25it/s, running training loss: 0.8462]\u001b[A\n",
      "Training:  65%|██████▍   | 1143/1772 [02:52<01:29,  7.05it/s, running training loss: 0.8462]\u001b[A\n",
      "Training:  65%|██████▍   | 1143/1772 [02:52<01:29,  7.05it/s, running training loss: 1.3818]\u001b[A\n",
      "Training:  65%|██████▍   | 1144/1772 [02:52<01:28,  7.10it/s, running training loss: 1.3818]\u001b[A\n",
      "Training:  65%|██████▍   | 1144/1772 [02:52<01:28,  7.10it/s, running training loss: 1.1692]\u001b[A\n",
      "Training:  65%|██████▍   | 1145/1772 [02:52<01:28,  7.12it/s, running training loss: 1.1692]\u001b[A\n",
      "Training:  65%|██████▍   | 1145/1772 [02:52<01:28,  7.12it/s, running training loss: 1.1654]\u001b[A\n",
      "Training:  65%|██████▍   | 1146/1772 [02:52<01:26,  7.24it/s, running training loss: 1.1654]\u001b[A\n",
      "Training:  65%|██████▍   | 1146/1772 [02:52<01:26,  7.24it/s, running training loss: 1.3617]\u001b[A\n",
      "Training:  65%|██████▍   | 1147/1772 [02:52<01:26,  7.21it/s, running training loss: 1.3617]\u001b[A\n",
      "Training:  65%|██████▍   | 1147/1772 [02:53<01:26,  7.21it/s, running training loss: 1.0533]\u001b[A\n",
      "Training:  65%|██████▍   | 1148/1772 [02:53<01:26,  7.20it/s, running training loss: 1.0533]\u001b[A\n",
      "Training:  65%|██████▍   | 1148/1772 [02:53<01:26,  7.20it/s, running training loss: 1.0629]\u001b[A\n",
      "Training:  65%|██████▍   | 1149/1772 [02:53<01:24,  7.38it/s, running training loss: 1.0629]\u001b[A\n",
      "Training:  65%|██████▍   | 1149/1772 [02:53<01:24,  7.38it/s, running training loss: 1.0751]\u001b[A\n",
      "Training:  65%|██████▍   | 1150/1772 [02:53<01:23,  7.45it/s, running training loss: 1.0751]\u001b[A\n",
      "Training:  65%|██████▍   | 1150/1772 [02:53<01:23,  7.45it/s, running training loss: 0.9661]\u001b[A\n",
      "Training:  65%|██████▍   | 1151/1772 [02:53<01:21,  7.59it/s, running training loss: 0.9661]\u001b[A\n",
      "Training:  65%|██████▍   | 1151/1772 [02:53<01:21,  7.59it/s, running training loss: 1.0133]\u001b[A\n",
      "Training:  65%|██████▌   | 1152/1772 [02:53<01:23,  7.43it/s, running training loss: 1.0133]\u001b[A\n",
      "Training:  65%|██████▌   | 1152/1772 [02:53<01:23,  7.43it/s, running training loss: 0.8567]\u001b[A\n",
      "Training:  65%|██████▌   | 1153/1772 [02:53<01:25,  7.22it/s, running training loss: 0.8567]\u001b[A\n",
      "Training:  65%|██████▌   | 1153/1772 [02:53<01:25,  7.22it/s, running training loss: 0.7754]\u001b[A\n",
      "Training:  65%|██████▌   | 1154/1772 [02:53<01:22,  7.51it/s, running training loss: 0.7754]\u001b[A\n",
      "Training:  65%|██████▌   | 1154/1772 [02:53<01:22,  7.51it/s, running training loss: 0.8710]\u001b[A\n",
      "Training:  65%|██████▌   | 1155/1772 [02:53<01:21,  7.58it/s, running training loss: 0.8710]\u001b[A\n",
      "Training:  65%|██████▌   | 1155/1772 [02:54<01:21,  7.58it/s, running training loss: 0.8153]\u001b[A\n",
      "Training:  65%|██████▌   | 1156/1772 [02:54<01:21,  7.53it/s, running training loss: 0.8153]\u001b[A\n",
      "Training:  65%|██████▌   | 1156/1772 [02:54<01:21,  7.53it/s, running training loss: 0.8129]\u001b[A\n",
      "Training:  65%|██████▌   | 1157/1772 [02:54<01:21,  7.52it/s, running training loss: 0.8129]\u001b[A\n",
      "Training:  65%|██████▌   | 1157/1772 [02:54<01:21,  7.52it/s, running training loss: 0.9604]\u001b[A\n",
      "Training:  65%|██████▌   | 1158/1772 [02:54<01:22,  7.41it/s, running training loss: 0.9604]\u001b[A\n",
      "Training:  65%|██████▌   | 1158/1772 [02:54<01:22,  7.41it/s, running training loss: 0.9903]\u001b[A\n",
      "Training:  65%|██████▌   | 1159/1772 [02:54<01:24,  7.25it/s, running training loss: 0.9903]\u001b[A\n",
      "Training:  65%|██████▌   | 1159/1772 [02:54<01:24,  7.25it/s, running training loss: 0.9984]\u001b[A\n",
      "Training:  65%|██████▌   | 1160/1772 [02:54<01:25,  7.19it/s, running training loss: 0.9984]\u001b[A\n",
      "Training:  65%|██████▌   | 1160/1772 [02:54<01:25,  7.19it/s, running training loss: 0.9193]\u001b[A\n",
      "Training:  66%|██████▌   | 1161/1772 [02:54<01:29,  6.85it/s, running training loss: 0.9193]\u001b[A\n",
      "Training:  66%|██████▌   | 1161/1772 [02:55<01:29,  6.85it/s, running training loss: 0.7861]\u001b[A\n",
      "Training:  66%|██████▌   | 1162/1772 [02:55<01:33,  6.54it/s, running training loss: 0.7861]\u001b[A\n",
      "Training:  66%|██████▌   | 1162/1772 [02:55<01:33,  6.54it/s, running training loss: 0.9633]\u001b[A\n",
      "Training:  66%|██████▌   | 1163/1772 [02:55<01:40,  6.04it/s, running training loss: 0.9633]\u001b[A\n",
      "Training:  66%|██████▌   | 1163/1772 [02:55<01:40,  6.04it/s, running training loss: 1.3291]\u001b[A\n",
      "Training:  66%|██████▌   | 1164/1772 [02:55<01:38,  6.19it/s, running training loss: 1.3291]\u001b[A\n",
      "Training:  66%|██████▌   | 1164/1772 [02:55<01:38,  6.19it/s, running training loss: 0.9984]\u001b[A\n",
      "Training:  66%|██████▌   | 1165/1772 [02:55<01:35,  6.37it/s, running training loss: 0.9984]\u001b[A\n",
      "Training:  66%|██████▌   | 1165/1772 [02:55<01:35,  6.37it/s, running training loss: 1.0104]\u001b[A\n",
      "Training:  66%|██████▌   | 1166/1772 [02:55<01:33,  6.47it/s, running training loss: 1.0104]\u001b[A\n",
      "Training:  66%|██████▌   | 1166/1772 [02:55<01:33,  6.47it/s, running training loss: 0.8733]\u001b[A\n",
      "Training:  66%|██████▌   | 1167/1772 [02:55<01:32,  6.57it/s, running training loss: 0.8733]\u001b[A\n",
      "Training:  66%|██████▌   | 1167/1772 [02:55<01:32,  6.57it/s, running training loss: 0.9880]\u001b[A\n",
      "Training:  66%|██████▌   | 1168/1772 [02:55<01:31,  6.61it/s, running training loss: 0.9880]\u001b[A\n",
      "Training:  66%|██████▌   | 1168/1772 [02:56<01:31,  6.61it/s, running training loss: 0.8309]\u001b[A\n",
      "Training:  66%|██████▌   | 1169/1772 [02:56<01:28,  6.80it/s, running training loss: 0.8309]\u001b[A\n",
      "Training:  66%|██████▌   | 1169/1772 [02:56<01:28,  6.80it/s, running training loss: 1.5366]\u001b[A\n",
      "Training:  66%|██████▌   | 1170/1772 [02:56<01:26,  6.94it/s, running training loss: 1.5366]\u001b[A\n",
      "Training:  66%|██████▌   | 1170/1772 [02:56<01:26,  6.94it/s, running training loss: 1.1646]\u001b[A\n",
      "Training:  66%|██████▌   | 1171/1772 [02:56<01:31,  6.57it/s, running training loss: 1.1646]\u001b[A\n",
      "Training:  66%|██████▌   | 1171/1772 [02:56<01:31,  6.57it/s, running training loss: 1.3960]\u001b[A\n",
      "Training:  66%|██████▌   | 1172/1772 [02:56<01:26,  6.90it/s, running training loss: 1.3960]\u001b[A\n",
      "Training:  66%|██████▌   | 1172/1772 [02:56<01:26,  6.90it/s, running training loss: 0.8944]\u001b[A\n",
      "Training:  66%|██████▌   | 1173/1772 [02:56<01:27,  6.86it/s, running training loss: 0.8944]\u001b[A\n",
      "Training:  66%|██████▌   | 1173/1772 [02:56<01:27,  6.86it/s, running training loss: 1.1603]\u001b[A\n",
      "Training:  66%|██████▋   | 1174/1772 [02:56<01:29,  6.65it/s, running training loss: 1.1603]\u001b[A\n",
      "Training:  66%|██████▋   | 1174/1772 [02:56<01:29,  6.65it/s, running training loss: 1.0206]\u001b[A\n",
      "Training:  66%|██████▋   | 1175/1772 [02:56<01:31,  6.55it/s, running training loss: 1.0206]\u001b[A\n",
      "Training:  66%|██████▋   | 1175/1772 [02:57<01:31,  6.55it/s, running training loss: 1.1652]\u001b[A\n",
      "Training:  66%|██████▋   | 1176/1772 [02:57<01:30,  6.62it/s, running training loss: 1.1652]\u001b[A\n",
      "Training:  66%|██████▋   | 1176/1772 [02:57<01:30,  6.62it/s, running training loss: 0.8717]\u001b[A\n",
      "Training:  66%|██████▋   | 1177/1772 [02:57<01:25,  6.94it/s, running training loss: 0.8717]\u001b[A\n",
      "Training:  66%|██████▋   | 1177/1772 [02:57<01:25,  6.94it/s, running training loss: 0.9632]\u001b[A\n",
      "Training:  66%|██████▋   | 1178/1772 [02:57<01:24,  7.03it/s, running training loss: 0.9632]\u001b[A\n",
      "Training:  66%|██████▋   | 1178/1772 [02:57<01:24,  7.03it/s, running training loss: 0.8434]\u001b[A\n",
      "Training:  67%|██████▋   | 1179/1772 [02:57<01:21,  7.26it/s, running training loss: 0.8434]\u001b[A\n",
      "Training:  67%|██████▋   | 1179/1772 [02:57<01:21,  7.26it/s, running training loss: 0.7864]\u001b[A\n",
      "Training:  67%|██████▋   | 1180/1772 [02:57<01:22,  7.19it/s, running training loss: 0.7864]\u001b[A\n",
      "Training:  67%|██████▋   | 1180/1772 [02:57<01:22,  7.19it/s, running training loss: 0.8798]\u001b[A\n",
      "Training:  67%|██████▋   | 1181/1772 [02:57<01:21,  7.29it/s, running training loss: 0.8798]\u001b[A\n",
      "Training:  67%|██████▋   | 1181/1772 [02:57<01:21,  7.29it/s, running training loss: 0.9595]\u001b[A\n",
      "Training:  67%|██████▋   | 1182/1772 [02:57<01:20,  7.29it/s, running training loss: 0.9595]\u001b[A\n",
      "Training:  67%|██████▋   | 1182/1772 [02:58<01:20,  7.29it/s, running training loss: 0.9750]\u001b[A\n",
      "Training:  67%|██████▋   | 1183/1772 [02:58<01:27,  6.75it/s, running training loss: 0.9750]\u001b[A\n",
      "Training:  67%|██████▋   | 1183/1772 [02:58<01:27,  6.75it/s, running training loss: 0.9378]\u001b[A\n",
      "Training:  67%|██████▋   | 1184/1772 [02:58<01:23,  7.04it/s, running training loss: 0.9378]\u001b[A\n",
      "Training:  67%|██████▋   | 1184/1772 [02:58<01:23,  7.04it/s, running training loss: 1.0424]\u001b[A\n",
      "Training:  67%|██████▋   | 1185/1772 [02:58<01:22,  7.14it/s, running training loss: 1.0424]\u001b[A\n",
      "Training:  67%|██████▋   | 1185/1772 [02:58<01:22,  7.14it/s, running training loss: 0.8480]\u001b[A\n",
      "Training:  67%|██████▋   | 1186/1772 [02:58<01:24,  6.97it/s, running training loss: 0.8480]\u001b[A\n",
      "Training:  67%|██████▋   | 1186/1772 [02:58<01:24,  6.97it/s, running training loss: 0.8798]\u001b[A\n",
      "Training:  67%|██████▋   | 1187/1772 [02:58<01:30,  6.46it/s, running training loss: 0.8798]\u001b[A\n",
      "Training:  67%|██████▋   | 1187/1772 [02:58<01:30,  6.46it/s, running training loss: 0.8182]\u001b[A\n",
      "Training:  67%|██████▋   | 1188/1772 [02:58<01:26,  6.73it/s, running training loss: 0.8182]\u001b[A\n",
      "Training:  67%|██████▋   | 1188/1772 [02:58<01:26,  6.73it/s, running training loss: 1.1191]\u001b[A\n",
      "Training:  67%|██████▋   | 1189/1772 [02:58<01:24,  6.94it/s, running training loss: 1.1191]\u001b[A\n",
      "Training:  67%|██████▋   | 1189/1772 [02:59<01:24,  6.94it/s, running training loss: 0.8537]\u001b[A\n",
      "Training:  67%|██████▋   | 1190/1772 [02:59<01:23,  7.01it/s, running training loss: 0.8537]\u001b[A\n",
      "Training:  67%|██████▋   | 1190/1772 [02:59<01:23,  7.01it/s, running training loss: 1.0052]\u001b[A\n",
      "Training:  67%|██████▋   | 1191/1772 [02:59<01:23,  6.92it/s, running training loss: 1.0052]\u001b[A\n",
      "Training:  67%|██████▋   | 1191/1772 [02:59<01:23,  6.92it/s, running training loss: 1.2152]\u001b[A\n",
      "Training:  67%|██████▋   | 1192/1772 [02:59<01:22,  7.00it/s, running training loss: 1.2152]\u001b[A\n",
      "Training:  67%|██████▋   | 1192/1772 [02:59<01:22,  7.00it/s, running training loss: 1.0201]\u001b[A\n",
      "Training:  67%|██████▋   | 1193/1772 [02:59<01:29,  6.44it/s, running training loss: 1.0201]\u001b[A\n",
      "Training:  67%|██████▋   | 1193/1772 [02:59<01:29,  6.44it/s, running training loss: 0.9550]\u001b[A\n",
      "Training:  67%|██████▋   | 1194/1772 [02:59<01:32,  6.22it/s, running training loss: 0.9550]\u001b[A\n",
      "Training:  67%|██████▋   | 1194/1772 [02:59<01:32,  6.22it/s, running training loss: 1.0200]\u001b[A\n",
      "Training:  67%|██████▋   | 1195/1772 [02:59<01:39,  5.83it/s, running training loss: 1.0200]\u001b[A\n",
      "Training:  67%|██████▋   | 1195/1772 [03:00<01:39,  5.83it/s, running training loss: 1.1794]\u001b[A\n",
      "Training:  67%|██████▋   | 1196/1772 [03:00<01:35,  6.04it/s, running training loss: 1.1794]\u001b[A\n",
      "Training:  67%|██████▋   | 1196/1772 [03:00<01:35,  6.04it/s, running training loss: 1.1647]\u001b[A\n",
      "Training:  68%|██████▊   | 1197/1772 [03:00<01:30,  6.36it/s, running training loss: 1.1647]\u001b[A\n",
      "Training:  68%|██████▊   | 1197/1772 [03:00<01:30,  6.36it/s, running training loss: 0.9616]\u001b[A\n",
      "Training:  68%|██████▊   | 1198/1772 [03:00<01:26,  6.61it/s, running training loss: 0.9616]\u001b[A\n",
      "Training:  68%|██████▊   | 1198/1772 [03:00<01:26,  6.61it/s, running training loss: 1.3941]\u001b[A\n",
      "Training:  68%|██████▊   | 1199/1772 [03:00<01:21,  6.99it/s, running training loss: 1.3941]\u001b[A\n",
      "Training:  68%|██████▊   | 1199/1772 [03:00<01:21,  6.99it/s, running training loss: 1.0147]\u001b[A\n",
      "\n",
      "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   0%|          | 1/270 [00:00<02:38,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   3%|▎         | 7/270 [00:00<01:49,  2.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   5%|▍         | 13/270 [00:00<01:16,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   7%|▋         | 19/270 [00:00<00:53,  4.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   9%|▉         | 25/270 [00:01<00:37,  6.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  11%|█▏        | 31/270 [00:01<00:27,  8.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  14%|█▎        | 37/270 [00:01<00:19, 11.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  16%|█▌        | 43/270 [00:01<00:14, 15.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  18%|█▊        | 49/270 [00:01<00:11, 19.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  20%|██        | 55/270 [00:01<00:08, 24.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  23%|██▎       | 61/270 [00:01<00:07, 29.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  25%|██▍       | 67/270 [00:01<00:05, 34.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  27%|██▋       | 74/270 [00:01<00:04, 39.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  30%|██▉       | 80/270 [00:01<00:04, 43.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  32%|███▏      | 86/270 [00:02<00:03, 47.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  34%|███▍      | 92/270 [00:02<00:03, 49.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  37%|███▋      | 99/270 [00:02<00:03, 52.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  39%|███▉      | 105/270 [00:02<00:03, 53.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  41%|████      | 111/270 [00:02<00:02, 55.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  43%|████▎     | 117/270 [00:02<00:02, 56.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  46%|████▌     | 124/270 [00:02<00:02, 57.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  48%|████▊     | 130/270 [00:02<00:02, 55.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  50%|█████     | 136/270 [00:02<00:02, 56.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  53%|█████▎    | 142/270 [00:03<00:02, 56.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  55%|█████▍    | 148/270 [00:03<00:02, 56.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  57%|█████▋    | 154/270 [00:03<00:02, 55.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  59%|█████▉    | 160/270 [00:03<00:01, 56.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  61%|██████▏   | 166/270 [00:03<00:01, 56.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  64%|██████▎   | 172/270 [00:03<00:01, 57.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  66%|██████▌   | 178/270 [00:03<00:01, 55.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  68%|██████▊   | 184/270 [00:03<00:01, 54.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  70%|███████   | 190/270 [00:03<00:01, 55.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  73%|███████▎  | 196/270 [00:04<00:01, 54.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  75%|███████▍  | 202/270 [00:04<00:01, 54.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  77%|███████▋  | 208/270 [00:04<00:01, 55.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  79%|███████▉  | 214/270 [00:04<00:01, 55.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  81%|████████▏ | 220/270 [00:04<00:00, 56.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  84%|████████▍ | 227/270 [00:04<00:00, 57.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  86%|████████▋ | 233/270 [00:04<00:00, 57.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  89%|████████▉ | 240/270 [00:04<00:00, 57.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  91%|█████████ | 246/270 [00:04<00:00, 56.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  93%|█████████▎| 252/270 [00:05<00:00, 54.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  96%|█████████▌| 258/270 [00:05<00:00, 54.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  98%|█████████▊| 264/270 [00:05<00:00, 54.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation: 100%|██████████| 270/270 [00:05<00:00, 48.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Training:  68%|██████▊   | 1200/1772 [03:06<17:13,  1.81s/it, running training loss: 1.0147]\u001b[A\n",
      "Training:  68%|██████▊   | 1200/1772 [03:06<17:13,  1.81s/it, running training loss: 0.9177]\u001b[A\n",
      "Training:  68%|██████▊   | 1201/1772 [03:06<12:26,  1.31s/it, running training loss: 0.9177]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> training loss: 1.023801, valid loss: 0.611119, valid f1: 0.403929, valid acc: 0.648517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  68%|██████▊   | 1201/1772 [03:06<12:26,  1.31s/it, running training loss: 0.8841]\u001b[A\n",
      "Training:  68%|██████▊   | 1202/1772 [03:06<09:11,  1.03it/s, running training loss: 0.8841]\u001b[A\n",
      "Training:  68%|██████▊   | 1202/1772 [03:06<09:11,  1.03it/s, running training loss: 0.8821]\u001b[A\n",
      "Training:  68%|██████▊   | 1203/1772 [03:06<06:48,  1.39it/s, running training loss: 0.8821]\u001b[A\n",
      "Training:  68%|██████▊   | 1203/1772 [03:06<06:48,  1.39it/s, running training loss: 1.0406]\u001b[A\n",
      "Training:  68%|██████▊   | 1204/1772 [03:06<05:09,  1.84it/s, running training loss: 1.0406]\u001b[A\n",
      "Training:  68%|██████▊   | 1204/1772 [03:06<05:09,  1.84it/s, running training loss: 0.9105]\u001b[A\n",
      "Training:  68%|██████▊   | 1205/1772 [03:06<04:03,  2.32it/s, running training loss: 0.9105]\u001b[A\n",
      "Training:  68%|██████▊   | 1205/1772 [03:07<04:03,  2.32it/s, running training loss: 0.9547]\u001b[A\n",
      "Training:  68%|██████▊   | 1206/1772 [03:07<03:26,  2.73it/s, running training loss: 0.9547]\u001b[A\n",
      "Training:  68%|██████▊   | 1206/1772 [03:07<03:26,  2.73it/s, running training loss: 0.9451]\u001b[A\n",
      "Training:  68%|██████▊   | 1207/1772 [03:07<02:46,  3.40it/s, running training loss: 0.9451]\u001b[A\n",
      "Training:  68%|██████▊   | 1207/1772 [03:07<02:46,  3.40it/s, running training loss: 1.1461]\u001b[A\n",
      "Training:  68%|██████▊   | 1208/1772 [03:07<02:21,  3.99it/s, running training loss: 1.1461]\u001b[A\n",
      "Training:  68%|██████▊   | 1208/1772 [03:07<02:21,  3.99it/s, running training loss: 1.0617]\u001b[A\n",
      "Training:  68%|██████▊   | 1209/1772 [03:07<01:59,  4.71it/s, running training loss: 1.0617]\u001b[A\n",
      "Training:  68%|██████▊   | 1209/1772 [03:07<01:59,  4.71it/s, running training loss: 1.0561]\u001b[A\n",
      "Training:  68%|██████▊   | 1210/1772 [03:07<01:50,  5.10it/s, running training loss: 1.0561]\u001b[A\n",
      "Training:  68%|██████▊   | 1210/1772 [03:07<01:50,  5.10it/s, running training loss: 0.9920]\u001b[A\n",
      "Training:  68%|██████▊   | 1211/1772 [03:07<01:53,  4.95it/s, running training loss: 0.9920]\u001b[A\n",
      "Training:  68%|██████▊   | 1211/1772 [03:08<01:53,  4.95it/s, running training loss: 1.2593]\u001b[A\n",
      "Training:  68%|██████▊   | 1212/1772 [03:08<01:45,  5.29it/s, running training loss: 1.2593]\u001b[A\n",
      "Training:  68%|██████▊   | 1212/1772 [03:08<01:45,  5.29it/s, running training loss: 0.9069]\u001b[A\n",
      "Training:  68%|██████▊   | 1213/1772 [03:08<01:36,  5.82it/s, running training loss: 0.9069]\u001b[A\n",
      "Training:  68%|██████▊   | 1213/1772 [03:08<01:36,  5.82it/s, running training loss: 0.8823]\u001b[A\n",
      "Training:  69%|██████▊   | 1214/1772 [03:08<01:28,  6.31it/s, running training loss: 0.8823]\u001b[A\n",
      "Training:  69%|██████▊   | 1214/1772 [03:08<01:28,  6.31it/s, running training loss: 1.0848]\u001b[A\n",
      "Training:  69%|██████▊   | 1215/1772 [03:08<01:24,  6.58it/s, running training loss: 1.0848]\u001b[A\n",
      "Training:  69%|██████▊   | 1215/1772 [03:08<01:24,  6.58it/s, running training loss: 0.8395]\u001b[A\n",
      "Training:  69%|██████▊   | 1216/1772 [03:08<01:24,  6.59it/s, running training loss: 0.8395]\u001b[A\n",
      "Training:  69%|██████▊   | 1216/1772 [03:08<01:24,  6.59it/s, running training loss: 0.8692]\u001b[A\n",
      "Training:  69%|██████▊   | 1217/1772 [03:08<01:24,  6.54it/s, running training loss: 0.8692]\u001b[A\n",
      "Training:  69%|██████▊   | 1217/1772 [03:08<01:24,  6.54it/s, running training loss: 1.0566]\u001b[A\n",
      "Training:  69%|██████▊   | 1218/1772 [03:08<01:23,  6.62it/s, running training loss: 1.0566]\u001b[A\n",
      "Training:  69%|██████▊   | 1218/1772 [03:09<01:23,  6.62it/s, running training loss: 0.8776]\u001b[A\n",
      "Training:  69%|██████▉   | 1219/1772 [03:09<01:23,  6.62it/s, running training loss: 0.8776]\u001b[A\n",
      "Training:  69%|██████▉   | 1219/1772 [03:09<01:23,  6.62it/s, running training loss: 1.2515]\u001b[A\n",
      "Training:  69%|██████▉   | 1220/1772 [03:09<01:22,  6.68it/s, running training loss: 1.2515]\u001b[A\n",
      "Training:  69%|██████▉   | 1220/1772 [03:09<01:22,  6.68it/s, running training loss: 1.1429]\u001b[A\n",
      "Training:  69%|██████▉   | 1221/1772 [03:09<01:17,  7.08it/s, running training loss: 1.1429]\u001b[A\n",
      "Training:  69%|██████▉   | 1221/1772 [03:09<01:17,  7.08it/s, running training loss: 1.0287]\u001b[A\n",
      "Training:  69%|██████▉   | 1222/1772 [03:09<01:15,  7.29it/s, running training loss: 1.0287]\u001b[A\n",
      "Training:  69%|██████▉   | 1222/1772 [03:09<01:15,  7.29it/s, running training loss: 1.6744]\u001b[A\n",
      "Training:  69%|██████▉   | 1223/1772 [03:09<01:17,  7.13it/s, running training loss: 1.6744]\u001b[A\n",
      "Training:  69%|██████▉   | 1223/1772 [03:09<01:17,  7.13it/s, running training loss: 1.4126]\u001b[A\n",
      "Training:  69%|██████▉   | 1224/1772 [03:09<01:16,  7.18it/s, running training loss: 1.4126]\u001b[A\n",
      "Training:  69%|██████▉   | 1224/1772 [03:09<01:16,  7.18it/s, running training loss: 0.9951]\u001b[A\n",
      "Training:  69%|██████▉   | 1225/1772 [03:09<01:16,  7.12it/s, running training loss: 0.9951]\u001b[A\n",
      "Training:  69%|██████▉   | 1225/1772 [03:10<01:16,  7.12it/s, running training loss: 1.2750]\u001b[A\n",
      "Training:  69%|██████▉   | 1226/1772 [03:10<01:15,  7.25it/s, running training loss: 1.2750]\u001b[A\n",
      "Training:  69%|██████▉   | 1226/1772 [03:10<01:15,  7.25it/s, running training loss: 0.8684]\u001b[A\n",
      "Training:  69%|██████▉   | 1227/1772 [03:10<01:16,  7.09it/s, running training loss: 0.8684]\u001b[A\n",
      "Training:  69%|██████▉   | 1227/1772 [03:10<01:16,  7.09it/s, running training loss: 0.9773]\u001b[A\n",
      "Training:  69%|██████▉   | 1228/1772 [03:10<01:15,  7.17it/s, running training loss: 0.9773]\u001b[A\n",
      "Training:  69%|██████▉   | 1228/1772 [03:10<01:15,  7.17it/s, running training loss: 1.0287]\u001b[A\n",
      "Training:  69%|██████▉   | 1229/1772 [03:10<01:15,  7.15it/s, running training loss: 1.0287]\u001b[A\n",
      "Training:  69%|██████▉   | 1229/1772 [03:10<01:15,  7.15it/s, running training loss: 0.7835]\u001b[A\n",
      "Training:  69%|██████▉   | 1230/1772 [03:10<01:21,  6.68it/s, running training loss: 0.7835]\u001b[A\n",
      "Training:  69%|██████▉   | 1230/1772 [03:10<01:21,  6.68it/s, running training loss: 0.8934]\u001b[A\n",
      "Training:  69%|██████▉   | 1231/1772 [03:10<01:18,  6.87it/s, running training loss: 0.8934]\u001b[A\n",
      "Training:  69%|██████▉   | 1231/1772 [03:10<01:18,  6.87it/s, running training loss: 0.9511]\u001b[A\n",
      "Training:  70%|██████▉   | 1232/1772 [03:10<01:17,  6.94it/s, running training loss: 0.9511]\u001b[A\n",
      "Training:  70%|██████▉   | 1232/1772 [03:11<01:17,  6.94it/s, running training loss: 0.8462]\u001b[A\n",
      "Training:  70%|██████▉   | 1233/1772 [03:11<01:17,  6.97it/s, running training loss: 0.8462]\u001b[A\n",
      "Training:  70%|██████▉   | 1233/1772 [03:11<01:17,  6.97it/s, running training loss: 1.1140]\u001b[A\n",
      "Training:  70%|██████▉   | 1234/1772 [03:11<01:18,  6.87it/s, running training loss: 1.1140]\u001b[A\n",
      "Training:  70%|██████▉   | 1234/1772 [03:11<01:18,  6.87it/s, running training loss: 1.0174]\u001b[A\n",
      "Training:  70%|██████▉   | 1235/1772 [03:11<01:19,  6.74it/s, running training loss: 1.0174]\u001b[A\n",
      "Training:  70%|██████▉   | 1235/1772 [03:11<01:19,  6.74it/s, running training loss: 1.1432]\u001b[A\n",
      "Training:  70%|██████▉   | 1236/1772 [03:11<01:19,  6.70it/s, running training loss: 1.1432]\u001b[A\n",
      "Training:  70%|██████▉   | 1236/1772 [03:11<01:19,  6.70it/s, running training loss: 1.1002]\u001b[A\n",
      "Training:  70%|██████▉   | 1237/1772 [03:11<01:17,  6.90it/s, running training loss: 1.1002]\u001b[A\n",
      "Training:  70%|██████▉   | 1237/1772 [03:11<01:17,  6.90it/s, running training loss: 0.8439]\u001b[A\n",
      "Training:  70%|██████▉   | 1238/1772 [03:11<01:15,  7.07it/s, running training loss: 0.8439]\u001b[A\n",
      "Training:  70%|██████▉   | 1238/1772 [03:11<01:15,  7.07it/s, running training loss: 0.9381]\u001b[A\n",
      "Training:  70%|██████▉   | 1239/1772 [03:11<01:13,  7.27it/s, running training loss: 0.9381]\u001b[A\n",
      "Training:  70%|██████▉   | 1239/1772 [03:12<01:13,  7.27it/s, running training loss: 0.9331]\u001b[A\n",
      "Training:  70%|██████▉   | 1240/1772 [03:12<01:16,  6.94it/s, running training loss: 0.9331]\u001b[A\n",
      "Training:  70%|██████▉   | 1240/1772 [03:12<01:16,  6.94it/s, running training loss: 0.8465]\u001b[A\n",
      "Training:  70%|███████   | 1241/1772 [03:12<01:23,  6.36it/s, running training loss: 0.8465]\u001b[A\n",
      "Training:  70%|███████   | 1241/1772 [03:12<01:23,  6.36it/s, running training loss: 0.9518]\u001b[A\n",
      "Training:  70%|███████   | 1242/1772 [03:12<01:20,  6.59it/s, running training loss: 0.9518]\u001b[A\n",
      "Training:  70%|███████   | 1242/1772 [03:12<01:20,  6.59it/s, running training loss: 0.9492]\u001b[A\n",
      "Training:  70%|███████   | 1243/1772 [03:12<01:17,  6.82it/s, running training loss: 0.9492]\u001b[A\n",
      "Training:  70%|███████   | 1243/1772 [03:12<01:17,  6.82it/s, running training loss: 1.0043]\u001b[A\n",
      "Training:  70%|███████   | 1244/1772 [03:12<01:24,  6.22it/s, running training loss: 1.0043]\u001b[A\n",
      "Training:  70%|███████   | 1244/1772 [03:12<01:24,  6.22it/s, running training loss: 1.2445]\u001b[A\n",
      "Training:  70%|███████   | 1245/1772 [03:12<01:21,  6.49it/s, running training loss: 1.2445]\u001b[A\n",
      "Training:  70%|███████   | 1245/1772 [03:13<01:21,  6.49it/s, running training loss: 1.2455]\u001b[A\n",
      "Training:  70%|███████   | 1246/1772 [03:13<01:20,  6.54it/s, running training loss: 1.2455]\u001b[A\n",
      "Training:  70%|███████   | 1246/1772 [03:13<01:20,  6.54it/s, running training loss: 0.8751]\u001b[A\n",
      "Training:  70%|███████   | 1247/1772 [03:13<01:17,  6.74it/s, running training loss: 0.8751]\u001b[A\n",
      "Training:  70%|███████   | 1247/1772 [03:13<01:17,  6.74it/s, running training loss: 1.1338]\u001b[A\n",
      "Training:  70%|███████   | 1248/1772 [03:13<01:23,  6.31it/s, running training loss: 1.1338]\u001b[A\n",
      "Training:  70%|███████   | 1248/1772 [03:13<01:23,  6.31it/s, running training loss: 0.8095]\u001b[A\n",
      "Training:  70%|███████   | 1249/1772 [03:13<01:22,  6.36it/s, running training loss: 0.8095]\u001b[A\n",
      "Training:  70%|███████   | 1249/1772 [03:13<01:22,  6.36it/s, running training loss: 0.8704]\u001b[A\n",
      "Training:  71%|███████   | 1250/1772 [03:13<01:18,  6.67it/s, running training loss: 0.8704]\u001b[A\n",
      "Training:  71%|███████   | 1250/1772 [03:13<01:18,  6.67it/s, running training loss: 1.1021]\u001b[A\n",
      "Training:  71%|███████   | 1251/1772 [03:13<01:16,  6.77it/s, running training loss: 1.1021]\u001b[A\n",
      "Training:  71%|███████   | 1251/1772 [03:13<01:16,  6.77it/s, running training loss: 0.8041]\u001b[A\n",
      "Training:  71%|███████   | 1252/1772 [03:13<01:17,  6.67it/s, running training loss: 0.8041]\u001b[A\n",
      "Training:  71%|███████   | 1252/1772 [03:14<01:17,  6.67it/s, running training loss: 0.9324]\u001b[A\n",
      "Training:  71%|███████   | 1253/1772 [03:14<01:14,  6.99it/s, running training loss: 0.9324]\u001b[A\n",
      "Training:  71%|███████   | 1253/1772 [03:14<01:14,  6.99it/s, running training loss: 1.1486]\u001b[A\n",
      "Training:  71%|███████   | 1254/1772 [03:14<01:13,  7.07it/s, running training loss: 1.1486]\u001b[A\n",
      "Training:  71%|███████   | 1254/1772 [03:14<01:13,  7.07it/s, running training loss: 1.1204]\u001b[A\n",
      "Training:  71%|███████   | 1255/1772 [03:14<01:22,  6.27it/s, running training loss: 1.1204]\u001b[A\n",
      "Training:  71%|███████   | 1255/1772 [03:14<01:22,  6.27it/s, running training loss: 1.1840]\u001b[A\n",
      "Training:  71%|███████   | 1256/1772 [03:14<01:19,  6.51it/s, running training loss: 1.1840]\u001b[A\n",
      "Training:  71%|███████   | 1256/1772 [03:14<01:19,  6.51it/s, running training loss: 0.8950]\u001b[A\n",
      "Training:  71%|███████   | 1257/1772 [03:14<01:20,  6.38it/s, running training loss: 0.8950]\u001b[A\n",
      "Training:  71%|███████   | 1257/1772 [03:14<01:20,  6.38it/s, running training loss: 0.9200]\u001b[A\n",
      "Training:  71%|███████   | 1258/1772 [03:14<01:21,  6.29it/s, running training loss: 0.9200]\u001b[A\n",
      "Training:  71%|███████   | 1258/1772 [03:15<01:21,  6.29it/s, running training loss: 0.7707]\u001b[A\n",
      "Training:  71%|███████   | 1259/1772 [03:15<01:19,  6.44it/s, running training loss: 0.7707]\u001b[A\n",
      "Training:  71%|███████   | 1259/1772 [03:15<01:19,  6.44it/s, running training loss: 0.8721]\u001b[A\n",
      "Training:  71%|███████   | 1260/1772 [03:15<01:16,  6.70it/s, running training loss: 0.8721]\u001b[A\n",
      "Training:  71%|███████   | 1260/1772 [03:15<01:16,  6.70it/s, running training loss: 0.9590]\u001b[A\n",
      "Training:  71%|███████   | 1261/1772 [03:15<01:15,  6.77it/s, running training loss: 0.9590]\u001b[A\n",
      "Training:  71%|███████   | 1261/1772 [03:15<01:15,  6.77it/s, running training loss: 0.9602]\u001b[A\n",
      "Training:  71%|███████   | 1262/1772 [03:15<01:16,  6.65it/s, running training loss: 0.9602]\u001b[A\n",
      "Training:  71%|███████   | 1262/1772 [03:15<01:16,  6.65it/s, running training loss: 1.0395]\u001b[A\n",
      "Training:  71%|███████▏  | 1263/1772 [03:15<01:13,  6.94it/s, running training loss: 1.0395]\u001b[A\n",
      "Training:  71%|███████▏  | 1263/1772 [03:15<01:13,  6.94it/s, running training loss: 0.9208]\u001b[A\n",
      "Training:  71%|███████▏  | 1264/1772 [03:15<01:14,  6.83it/s, running training loss: 0.9208]\u001b[A\n",
      "Training:  71%|███████▏  | 1264/1772 [03:15<01:14,  6.83it/s, running training loss: 0.9323]\u001b[A\n",
      "Training:  71%|███████▏  | 1265/1772 [03:15<01:12,  6.95it/s, running training loss: 0.9323]\u001b[A\n",
      "Training:  71%|███████▏  | 1265/1772 [03:16<01:12,  6.95it/s, running training loss: 1.1909]\u001b[A\n",
      "Training:  71%|███████▏  | 1266/1772 [03:16<01:21,  6.21it/s, running training loss: 1.1909]\u001b[A\n",
      "Training:  71%|███████▏  | 1266/1772 [03:16<01:21,  6.21it/s, running training loss: 1.3505]\u001b[A\n",
      "Training:  72%|███████▏  | 1267/1772 [03:16<01:18,  6.45it/s, running training loss: 1.3505]\u001b[A\n",
      "Training:  72%|███████▏  | 1267/1772 [03:16<01:18,  6.45it/s, running training loss: 1.1580]\u001b[A\n",
      "Training:  72%|███████▏  | 1268/1772 [03:16<01:14,  6.79it/s, running training loss: 1.1580]\u001b[A\n",
      "Training:  72%|███████▏  | 1268/1772 [03:16<01:14,  6.79it/s, running training loss: 1.3707]\u001b[A\n",
      "Training:  72%|███████▏  | 1269/1772 [03:16<01:11,  7.00it/s, running training loss: 1.3707]\u001b[A\n",
      "Training:  72%|███████▏  | 1269/1772 [03:16<01:11,  7.00it/s, running training loss: 1.0887]\u001b[A\n",
      "Training:  72%|███████▏  | 1270/1772 [03:16<01:10,  7.07it/s, running training loss: 1.0887]\u001b[A\n",
      "Training:  72%|███████▏  | 1270/1772 [03:16<01:10,  7.07it/s, running training loss: 1.0560]\u001b[A\n",
      "Training:  72%|███████▏  | 1271/1772 [03:16<01:08,  7.28it/s, running training loss: 1.0560]\u001b[A\n",
      "Training:  72%|███████▏  | 1271/1772 [03:16<01:08,  7.28it/s, running training loss: 1.2773]\u001b[A\n",
      "Training:  72%|███████▏  | 1272/1772 [03:16<01:08,  7.26it/s, running training loss: 1.2773]\u001b[A\n",
      "Training:  72%|███████▏  | 1272/1772 [03:17<01:08,  7.26it/s, running training loss: 1.0542]\u001b[A\n",
      "Training:  72%|███████▏  | 1273/1772 [03:17<01:14,  6.72it/s, running training loss: 1.0542]\u001b[A\n",
      "Training:  72%|███████▏  | 1273/1772 [03:17<01:14,  6.72it/s, running training loss: 1.3958]\u001b[A\n",
      "Training:  72%|███████▏  | 1274/1772 [03:17<01:10,  7.09it/s, running training loss: 1.3958]\u001b[A\n",
      "Training:  72%|███████▏  | 1274/1772 [03:17<01:10,  7.09it/s, running training loss: 0.8075]\u001b[A\n",
      "Training:  72%|███████▏  | 1275/1772 [03:17<01:10,  7.06it/s, running training loss: 0.8075]\u001b[A\n",
      "Training:  72%|███████▏  | 1275/1772 [03:17<01:10,  7.06it/s, running training loss: 1.0189]\u001b[A\n",
      "Training:  72%|███████▏  | 1276/1772 [03:17<01:11,  6.93it/s, running training loss: 1.0189]\u001b[A\n",
      "Training:  72%|███████▏  | 1276/1772 [03:17<01:11,  6.93it/s, running training loss: 0.8318]\u001b[A\n",
      "Training:  72%|███████▏  | 1277/1772 [03:17<01:09,  7.14it/s, running training loss: 0.8318]\u001b[A\n",
      "Training:  72%|███████▏  | 1277/1772 [03:17<01:09,  7.14it/s, running training loss: 0.8573]\u001b[A\n",
      "Training:  72%|███████▏  | 1278/1772 [03:17<01:07,  7.34it/s, running training loss: 0.8573]\u001b[A\n",
      "Training:  72%|███████▏  | 1278/1772 [03:17<01:07,  7.34it/s, running training loss: 1.0140]\u001b[A\n",
      "Training:  72%|███████▏  | 1279/1772 [03:17<01:07,  7.32it/s, running training loss: 1.0140]\u001b[A\n",
      "Training:  72%|███████▏  | 1279/1772 [03:18<01:07,  7.32it/s, running training loss: 0.8866]\u001b[A\n",
      "Training:  72%|███████▏  | 1280/1772 [03:18<01:07,  7.30it/s, running training loss: 0.8866]\u001b[A\n",
      "Training:  72%|███████▏  | 1280/1772 [03:18<01:07,  7.30it/s, running training loss: 0.7667]\u001b[A\n",
      "Training:  72%|███████▏  | 1281/1772 [03:18<01:07,  7.28it/s, running training loss: 0.7667]\u001b[A\n",
      "Training:  72%|███████▏  | 1281/1772 [03:18<01:07,  7.28it/s, running training loss: 0.8332]\u001b[A\n",
      "Training:  72%|███████▏  | 1282/1772 [03:18<01:09,  7.04it/s, running training loss: 0.8332]\u001b[A\n",
      "Training:  72%|███████▏  | 1282/1772 [03:18<01:09,  7.04it/s, running training loss: 0.7544]\u001b[A\n",
      "Training:  72%|███████▏  | 1283/1772 [03:18<01:10,  6.89it/s, running training loss: 0.7544]\u001b[A\n",
      "Training:  72%|███████▏  | 1283/1772 [03:18<01:10,  6.89it/s, running training loss: 0.9307]\u001b[A\n",
      "Training:  72%|███████▏  | 1284/1772 [03:18<01:07,  7.21it/s, running training loss: 0.9307]\u001b[A\n",
      "Training:  72%|███████▏  | 1284/1772 [03:18<01:07,  7.21it/s, running training loss: 1.1106]\u001b[A\n",
      "Training:  73%|███████▎  | 1285/1772 [03:18<01:06,  7.29it/s, running training loss: 1.1106]\u001b[A\n",
      "Training:  73%|███████▎  | 1285/1772 [03:18<01:06,  7.29it/s, running training loss: 0.7253]\u001b[A\n",
      "Training:  73%|███████▎  | 1286/1772 [03:18<01:06,  7.29it/s, running training loss: 0.7253]\u001b[A\n",
      "Training:  73%|███████▎  | 1286/1772 [03:19<01:06,  7.29it/s, running training loss: 1.1140]\u001b[A\n",
      "Training:  73%|███████▎  | 1287/1772 [03:19<01:13,  6.61it/s, running training loss: 1.1140]\u001b[A\n",
      "Training:  73%|███████▎  | 1287/1772 [03:19<01:13,  6.61it/s, running training loss: 0.9045]\u001b[A\n",
      "Training:  73%|███████▎  | 1288/1772 [03:19<01:10,  6.91it/s, running training loss: 0.9045]\u001b[A\n",
      "Training:  73%|███████▎  | 1288/1772 [03:19<01:10,  6.91it/s, running training loss: 1.3159]\u001b[A\n",
      "Training:  73%|███████▎  | 1289/1772 [03:19<01:10,  6.85it/s, running training loss: 1.3159]\u001b[A\n",
      "Training:  73%|███████▎  | 1289/1772 [03:19<01:10,  6.85it/s, running training loss: 1.3940]\u001b[A\n",
      "Training:  73%|███████▎  | 1290/1772 [03:19<01:07,  7.13it/s, running training loss: 1.3940]\u001b[A\n",
      "Training:  73%|███████▎  | 1290/1772 [03:19<01:07,  7.13it/s, running training loss: 1.5149]\u001b[A\n",
      "Training:  73%|███████▎  | 1291/1772 [03:19<01:06,  7.23it/s, running training loss: 1.5149]\u001b[A\n",
      "Training:  73%|███████▎  | 1291/1772 [03:19<01:06,  7.23it/s, running training loss: 1.0461]\u001b[A\n",
      "Training:  73%|███████▎  | 1292/1772 [03:19<01:06,  7.27it/s, running training loss: 1.0461]\u001b[A\n",
      "Training:  73%|███████▎  | 1292/1772 [03:19<01:06,  7.27it/s, running training loss: 1.9060]\u001b[A\n",
      "Training:  73%|███████▎  | 1293/1772 [03:19<01:05,  7.35it/s, running training loss: 1.9060]\u001b[A\n",
      "Training:  73%|███████▎  | 1293/1772 [03:20<01:05,  7.35it/s, running training loss: 0.8017]\u001b[A\n",
      "Training:  73%|███████▎  | 1294/1772 [03:20<01:09,  6.86it/s, running training loss: 0.8017]\u001b[A\n",
      "Training:  73%|███████▎  | 1294/1772 [03:20<01:09,  6.86it/s, running training loss: 0.8959]\u001b[A\n",
      "Training:  73%|███████▎  | 1295/1772 [03:20<01:06,  7.19it/s, running training loss: 0.8959]\u001b[A\n",
      "Training:  73%|███████▎  | 1295/1772 [03:20<01:06,  7.19it/s, running training loss: 1.2589]\u001b[A\n",
      "Training:  73%|███████▎  | 1296/1772 [03:20<01:04,  7.41it/s, running training loss: 1.2589]\u001b[A\n",
      "Training:  73%|███████▎  | 1296/1772 [03:20<01:04,  7.41it/s, running training loss: 1.0323]\u001b[A\n",
      "Training:  73%|███████▎  | 1297/1772 [03:20<01:04,  7.39it/s, running training loss: 1.0323]\u001b[A\n",
      "Training:  73%|███████▎  | 1297/1772 [03:20<01:04,  7.39it/s, running training loss: 0.7980]\u001b[A\n",
      "Training:  73%|███████▎  | 1298/1772 [03:20<01:04,  7.34it/s, running training loss: 0.7980]\u001b[A\n",
      "Training:  73%|███████▎  | 1298/1772 [03:20<01:04,  7.34it/s, running training loss: 0.9971]\u001b[A\n",
      "Training:  73%|███████▎  | 1299/1772 [03:20<01:11,  6.60it/s, running training loss: 0.9971]\u001b[A\n",
      "Training:  73%|███████▎  | 1299/1772 [03:20<01:11,  6.60it/s, running training loss: 0.8003]\u001b[A\n",
      "Training:  73%|███████▎  | 1300/1772 [03:20<01:09,  6.79it/s, running training loss: 0.8003]\u001b[A\n",
      "Training:  73%|███████▎  | 1300/1772 [03:20<01:09,  6.79it/s, running training loss: 0.8741]\u001b[A\n",
      "Training:  73%|███████▎  | 1301/1772 [03:20<01:08,  6.93it/s, running training loss: 0.8741]\u001b[A\n",
      "Training:  73%|███████▎  | 1301/1772 [03:21<01:08,  6.93it/s, running training loss: 0.8256]\u001b[A\n",
      "Training:  73%|███████▎  | 1302/1772 [03:21<01:11,  6.56it/s, running training loss: 0.8256]\u001b[A\n",
      "Training:  73%|███████▎  | 1302/1772 [03:21<01:11,  6.56it/s, running training loss: 0.9767]\u001b[A\n",
      "Training:  74%|███████▎  | 1303/1772 [03:21<01:09,  6.75it/s, running training loss: 0.9767]\u001b[A\n",
      "Training:  74%|███████▎  | 1303/1772 [03:21<01:09,  6.75it/s, running training loss: 0.8255]\u001b[A\n",
      "Training:  74%|███████▎  | 1304/1772 [03:21<01:09,  6.69it/s, running training loss: 0.8255]\u001b[A\n",
      "Training:  74%|███████▎  | 1304/1772 [03:21<01:09,  6.69it/s, running training loss: 1.0252]\u001b[A\n",
      "Training:  74%|███████▎  | 1305/1772 [03:21<01:06,  7.01it/s, running training loss: 1.0252]\u001b[A\n",
      "Training:  74%|███████▎  | 1305/1772 [03:21<01:06,  7.01it/s, running training loss: 1.0863]\u001b[A\n",
      "Training:  74%|███████▎  | 1306/1772 [03:21<01:02,  7.41it/s, running training loss: 1.0863]\u001b[A\n",
      "Training:  74%|███████▎  | 1306/1772 [03:21<01:02,  7.41it/s, running training loss: 1.1107]\u001b[A\n",
      "Training:  74%|███████▍  | 1307/1772 [03:21<01:01,  7.51it/s, running training loss: 1.1107]\u001b[A\n",
      "Training:  74%|███████▍  | 1307/1772 [03:22<01:01,  7.51it/s, running training loss: 0.9906]\u001b[A\n",
      "Training:  74%|███████▍  | 1308/1772 [03:22<01:09,  6.70it/s, running training loss: 0.9906]\u001b[A\n",
      "Training:  74%|███████▍  | 1308/1772 [03:22<01:09,  6.70it/s, running training loss: 0.8064]\u001b[A\n",
      "Training:  74%|███████▍  | 1309/1772 [03:22<01:09,  6.70it/s, running training loss: 0.8064]\u001b[A\n",
      "Training:  74%|███████▍  | 1309/1772 [03:22<01:09,  6.70it/s, running training loss: 1.0331]\u001b[A\n",
      "Training:  74%|███████▍  | 1310/1772 [03:22<01:07,  6.81it/s, running training loss: 1.0331]\u001b[A\n",
      "Training:  74%|███████▍  | 1310/1772 [03:22<01:07,  6.81it/s, running training loss: 1.0024]\u001b[A\n",
      "Training:  74%|███████▍  | 1311/1772 [03:22<01:06,  6.94it/s, running training loss: 1.0024]\u001b[A\n",
      "Training:  74%|███████▍  | 1311/1772 [03:22<01:06,  6.94it/s, running training loss: 1.1305]\u001b[A\n",
      "Training:  74%|███████▍  | 1312/1772 [03:22<01:05,  7.07it/s, running training loss: 1.1305]\u001b[A\n",
      "Training:  74%|███████▍  | 1312/1772 [03:22<01:05,  7.07it/s, running training loss: 1.2848]\u001b[A\n",
      "Training:  74%|███████▍  | 1313/1772 [03:22<01:09,  6.61it/s, running training loss: 1.2848]\u001b[A\n",
      "Training:  74%|███████▍  | 1313/1772 [03:22<01:09,  6.61it/s, running training loss: 1.1685]\u001b[A\n",
      "Training:  74%|███████▍  | 1314/1772 [03:22<01:09,  6.54it/s, running training loss: 1.1685]\u001b[A\n",
      "Training:  74%|███████▍  | 1314/1772 [03:23<01:09,  6.54it/s, running training loss: 1.3353]\u001b[A\n",
      "Training:  74%|███████▍  | 1315/1772 [03:23<01:15,  6.03it/s, running training loss: 1.3353]\u001b[A\n",
      "Training:  74%|███████▍  | 1315/1772 [03:23<01:15,  6.03it/s, running training loss: 1.1944]\u001b[A\n",
      "Training:  74%|███████▍  | 1316/1772 [03:23<01:14,  6.15it/s, running training loss: 1.1944]\u001b[A\n",
      "Training:  74%|███████▍  | 1316/1772 [03:23<01:14,  6.15it/s, running training loss: 1.0191]\u001b[A\n",
      "Training:  74%|███████▍  | 1317/1772 [03:23<01:12,  6.28it/s, running training loss: 1.0191]\u001b[A\n",
      "Training:  74%|███████▍  | 1317/1772 [03:23<01:12,  6.28it/s, running training loss: 1.1219]\u001b[A\n",
      "Training:  74%|███████▍  | 1318/1772 [03:23<01:09,  6.56it/s, running training loss: 1.1219]\u001b[A\n",
      "Training:  74%|███████▍  | 1318/1772 [03:23<01:09,  6.56it/s, running training loss: 1.0565]\u001b[A\n",
      "Training:  74%|███████▍  | 1319/1772 [03:23<01:09,  6.48it/s, running training loss: 1.0565]\u001b[A\n",
      "Training:  74%|███████▍  | 1319/1772 [03:23<01:09,  6.48it/s, running training loss: 0.9085]\u001b[A\n",
      "Training:  74%|███████▍  | 1320/1772 [03:23<01:17,  5.86it/s, running training loss: 0.9085]\u001b[A\n",
      "Training:  74%|███████▍  | 1320/1772 [03:24<01:17,  5.86it/s, running training loss: 0.8273]\u001b[A\n",
      "Training:  75%|███████▍  | 1321/1772 [03:24<01:11,  6.26it/s, running training loss: 0.8273]\u001b[A\n",
      "Training:  75%|███████▍  | 1321/1772 [03:24<01:11,  6.26it/s, running training loss: 0.8523]\u001b[A\n",
      "Training:  75%|███████▍  | 1322/1772 [03:24<01:11,  6.34it/s, running training loss: 0.8523]\u001b[A\n",
      "Training:  75%|███████▍  | 1322/1772 [03:24<01:11,  6.34it/s, running training loss: 0.7765]\u001b[A\n",
      "Training:  75%|███████▍  | 1323/1772 [03:24<01:08,  6.60it/s, running training loss: 0.7765]\u001b[A\n",
      "Training:  75%|███████▍  | 1323/1772 [03:24<01:08,  6.60it/s, running training loss: 0.9193]\u001b[A\n",
      "Training:  75%|███████▍  | 1324/1772 [03:24<01:06,  6.71it/s, running training loss: 0.9193]\u001b[A\n",
      "Training:  75%|███████▍  | 1324/1772 [03:24<01:06,  6.71it/s, running training loss: 0.8398]\u001b[A\n",
      "Training:  75%|███████▍  | 1325/1772 [03:24<01:03,  7.04it/s, running training loss: 0.8398]\u001b[A\n",
      "Training:  75%|███████▍  | 1325/1772 [03:24<01:03,  7.04it/s, running training loss: 0.8236]\u001b[A\n",
      "Training:  75%|███████▍  | 1326/1772 [03:24<01:01,  7.21it/s, running training loss: 0.8236]\u001b[A\n",
      "Training:  75%|███████▍  | 1326/1772 [03:24<01:01,  7.21it/s, running training loss: 1.0118]\u001b[A\n",
      "Training:  75%|███████▍  | 1327/1772 [03:24<01:01,  7.25it/s, running training loss: 1.0118]\u001b[A\n",
      "Training:  75%|███████▍  | 1327/1772 [03:25<01:01,  7.25it/s, running training loss: 0.9621]\u001b[A\n",
      "Training:  75%|███████▍  | 1328/1772 [03:25<01:02,  7.14it/s, running training loss: 0.9621]\u001b[A\n",
      "Training:  75%|███████▍  | 1328/1772 [03:25<01:02,  7.14it/s, running training loss: 0.7809]\u001b[A\n",
      "Training:  75%|███████▌  | 1329/1772 [03:25<01:00,  7.36it/s, running training loss: 0.7809]\u001b[A\n",
      "Training:  75%|███████▌  | 1329/1772 [03:25<01:00,  7.36it/s, running training loss: 0.8902]\u001b[A\n",
      "Training:  75%|███████▌  | 1330/1772 [03:25<00:58,  7.53it/s, running training loss: 0.8902]\u001b[A\n",
      "Training:  75%|███████▌  | 1330/1772 [03:25<00:58,  7.53it/s, running training loss: 0.9239]\u001b[A\n",
      "Training:  75%|███████▌  | 1331/1772 [03:25<01:02,  7.11it/s, running training loss: 0.9239]\u001b[A\n",
      "Training:  75%|███████▌  | 1331/1772 [03:25<01:02,  7.11it/s, running training loss: 1.1621]\u001b[A\n",
      "Training:  75%|███████▌  | 1332/1772 [03:25<01:02,  6.99it/s, running training loss: 1.1621]\u001b[A\n",
      "Training:  75%|███████▌  | 1332/1772 [03:25<01:02,  6.99it/s, running training loss: 1.1788]\u001b[A\n",
      "Training:  75%|███████▌  | 1333/1772 [03:25<01:05,  6.74it/s, running training loss: 1.1788]\u001b[A\n",
      "Training:  75%|███████▌  | 1333/1772 [03:25<01:05,  6.74it/s, running training loss: 0.9955]\u001b[A\n",
      "Training:  75%|███████▌  | 1334/1772 [03:25<01:04,  6.84it/s, running training loss: 0.9955]\u001b[A\n",
      "Training:  75%|███████▌  | 1334/1772 [03:26<01:04,  6.84it/s, running training loss: 0.9580]\u001b[A\n",
      "Training:  75%|███████▌  | 1335/1772 [03:26<01:04,  6.73it/s, running training loss: 0.9580]\u001b[A\n",
      "Training:  75%|███████▌  | 1335/1772 [03:26<01:04,  6.73it/s, running training loss: 1.0402]\u001b[A\n",
      "Training:  75%|███████▌  | 1336/1772 [03:26<01:07,  6.48it/s, running training loss: 1.0402]\u001b[A\n",
      "Training:  75%|███████▌  | 1336/1772 [03:26<01:07,  6.48it/s, running training loss: 1.0137]\u001b[A\n",
      "Training:  75%|███████▌  | 1337/1772 [03:26<01:06,  6.52it/s, running training loss: 1.0137]\u001b[A\n",
      "Training:  75%|███████▌  | 1337/1772 [03:26<01:06,  6.52it/s, running training loss: 0.9199]\u001b[A\n",
      "Training:  76%|███████▌  | 1338/1772 [03:26<01:04,  6.74it/s, running training loss: 0.9199]\u001b[A\n",
      "Training:  76%|███████▌  | 1338/1772 [03:26<01:04,  6.74it/s, running training loss: 0.9370]\u001b[A\n",
      "Training:  76%|███████▌  | 1339/1772 [03:26<01:06,  6.52it/s, running training loss: 0.9370]\u001b[A\n",
      "Training:  76%|███████▌  | 1339/1772 [03:26<01:06,  6.52it/s, running training loss: 1.0769]\u001b[A\n",
      "Training:  76%|███████▌  | 1340/1772 [03:26<01:03,  6.76it/s, running training loss: 1.0769]\u001b[A\n",
      "Training:  76%|███████▌  | 1340/1772 [03:26<01:03,  6.76it/s, running training loss: 0.8270]\u001b[A\n",
      "Training:  76%|███████▌  | 1341/1772 [03:26<01:02,  6.91it/s, running training loss: 0.8270]\u001b[A\n",
      "Training:  76%|███████▌  | 1341/1772 [03:27<01:02,  6.91it/s, running training loss: 0.7744]\u001b[A\n",
      "Training:  76%|███████▌  | 1342/1772 [03:27<01:01,  7.01it/s, running training loss: 0.7744]\u001b[A\n",
      "Training:  76%|███████▌  | 1342/1772 [03:27<01:01,  7.01it/s, running training loss: 0.8690]\u001b[A\n",
      "Training:  76%|███████▌  | 1343/1772 [03:27<01:08,  6.26it/s, running training loss: 0.8690]\u001b[A\n",
      "Training:  76%|███████▌  | 1343/1772 [03:27<01:08,  6.26it/s, running training loss: 0.9664]\u001b[A\n",
      "Training:  76%|███████▌  | 1344/1772 [03:27<01:09,  6.19it/s, running training loss: 0.9664]\u001b[A\n",
      "Training:  76%|███████▌  | 1344/1772 [03:27<01:09,  6.19it/s, running training loss: 1.1222]\u001b[A\n",
      "Training:  76%|███████▌  | 1345/1772 [03:27<01:09,  6.15it/s, running training loss: 1.1222]\u001b[A\n",
      "Training:  76%|███████▌  | 1345/1772 [03:27<01:09,  6.15it/s, running training loss: 0.8824]\u001b[A\n",
      "Training:  76%|███████▌  | 1346/1772 [03:27<01:09,  6.15it/s, running training loss: 0.8824]\u001b[A\n",
      "Training:  76%|███████▌  | 1346/1772 [03:27<01:09,  6.15it/s, running training loss: 1.0540]\u001b[A\n",
      "Training:  76%|███████▌  | 1347/1772 [03:27<01:08,  6.17it/s, running training loss: 1.0540]\u001b[A\n",
      "Training:  76%|███████▌  | 1347/1772 [03:28<01:08,  6.17it/s, running training loss: 1.1720]\u001b[A\n",
      "Training:  76%|███████▌  | 1348/1772 [03:28<01:05,  6.46it/s, running training loss: 1.1720]\u001b[A\n",
      "Training:  76%|███████▌  | 1348/1772 [03:28<01:05,  6.46it/s, running training loss: 0.9139]\u001b[A\n",
      "Training:  76%|███████▌  | 1349/1772 [03:28<01:03,  6.67it/s, running training loss: 0.9139]\u001b[A\n",
      "Training:  76%|███████▌  | 1349/1772 [03:28<01:03,  6.67it/s, running training loss: 0.8187]\u001b[A\n",
      "Training:  76%|███████▌  | 1350/1772 [03:28<01:03,  6.66it/s, running training loss: 0.8187]\u001b[A\n",
      "Training:  76%|███████▌  | 1350/1772 [03:28<01:03,  6.66it/s, running training loss: 1.4319]\u001b[A\n",
      "Training:  76%|███████▌  | 1351/1772 [03:28<01:00,  6.93it/s, running training loss: 1.4319]\u001b[A\n",
      "Training:  76%|███████▌  | 1351/1772 [03:28<01:00,  6.93it/s, running training loss: 0.6452]\u001b[A\n",
      "Training:  76%|███████▋  | 1352/1772 [03:28<00:59,  7.09it/s, running training loss: 0.6452]\u001b[A\n",
      "Training:  76%|███████▋  | 1352/1772 [03:28<00:59,  7.09it/s, running training loss: 1.0401]\u001b[A\n",
      "Training:  76%|███████▋  | 1353/1772 [03:28<00:57,  7.34it/s, running training loss: 1.0401]\u001b[A\n",
      "Training:  76%|███████▋  | 1353/1772 [03:28<00:57,  7.34it/s, running training loss: 0.7967]\u001b[A\n",
      "Training:  76%|███████▋  | 1354/1772 [03:28<00:57,  7.32it/s, running training loss: 0.7967]\u001b[A\n",
      "Training:  76%|███████▋  | 1354/1772 [03:29<00:57,  7.32it/s, running training loss: 1.2969]\u001b[A\n",
      "Training:  76%|███████▋  | 1355/1772 [03:29<00:59,  6.97it/s, running training loss: 1.2969]\u001b[A\n",
      "Training:  76%|███████▋  | 1355/1772 [03:29<00:59,  6.97it/s, running training loss: 1.0600]\u001b[A\n",
      "Training:  77%|███████▋  | 1356/1772 [03:29<00:58,  7.11it/s, running training loss: 1.0600]\u001b[A\n",
      "Training:  77%|███████▋  | 1356/1772 [03:29<00:58,  7.11it/s, running training loss: 1.2292]\u001b[A\n",
      "Training:  77%|███████▋  | 1357/1772 [03:29<00:58,  7.08it/s, running training loss: 1.2292]\u001b[A\n",
      "Training:  77%|███████▋  | 1357/1772 [03:29<00:58,  7.08it/s, running training loss: 1.2011]\u001b[A\n",
      "Training:  77%|███████▋  | 1358/1772 [03:29<00:59,  6.90it/s, running training loss: 1.2011]\u001b[A\n",
      "Training:  77%|███████▋  | 1358/1772 [03:29<00:59,  6.90it/s, running training loss: 0.9262]\u001b[A\n",
      "Training:  77%|███████▋  | 1359/1772 [03:29<00:58,  7.07it/s, running training loss: 0.9262]\u001b[A\n",
      "Training:  77%|███████▋  | 1359/1772 [03:29<00:58,  7.07it/s, running training loss: 0.9800]\u001b[A\n",
      "Training:  77%|███████▋  | 1360/1772 [03:29<00:58,  7.08it/s, running training loss: 0.9800]\u001b[A\n",
      "Training:  77%|███████▋  | 1360/1772 [03:29<00:58,  7.08it/s, running training loss: 1.2988]\u001b[A\n",
      "Training:  77%|███████▋  | 1361/1772 [03:29<00:56,  7.22it/s, running training loss: 1.2988]\u001b[A\n",
      "Training:  77%|███████▋  | 1361/1772 [03:30<00:56,  7.22it/s, running training loss: 1.1282]\u001b[A\n",
      "Training:  77%|███████▋  | 1362/1772 [03:30<00:56,  7.22it/s, running training loss: 1.1282]\u001b[A\n",
      "Training:  77%|███████▋  | 1362/1772 [03:30<00:56,  7.22it/s, running training loss: 1.2094]\u001b[A\n",
      "Training:  77%|███████▋  | 1363/1772 [03:30<00:56,  7.28it/s, running training loss: 1.2094]\u001b[A\n",
      "Training:  77%|███████▋  | 1363/1772 [03:30<00:56,  7.28it/s, running training loss: 1.4029]\u001b[A\n",
      "Training:  77%|███████▋  | 1364/1772 [03:30<01:04,  6.34it/s, running training loss: 1.4029]\u001b[A\n",
      "Training:  77%|███████▋  | 1364/1772 [03:30<01:04,  6.34it/s, running training loss: 0.8651]\u001b[A\n",
      "Training:  77%|███████▋  | 1365/1772 [03:30<01:01,  6.61it/s, running training loss: 0.8651]\u001b[A\n",
      "Training:  77%|███████▋  | 1365/1772 [03:30<01:01,  6.61it/s, running training loss: 0.7797]\u001b[A\n",
      "Training:  77%|███████▋  | 1366/1772 [03:30<00:59,  6.79it/s, running training loss: 0.7797]\u001b[A\n",
      "Training:  77%|███████▋  | 1366/1772 [03:30<00:59,  6.79it/s, running training loss: 1.3318]\u001b[A\n",
      "Training:  77%|███████▋  | 1367/1772 [03:30<01:03,  6.33it/s, running training loss: 1.3318]\u001b[A\n",
      "Training:  77%|███████▋  | 1367/1772 [03:30<01:03,  6.33it/s, running training loss: 1.0865]\u001b[A\n",
      "Training:  77%|███████▋  | 1368/1772 [03:30<00:59,  6.76it/s, running training loss: 1.0865]\u001b[A\n",
      "Training:  77%|███████▋  | 1368/1772 [03:31<00:59,  6.76it/s, running training loss: 1.0648]\u001b[A\n",
      "Training:  77%|███████▋  | 1369/1772 [03:31<01:02,  6.41it/s, running training loss: 1.0648]\u001b[A\n",
      "Training:  77%|███████▋  | 1369/1772 [03:31<01:02,  6.41it/s, running training loss: 0.7767]\u001b[A\n",
      "Training:  77%|███████▋  | 1370/1772 [03:31<00:59,  6.81it/s, running training loss: 0.7767]\u001b[A\n",
      "Training:  77%|███████▋  | 1370/1772 [03:31<00:59,  6.81it/s, running training loss: 0.8308]\u001b[A\n",
      "Training:  77%|███████▋  | 1371/1772 [03:31<00:56,  7.11it/s, running training loss: 0.8308]\u001b[A\n",
      "Training:  77%|███████▋  | 1371/1772 [03:31<00:56,  7.11it/s, running training loss: 0.8014]\u001b[A\n",
      "Training:  77%|███████▋  | 1372/1772 [03:31<00:58,  6.82it/s, running training loss: 0.8014]\u001b[A\n",
      "Training:  77%|███████▋  | 1372/1772 [03:31<00:58,  6.82it/s, running training loss: 0.9192]\u001b[A\n",
      "Training:  77%|███████▋  | 1373/1772 [03:31<00:59,  6.69it/s, running training loss: 0.9192]\u001b[A\n",
      "Training:  77%|███████▋  | 1373/1772 [03:31<00:59,  6.69it/s, running training loss: 1.0855]\u001b[A\n",
      "Training:  78%|███████▊  | 1374/1772 [03:31<00:58,  6.84it/s, running training loss: 1.0855]\u001b[A\n",
      "Training:  78%|███████▊  | 1374/1772 [03:31<00:58,  6.84it/s, running training loss: 0.9050]\u001b[A\n",
      "Training:  78%|███████▊  | 1375/1772 [03:31<00:58,  6.76it/s, running training loss: 0.9050]\u001b[A\n",
      "Training:  78%|███████▊  | 1375/1772 [03:32<00:58,  6.76it/s, running training loss: 0.8801]\u001b[A\n",
      "Training:  78%|███████▊  | 1376/1772 [03:32<00:58,  6.76it/s, running training loss: 0.8801]\u001b[A\n",
      "Training:  78%|███████▊  | 1376/1772 [03:32<00:58,  6.76it/s, running training loss: 0.9451]\u001b[A\n",
      "Training:  78%|███████▊  | 1377/1772 [03:32<01:04,  6.11it/s, running training loss: 0.9451]\u001b[A\n",
      "Training:  78%|███████▊  | 1377/1772 [03:32<01:04,  6.11it/s, running training loss: 1.0358]\u001b[A\n",
      "Training:  78%|███████▊  | 1378/1772 [03:32<01:01,  6.45it/s, running training loss: 1.0358]\u001b[A\n",
      "Training:  78%|███████▊  | 1378/1772 [03:32<01:01,  6.45it/s, running training loss: 1.2191]\u001b[A\n",
      "Training:  78%|███████▊  | 1379/1772 [03:32<00:59,  6.63it/s, running training loss: 1.2191]\u001b[A\n",
      "Training:  78%|███████▊  | 1379/1772 [03:32<00:59,  6.63it/s, running training loss: 1.3108]\u001b[A\n",
      "Training:  78%|███████▊  | 1380/1772 [03:32<01:00,  6.49it/s, running training loss: 1.3108]\u001b[A\n",
      "Training:  78%|███████▊  | 1380/1772 [03:32<01:00,  6.49it/s, running training loss: 1.3123]\u001b[A\n",
      "Training:  78%|███████▊  | 1381/1772 [03:32<00:57,  6.74it/s, running training loss: 1.3123]\u001b[A\n",
      "Training:  78%|███████▊  | 1381/1772 [03:33<00:57,  6.74it/s, running training loss: 0.8959]\u001b[A\n",
      "Training:  78%|███████▊  | 1382/1772 [03:33<00:56,  6.88it/s, running training loss: 0.8959]\u001b[A\n",
      "Training:  78%|███████▊  | 1382/1772 [03:33<00:56,  6.88it/s, running training loss: 1.2506]\u001b[A\n",
      "Training:  78%|███████▊  | 1383/1772 [03:33<01:00,  6.47it/s, running training loss: 1.2506]\u001b[A\n",
      "Training:  78%|███████▊  | 1383/1772 [03:33<01:00,  6.47it/s, running training loss: 1.1241]\u001b[A\n",
      "Training:  78%|███████▊  | 1384/1772 [03:33<01:01,  6.31it/s, running training loss: 1.1241]\u001b[A\n",
      "Training:  78%|███████▊  | 1384/1772 [03:33<01:01,  6.31it/s, running training loss: 1.5384]\u001b[A\n",
      "Training:  78%|███████▊  | 1385/1772 [03:33<01:03,  6.10it/s, running training loss: 1.5384]\u001b[A\n",
      "Training:  78%|███████▊  | 1385/1772 [03:33<01:03,  6.10it/s, running training loss: 1.2140]\u001b[A\n",
      "Training:  78%|███████▊  | 1386/1772 [03:33<00:59,  6.51it/s, running training loss: 1.2140]\u001b[A\n",
      "Training:  78%|███████▊  | 1386/1772 [03:33<00:59,  6.51it/s, running training loss: 0.9166]\u001b[A\n",
      "Training:  78%|███████▊  | 1387/1772 [03:33<01:06,  5.82it/s, running training loss: 0.9166]\u001b[A\n",
      "Training:  78%|███████▊  | 1387/1772 [03:34<01:06,  5.82it/s, running training loss: 0.9413]\u001b[A\n",
      "Training:  78%|███████▊  | 1388/1772 [03:34<01:03,  6.05it/s, running training loss: 0.9413]\u001b[A\n",
      "Training:  78%|███████▊  | 1388/1772 [03:34<01:03,  6.05it/s, running training loss: 1.0308]\u001b[A\n",
      "Training:  78%|███████▊  | 1389/1772 [03:34<01:01,  6.23it/s, running training loss: 1.0308]\u001b[A\n",
      "Training:  78%|███████▊  | 1389/1772 [03:34<01:01,  6.23it/s, running training loss: 0.9787]\u001b[A\n",
      "Training:  78%|███████▊  | 1390/1772 [03:34<00:57,  6.67it/s, running training loss: 0.9787]\u001b[A\n",
      "Training:  78%|███████▊  | 1390/1772 [03:34<00:57,  6.67it/s, running training loss: 0.9045]\u001b[A\n",
      "Training:  78%|███████▊  | 1391/1772 [03:34<00:56,  6.75it/s, running training loss: 0.9045]\u001b[A\n",
      "Training:  78%|███████▊  | 1391/1772 [03:34<00:56,  6.75it/s, running training loss: 0.8888]\u001b[A\n",
      "Training:  79%|███████▊  | 1392/1772 [03:34<00:54,  6.96it/s, running training loss: 0.8888]\u001b[A\n",
      "Training:  79%|███████▊  | 1392/1772 [03:34<00:54,  6.96it/s, running training loss: 0.9166]\u001b[A\n",
      "Training:  79%|███████▊  | 1393/1772 [03:34<00:56,  6.73it/s, running training loss: 0.9166]\u001b[A\n",
      "Training:  79%|███████▊  | 1393/1772 [03:34<00:56,  6.73it/s, running training loss: 0.9812]\u001b[A\n",
      "Training:  79%|███████▊  | 1394/1772 [03:34<00:56,  6.67it/s, running training loss: 0.9812]\u001b[A\n",
      "Training:  79%|███████▊  | 1394/1772 [03:35<00:56,  6.67it/s, running training loss: 0.9739]\u001b[A\n",
      "Training:  79%|███████▊  | 1395/1772 [03:35<00:54,  6.87it/s, running training loss: 0.9739]\u001b[A\n",
      "Training:  79%|███████▊  | 1395/1772 [03:35<00:54,  6.87it/s, running training loss: 1.1599]\u001b[A\n",
      "Training:  79%|███████▉  | 1396/1772 [03:35<00:53,  7.07it/s, running training loss: 1.1599]\u001b[A\n",
      "Training:  79%|███████▉  | 1396/1772 [03:35<00:53,  7.07it/s, running training loss: 0.9332]\u001b[A\n",
      "Training:  79%|███████▉  | 1397/1772 [03:35<00:51,  7.24it/s, running training loss: 0.9332]\u001b[A\n",
      "Training:  79%|███████▉  | 1397/1772 [03:35<00:51,  7.24it/s, running training loss: 0.9984]\u001b[A\n",
      "Training:  79%|███████▉  | 1398/1772 [03:35<00:55,  6.76it/s, running training loss: 0.9984]\u001b[A\n",
      "Training:  79%|███████▉  | 1398/1772 [03:35<00:55,  6.76it/s, running training loss: 0.8827]\u001b[A\n",
      "Training:  79%|███████▉  | 1399/1772 [03:35<00:53,  6.94it/s, running training loss: 0.8827]\u001b[A\n",
      "Training:  79%|███████▉  | 1399/1772 [03:35<00:53,  6.94it/s, running training loss: 0.9251]\u001b[A\n",
      "Training:  79%|███████▉  | 1400/1772 [03:35<00:54,  6.78it/s, running training loss: 0.9251]\u001b[A\n",
      "Training:  79%|███████▉  | 1400/1772 [03:35<00:54,  6.78it/s, running training loss: 1.0845]\u001b[A\n",
      "Training:  79%|███████▉  | 1401/1772 [03:35<00:56,  6.51it/s, running training loss: 1.0845]\u001b[A\n",
      "Training:  79%|███████▉  | 1401/1772 [03:36<00:56,  6.51it/s, running training loss: 0.7810]\u001b[A\n",
      "Training:  79%|███████▉  | 1402/1772 [03:36<00:59,  6.25it/s, running training loss: 0.7810]\u001b[A\n",
      "Training:  79%|███████▉  | 1402/1772 [03:36<00:59,  6.25it/s, running training loss: 0.8496]\u001b[A\n",
      "Training:  79%|███████▉  | 1403/1772 [03:36<01:03,  5.81it/s, running training loss: 0.8496]\u001b[A\n",
      "Training:  79%|███████▉  | 1403/1772 [03:36<01:03,  5.81it/s, running training loss: 0.9969]\u001b[A\n",
      "Training:  79%|███████▉  | 1404/1772 [03:36<01:01,  5.94it/s, running training loss: 0.9969]\u001b[A\n",
      "Training:  79%|███████▉  | 1404/1772 [03:36<01:01,  5.94it/s, running training loss: 0.9203]\u001b[A\n",
      "Training:  79%|███████▉  | 1405/1772 [03:36<00:57,  6.34it/s, running training loss: 0.9203]\u001b[A\n",
      "Training:  79%|███████▉  | 1405/1772 [03:36<00:57,  6.34it/s, running training loss: 0.9202]\u001b[A\n",
      "Training:  79%|███████▉  | 1406/1772 [03:36<00:54,  6.72it/s, running training loss: 0.9202]\u001b[A\n",
      "Training:  79%|███████▉  | 1406/1772 [03:36<00:54,  6.72it/s, running training loss: 0.8911]\u001b[A\n",
      "Training:  79%|███████▉  | 1407/1772 [03:36<00:52,  7.02it/s, running training loss: 0.8911]\u001b[A\n",
      "Training:  79%|███████▉  | 1407/1772 [03:37<00:52,  7.02it/s, running training loss: 0.9253]\u001b[A\n",
      "Training:  79%|███████▉  | 1408/1772 [03:37<00:55,  6.60it/s, running training loss: 0.9253]\u001b[A\n",
      "Training:  79%|███████▉  | 1408/1772 [03:37<00:55,  6.60it/s, running training loss: 1.3277]\u001b[A\n",
      "Training:  80%|███████▉  | 1409/1772 [03:37<00:58,  6.22it/s, running training loss: 1.3277]\u001b[A\n",
      "Training:  80%|███████▉  | 1409/1772 [03:37<00:58,  6.22it/s, running training loss: 1.4288]\u001b[A\n",
      "Training:  80%|███████▉  | 1410/1772 [03:37<00:56,  6.39it/s, running training loss: 1.4288]\u001b[A\n",
      "Training:  80%|███████▉  | 1410/1772 [03:37<00:56,  6.39it/s, running training loss: 0.7766]\u001b[A\n",
      "Training:  80%|███████▉  | 1411/1772 [03:37<00:55,  6.52it/s, running training loss: 0.7766]\u001b[A\n",
      "Training:  80%|███████▉  | 1411/1772 [03:37<00:55,  6.52it/s, running training loss: 1.1025]\u001b[A\n",
      "Training:  80%|███████▉  | 1412/1772 [03:37<00:53,  6.76it/s, running training loss: 1.1025]\u001b[A\n",
      "Training:  80%|███████▉  | 1412/1772 [03:37<00:53,  6.76it/s, running training loss: 0.9676]\u001b[A\n",
      "Training:  80%|███████▉  | 1413/1772 [03:37<00:51,  6.91it/s, running training loss: 0.9676]\u001b[A\n",
      "Training:  80%|███████▉  | 1413/1772 [03:37<00:51,  6.91it/s, running training loss: 0.9986]\u001b[A\n",
      "Training:  80%|███████▉  | 1414/1772 [03:37<00:49,  7.24it/s, running training loss: 0.9986]\u001b[A\n",
      "Training:  80%|███████▉  | 1414/1772 [03:38<00:49,  7.24it/s, running training loss: 1.0611]\u001b[A\n",
      "Training:  80%|███████▉  | 1415/1772 [03:38<00:50,  7.03it/s, running training loss: 1.0611]\u001b[A\n",
      "Training:  80%|███████▉  | 1415/1772 [03:38<00:50,  7.03it/s, running training loss: 0.8844]\u001b[A\n",
      "Training:  80%|███████▉  | 1416/1772 [03:38<00:49,  7.26it/s, running training loss: 0.8844]\u001b[A\n",
      "Training:  80%|███████▉  | 1416/1772 [03:38<00:49,  7.26it/s, running training loss: 0.9564]\u001b[A\n",
      "Training:  80%|███████▉  | 1417/1772 [03:38<00:52,  6.78it/s, running training loss: 0.9564]\u001b[A\n",
      "Training:  80%|███████▉  | 1417/1772 [03:38<00:52,  6.78it/s, running training loss: 1.0101]\u001b[A\n",
      "Training:  80%|████████  | 1418/1772 [03:38<00:50,  7.02it/s, running training loss: 1.0101]\u001b[A\n",
      "Training:  80%|████████  | 1418/1772 [03:38<00:50,  7.02it/s, running training loss: 0.8989]\u001b[A\n",
      "Training:  80%|████████  | 1419/1772 [03:38<00:49,  7.12it/s, running training loss: 0.8989]\u001b[A\n",
      "Training:  80%|████████  | 1419/1772 [03:38<00:49,  7.12it/s, running training loss: 0.7944]\u001b[A\n",
      "Training:  80%|████████  | 1420/1772 [03:38<00:48,  7.30it/s, running training loss: 0.7944]\u001b[A\n",
      "Training:  80%|████████  | 1420/1772 [03:38<00:48,  7.30it/s, running training loss: 0.8901]\u001b[A\n",
      "Training:  80%|████████  | 1421/1772 [03:38<00:53,  6.57it/s, running training loss: 0.8901]\u001b[A\n",
      "Training:  80%|████████  | 1421/1772 [03:39<00:53,  6.57it/s, running training loss: 0.7953]\u001b[A\n",
      "Training:  80%|████████  | 1422/1772 [03:39<00:51,  6.75it/s, running training loss: 0.7953]\u001b[A\n",
      "Training:  80%|████████  | 1422/1772 [03:39<00:51,  6.75it/s, running training loss: 0.9935]\u001b[A\n",
      "Training:  80%|████████  | 1423/1772 [03:39<00:49,  7.00it/s, running training loss: 0.9935]\u001b[A\n",
      "Training:  80%|████████  | 1423/1772 [03:39<00:49,  7.00it/s, running training loss: 0.9495]\u001b[A\n",
      "Training:  80%|████████  | 1424/1772 [03:39<00:49,  7.06it/s, running training loss: 0.9495]\u001b[A\n",
      "Training:  80%|████████  | 1424/1772 [03:39<00:49,  7.06it/s, running training loss: 0.7734]\u001b[A\n",
      "Training:  80%|████████  | 1425/1772 [03:39<00:50,  6.94it/s, running training loss: 0.7734]\u001b[A\n",
      "Training:  80%|████████  | 1425/1772 [03:39<00:50,  6.94it/s, running training loss: 1.1193]\u001b[A\n",
      "Training:  80%|████████  | 1426/1772 [03:39<00:48,  7.10it/s, running training loss: 1.1193]\u001b[A\n",
      "Training:  80%|████████  | 1426/1772 [03:39<00:48,  7.10it/s, running training loss: 1.6565]\u001b[A\n",
      "Training:  81%|████████  | 1427/1772 [03:39<00:49,  7.00it/s, running training loss: 1.6565]\u001b[A\n",
      "Training:  81%|████████  | 1427/1772 [03:39<00:49,  7.00it/s, running training loss: 1.0017]\u001b[A\n",
      "Training:  81%|████████  | 1428/1772 [03:39<00:48,  7.08it/s, running training loss: 1.0017]\u001b[A\n",
      "Training:  81%|████████  | 1428/1772 [03:40<00:48,  7.08it/s, running training loss: 0.9370]\u001b[A\n",
      "Training:  81%|████████  | 1429/1772 [03:40<00:47,  7.21it/s, running training loss: 0.9370]\u001b[A\n",
      "Training:  81%|████████  | 1429/1772 [03:40<00:47,  7.21it/s, running training loss: 1.2598]\u001b[A\n",
      "Training:  81%|████████  | 1430/1772 [03:40<00:47,  7.27it/s, running training loss: 1.2598]\u001b[A\n",
      "Training:  81%|████████  | 1430/1772 [03:40<00:47,  7.27it/s, running training loss: 1.4490]\u001b[A\n",
      "Training:  81%|████████  | 1431/1772 [03:40<00:49,  6.92it/s, running training loss: 1.4490]\u001b[A\n",
      "Training:  81%|████████  | 1431/1772 [03:40<00:49,  6.92it/s, running training loss: 1.5492]\u001b[A\n",
      "Training:  81%|████████  | 1432/1772 [03:40<00:46,  7.37it/s, running training loss: 1.5492]\u001b[A\n",
      "Training:  81%|████████  | 1432/1772 [03:40<00:46,  7.37it/s, running training loss: 0.8871]\u001b[A\n",
      "Training:  81%|████████  | 1433/1772 [03:40<00:50,  6.68it/s, running training loss: 0.8871]\u001b[A\n",
      "Training:  81%|████████  | 1433/1772 [03:40<00:50,  6.68it/s, running training loss: 0.8814]\u001b[A\n",
      "Training:  81%|████████  | 1434/1772 [03:40<00:53,  6.30it/s, running training loss: 0.8814]\u001b[A\n",
      "Training:  81%|████████  | 1434/1772 [03:40<00:53,  6.30it/s, running training loss: 0.8603]\u001b[A\n",
      "Training:  81%|████████  | 1435/1772 [03:40<00:53,  6.36it/s, running training loss: 0.8603]\u001b[A\n",
      "Training:  81%|████████  | 1435/1772 [03:41<00:53,  6.36it/s, running training loss: 0.9177]\u001b[A\n",
      "Training:  81%|████████  | 1436/1772 [03:41<00:49,  6.72it/s, running training loss: 0.9177]\u001b[A\n",
      "Training:  81%|████████  | 1436/1772 [03:41<00:49,  6.72it/s, running training loss: 1.0750]\u001b[A\n",
      "Training:  81%|████████  | 1437/1772 [03:41<00:51,  6.50it/s, running training loss: 1.0750]\u001b[A\n",
      "Training:  81%|████████  | 1437/1772 [03:41<00:51,  6.50it/s, running training loss: 1.1513]\u001b[A\n",
      "Training:  81%|████████  | 1438/1772 [03:41<00:51,  6.43it/s, running training loss: 1.1513]\u001b[A\n",
      "Training:  81%|████████  | 1438/1772 [03:41<00:51,  6.43it/s, running training loss: 0.9161]\u001b[A\n",
      "Training:  81%|████████  | 1439/1772 [03:41<00:49,  6.66it/s, running training loss: 0.9161]\u001b[A\n",
      "Training:  81%|████████  | 1439/1772 [03:41<00:49,  6.66it/s, running training loss: 1.0744]\u001b[A\n",
      "Training:  81%|████████▏ | 1440/1772 [03:41<00:54,  6.15it/s, running training loss: 1.0744]\u001b[A\n",
      "Training:  81%|████████▏ | 1440/1772 [03:41<00:54,  6.15it/s, running training loss: 0.9201]\u001b[A\n",
      "Training:  81%|████████▏ | 1441/1772 [03:41<00:50,  6.50it/s, running training loss: 0.9201]\u001b[A\n",
      "Training:  81%|████████▏ | 1441/1772 [03:42<00:50,  6.50it/s, running training loss: 0.9443]\u001b[A\n",
      "Training:  81%|████████▏ | 1442/1772 [03:42<00:50,  6.54it/s, running training loss: 0.9443]\u001b[A\n",
      "Training:  81%|████████▏ | 1442/1772 [03:42<00:50,  6.54it/s, running training loss: 0.9496]\u001b[A\n",
      "Training:  81%|████████▏ | 1443/1772 [03:42<00:47,  6.86it/s, running training loss: 0.9496]\u001b[A\n",
      "Training:  81%|████████▏ | 1443/1772 [03:42<00:47,  6.86it/s, running training loss: 0.8273]\u001b[A\n",
      "Training:  81%|████████▏ | 1444/1772 [03:42<00:51,  6.37it/s, running training loss: 0.8273]\u001b[A\n",
      "Training:  81%|████████▏ | 1444/1772 [03:42<00:51,  6.37it/s, running training loss: 0.8536]\u001b[A\n",
      "Training:  82%|████████▏ | 1445/1772 [03:42<00:49,  6.61it/s, running training loss: 0.8536]\u001b[A\n",
      "Training:  82%|████████▏ | 1445/1772 [03:42<00:49,  6.61it/s, running training loss: 0.8002]\u001b[A\n",
      "Training:  82%|████████▏ | 1446/1772 [03:42<00:48,  6.76it/s, running training loss: 0.8002]\u001b[A\n",
      "Training:  82%|████████▏ | 1446/1772 [03:42<00:48,  6.76it/s, running training loss: 0.8393]\u001b[A\n",
      "Training:  82%|████████▏ | 1447/1772 [03:42<00:48,  6.69it/s, running training loss: 0.8393]\u001b[A\n",
      "Training:  82%|████████▏ | 1447/1772 [03:42<00:48,  6.69it/s, running training loss: 0.8893]\u001b[A\n",
      "Training:  82%|████████▏ | 1448/1772 [03:42<00:46,  6.96it/s, running training loss: 0.8893]\u001b[A\n",
      "Training:  82%|████████▏ | 1448/1772 [03:43<00:46,  6.96it/s, running training loss: 1.0056]\u001b[A\n",
      "Training:  82%|████████▏ | 1449/1772 [03:43<00:46,  6.91it/s, running training loss: 1.0056]\u001b[A\n",
      "Training:  82%|████████▏ | 1449/1772 [03:43<00:46,  6.91it/s, running training loss: 1.0006]\u001b[A\n",
      "Training:  82%|████████▏ | 1450/1772 [03:43<00:45,  7.00it/s, running training loss: 1.0006]\u001b[A\n",
      "Training:  82%|████████▏ | 1450/1772 [03:43<00:45,  7.00it/s, running training loss: 0.9608]\u001b[A\n",
      "Training:  82%|████████▏ | 1451/1772 [03:43<00:44,  7.18it/s, running training loss: 0.9608]\u001b[A\n",
      "Training:  82%|████████▏ | 1451/1772 [03:43<00:44,  7.18it/s, running training loss: 0.9961]\u001b[A\n",
      "Training:  82%|████████▏ | 1452/1772 [03:43<00:44,  7.18it/s, running training loss: 0.9961]\u001b[A\n",
      "Training:  82%|████████▏ | 1452/1772 [03:43<00:44,  7.18it/s, running training loss: 0.8247]\u001b[A\n",
      "Training:  82%|████████▏ | 1453/1772 [03:43<00:44,  7.23it/s, running training loss: 0.8247]\u001b[A\n",
      "Training:  82%|████████▏ | 1453/1772 [03:43<00:44,  7.23it/s, running training loss: 0.9331]\u001b[A\n",
      "Training:  82%|████████▏ | 1454/1772 [03:43<00:45,  6.94it/s, running training loss: 0.9331]\u001b[A\n",
      "Training:  82%|████████▏ | 1454/1772 [03:43<00:45,  6.94it/s, running training loss: 0.8599]\u001b[A\n",
      "Training:  82%|████████▏ | 1455/1772 [03:43<00:44,  7.14it/s, running training loss: 0.8599]\u001b[A\n",
      "Training:  82%|████████▏ | 1455/1772 [03:44<00:44,  7.14it/s, running training loss: 0.9800]\u001b[A\n",
      "Training:  82%|████████▏ | 1456/1772 [03:44<00:43,  7.25it/s, running training loss: 0.9800]\u001b[A\n",
      "Training:  82%|████████▏ | 1456/1772 [03:44<00:43,  7.25it/s, running training loss: 0.9520]\u001b[A\n",
      "Training:  82%|████████▏ | 1457/1772 [03:44<00:42,  7.40it/s, running training loss: 0.9520]\u001b[A\n",
      "Training:  82%|████████▏ | 1457/1772 [03:44<00:42,  7.40it/s, running training loss: 0.9817]\u001b[A\n",
      "Training:  82%|████████▏ | 1458/1772 [03:44<00:44,  7.07it/s, running training loss: 0.9817]\u001b[A\n",
      "Training:  82%|████████▏ | 1458/1772 [03:44<00:44,  7.07it/s, running training loss: 0.9934]\u001b[A\n",
      "Training:  82%|████████▏ | 1459/1772 [03:44<00:44,  7.04it/s, running training loss: 0.9934]\u001b[A\n",
      "Training:  82%|████████▏ | 1459/1772 [03:44<00:44,  7.04it/s, running training loss: 1.0323]\u001b[A\n",
      "Training:  82%|████████▏ | 1460/1772 [03:44<00:48,  6.37it/s, running training loss: 1.0323]\u001b[A\n",
      "Training:  82%|████████▏ | 1460/1772 [03:44<00:48,  6.37it/s, running training loss: 1.2704]\u001b[A\n",
      "Training:  82%|████████▏ | 1461/1772 [03:44<00:49,  6.30it/s, running training loss: 1.2704]\u001b[A\n",
      "Training:  82%|████████▏ | 1461/1772 [03:45<00:49,  6.30it/s, running training loss: 0.9433]\u001b[A\n",
      "Training:  83%|████████▎ | 1462/1772 [03:45<00:54,  5.66it/s, running training loss: 0.9433]\u001b[A\n",
      "Training:  83%|████████▎ | 1462/1772 [03:45<00:54,  5.66it/s, running training loss: 0.8885]\u001b[A\n",
      "Training:  83%|████████▎ | 1463/1772 [03:45<00:50,  6.13it/s, running training loss: 0.8885]\u001b[A\n",
      "Training:  83%|████████▎ | 1463/1772 [03:45<00:50,  6.13it/s, running training loss: 0.6966]\u001b[A\n",
      "Training:  83%|████████▎ | 1464/1772 [03:45<00:47,  6.48it/s, running training loss: 0.6966]\u001b[A\n",
      "Training:  83%|████████▎ | 1464/1772 [03:45<00:47,  6.48it/s, running training loss: 1.3146]\u001b[A\n",
      "Training:  83%|████████▎ | 1465/1772 [03:45<00:45,  6.68it/s, running training loss: 1.3146]\u001b[A\n",
      "Training:  83%|████████▎ | 1465/1772 [03:45<00:45,  6.68it/s, running training loss: 1.0735]\u001b[A\n",
      "Training:  83%|████████▎ | 1466/1772 [03:45<00:45,  6.79it/s, running training loss: 1.0735]\u001b[A\n",
      "Training:  83%|████████▎ | 1466/1772 [03:45<00:45,  6.79it/s, running training loss: 1.1717]\u001b[A\n",
      "Training:  83%|████████▎ | 1467/1772 [03:45<00:43,  6.97it/s, running training loss: 1.1717]\u001b[A\n",
      "Training:  83%|████████▎ | 1467/1772 [03:45<00:43,  6.97it/s, running training loss: 0.9548]\u001b[A\n",
      "Training:  83%|████████▎ | 1468/1772 [03:45<00:45,  6.69it/s, running training loss: 0.9548]\u001b[A\n",
      "Training:  83%|████████▎ | 1468/1772 [03:46<00:45,  6.69it/s, running training loss: 1.0641]\u001b[A\n",
      "Training:  83%|████████▎ | 1469/1772 [03:46<00:45,  6.68it/s, running training loss: 1.0641]\u001b[A\n",
      "Training:  83%|████████▎ | 1469/1772 [03:46<00:45,  6.68it/s, running training loss: 0.7808]\u001b[A\n",
      "Training:  83%|████████▎ | 1470/1772 [03:46<00:46,  6.43it/s, running training loss: 0.7808]\u001b[A\n",
      "Training:  83%|████████▎ | 1470/1772 [03:46<00:46,  6.43it/s, running training loss: 0.9817]\u001b[A\n",
      "Training:  83%|████████▎ | 1471/1772 [03:46<00:46,  6.51it/s, running training loss: 0.9817]\u001b[A\n",
      "Training:  83%|████████▎ | 1471/1772 [03:46<00:46,  6.51it/s, running training loss: 0.8234]\u001b[A\n",
      "Training:  83%|████████▎ | 1472/1772 [03:46<00:46,  6.42it/s, running training loss: 0.8234]\u001b[A\n",
      "Training:  83%|████████▎ | 1472/1772 [03:46<00:46,  6.42it/s, running training loss: 1.0552]\u001b[A\n",
      "Training:  83%|████████▎ | 1473/1772 [03:46<00:45,  6.52it/s, running training loss: 1.0552]\u001b[A\n",
      "Training:  83%|████████▎ | 1473/1772 [03:46<00:45,  6.52it/s, running training loss: 0.8690]\u001b[A\n",
      "Training:  83%|████████▎ | 1474/1772 [03:46<00:46,  6.46it/s, running training loss: 0.8690]\u001b[A\n",
      "Training:  83%|████████▎ | 1474/1772 [03:46<00:46,  6.46it/s, running training loss: 1.2776]\u001b[A\n",
      "Training:  83%|████████▎ | 1475/1772 [03:46<00:44,  6.71it/s, running training loss: 1.2776]\u001b[A\n",
      "Training:  83%|████████▎ | 1475/1772 [03:47<00:44,  6.71it/s, running training loss: 1.1771]\u001b[A\n",
      "Training:  83%|████████▎ | 1476/1772 [03:47<00:43,  6.74it/s, running training loss: 1.1771]\u001b[A\n",
      "Training:  83%|████████▎ | 1476/1772 [03:47<00:43,  6.74it/s, running training loss: 1.0776]\u001b[A\n",
      "Training:  83%|████████▎ | 1477/1772 [03:47<00:43,  6.79it/s, running training loss: 1.0776]\u001b[A\n",
      "Training:  83%|████████▎ | 1477/1772 [03:47<00:43,  6.79it/s, running training loss: 0.8339]\u001b[A\n",
      "Training:  83%|████████▎ | 1478/1772 [03:47<00:45,  6.47it/s, running training loss: 0.8339]\u001b[A\n",
      "Training:  83%|████████▎ | 1478/1772 [03:47<00:45,  6.47it/s, running training loss: 1.0082]\u001b[A\n",
      "Training:  83%|████████▎ | 1479/1772 [03:47<00:43,  6.78it/s, running training loss: 1.0082]\u001b[A\n",
      "Training:  83%|████████▎ | 1479/1772 [03:47<00:43,  6.78it/s, running training loss: 0.8114]\u001b[A\n",
      "Training:  84%|████████▎ | 1480/1772 [03:47<00:42,  6.92it/s, running training loss: 0.8114]\u001b[A\n",
      "Training:  84%|████████▎ | 1480/1772 [03:47<00:42,  6.92it/s, running training loss: 1.1239]\u001b[A\n",
      "Training:  84%|████████▎ | 1481/1772 [03:47<00:45,  6.44it/s, running training loss: 1.1239]\u001b[A\n",
      "Training:  84%|████████▎ | 1481/1772 [03:48<00:45,  6.44it/s, running training loss: 0.8248]\u001b[A\n",
      "Training:  84%|████████▎ | 1482/1772 [03:48<00:46,  6.20it/s, running training loss: 0.8248]\u001b[A\n",
      "Training:  84%|████████▎ | 1482/1772 [03:48<00:46,  6.20it/s, running training loss: 0.8013]\u001b[A\n",
      "Training:  84%|████████▎ | 1483/1772 [03:48<00:44,  6.51it/s, running training loss: 0.8013]\u001b[A\n",
      "Training:  84%|████████▎ | 1483/1772 [03:48<00:44,  6.51it/s, running training loss: 1.0370]\u001b[A\n",
      "Training:  84%|████████▎ | 1484/1772 [03:48<00:45,  6.39it/s, running training loss: 1.0370]\u001b[A\n",
      "Training:  84%|████████▎ | 1484/1772 [03:48<00:45,  6.39it/s, running training loss: 1.1038]\u001b[A\n",
      "Training:  84%|████████▍ | 1485/1772 [03:48<00:42,  6.77it/s, running training loss: 1.1038]\u001b[A\n",
      "Training:  84%|████████▍ | 1485/1772 [03:48<00:42,  6.77it/s, running training loss: 1.0511]\u001b[A\n",
      "Training:  84%|████████▍ | 1486/1772 [03:48<00:40,  7.09it/s, running training loss: 1.0511]\u001b[A\n",
      "Training:  84%|████████▍ | 1486/1772 [03:48<00:40,  7.09it/s, running training loss: 1.1832]\u001b[A\n",
      "Training:  84%|████████▍ | 1487/1772 [03:48<00:39,  7.22it/s, running training loss: 1.1832]\u001b[A\n",
      "Training:  84%|████████▍ | 1487/1772 [03:48<00:39,  7.22it/s, running training loss: 0.7403]\u001b[A\n",
      "Training:  84%|████████▍ | 1488/1772 [03:48<00:39,  7.25it/s, running training loss: 0.7403]\u001b[A\n",
      "Training:  84%|████████▍ | 1488/1772 [03:48<00:39,  7.25it/s, running training loss: 1.0329]\u001b[A\n",
      "Training:  84%|████████▍ | 1489/1772 [03:48<00:38,  7.29it/s, running training loss: 1.0329]\u001b[A\n",
      "Training:  84%|████████▍ | 1489/1772 [03:49<00:38,  7.29it/s, running training loss: 0.9669]\u001b[A\n",
      "Training:  84%|████████▍ | 1490/1772 [03:49<00:40,  7.04it/s, running training loss: 0.9669]\u001b[A\n",
      "Training:  84%|████████▍ | 1490/1772 [03:49<00:40,  7.04it/s, running training loss: 0.7452]\u001b[A\n",
      "Training:  84%|████████▍ | 1491/1772 [03:49<00:39,  7.18it/s, running training loss: 0.7452]\u001b[A\n",
      "Training:  84%|████████▍ | 1491/1772 [03:49<00:39,  7.18it/s, running training loss: 0.9576]\u001b[A\n",
      "Training:  84%|████████▍ | 1492/1772 [03:49<00:39,  7.16it/s, running training loss: 0.9576]\u001b[A\n",
      "Training:  84%|████████▍ | 1492/1772 [03:49<00:39,  7.16it/s, running training loss: 0.9121]\u001b[A\n",
      "Training:  84%|████████▍ | 1493/1772 [03:49<00:38,  7.30it/s, running training loss: 0.9121]\u001b[A\n",
      "Training:  84%|████████▍ | 1493/1772 [03:49<00:38,  7.30it/s, running training loss: 1.1238]\u001b[A\n",
      "Training:  84%|████████▍ | 1494/1772 [03:49<00:38,  7.18it/s, running training loss: 1.1238]\u001b[A\n",
      "Training:  84%|████████▍ | 1494/1772 [03:49<00:38,  7.18it/s, running training loss: 0.9647]\u001b[A\n",
      "Training:  84%|████████▍ | 1495/1772 [03:49<00:39,  7.03it/s, running training loss: 0.9647]\u001b[A\n",
      "Training:  84%|████████▍ | 1495/1772 [03:49<00:39,  7.03it/s, running training loss: 0.9104]\u001b[A\n",
      "Training:  84%|████████▍ | 1496/1772 [03:49<00:38,  7.11it/s, running training loss: 0.9104]\u001b[A\n",
      "Training:  84%|████████▍ | 1496/1772 [03:50<00:38,  7.11it/s, running training loss: 0.9064]\u001b[A\n",
      "Training:  84%|████████▍ | 1497/1772 [03:50<00:38,  7.23it/s, running training loss: 0.9064]\u001b[A\n",
      "Training:  84%|████████▍ | 1497/1772 [03:50<00:38,  7.23it/s, running training loss: 0.9330]\u001b[A\n",
      "Training:  85%|████████▍ | 1498/1772 [03:50<00:39,  6.99it/s, running training loss: 0.9330]\u001b[A\n",
      "Training:  85%|████████▍ | 1498/1772 [03:50<00:39,  6.99it/s, running training loss: 1.0497]\u001b[A\n",
      "Training:  85%|████████▍ | 1499/1772 [03:50<00:38,  7.08it/s, running training loss: 1.0497]\u001b[A\n",
      "Training:  85%|████████▍ | 1499/1772 [03:50<00:38,  7.08it/s, running training loss: 0.8861]\u001b[A\n",
      "Training:  85%|████████▍ | 1500/1772 [03:50<00:38,  7.15it/s, running training loss: 0.8861]\u001b[A\n",
      "Training:  85%|████████▍ | 1500/1772 [03:50<00:38,  7.15it/s, running training loss: 0.9044]\u001b[A\n",
      "Training:  85%|████████▍ | 1501/1772 [03:50<00:37,  7.19it/s, running training loss: 0.9044]\u001b[A\n",
      "Training:  85%|████████▍ | 1501/1772 [03:50<00:37,  7.19it/s, running training loss: 0.7266]\u001b[A\n",
      "Training:  85%|████████▍ | 1502/1772 [03:50<00:38,  6.96it/s, running training loss: 0.7266]\u001b[A\n",
      "Training:  85%|████████▍ | 1502/1772 [03:50<00:38,  6.96it/s, running training loss: 0.8126]\u001b[A\n",
      "Training:  85%|████████▍ | 1503/1772 [03:50<00:37,  7.12it/s, running training loss: 0.8126]\u001b[A\n",
      "Training:  85%|████████▍ | 1503/1772 [03:51<00:37,  7.12it/s, running training loss: 1.1147]\u001b[A\n",
      "Training:  85%|████████▍ | 1504/1772 [03:51<00:37,  7.14it/s, running training loss: 1.1147]\u001b[A\n",
      "Training:  85%|████████▍ | 1504/1772 [03:51<00:37,  7.14it/s, running training loss: 1.2439]\u001b[A\n",
      "Training:  85%|████████▍ | 1505/1772 [03:51<00:38,  6.93it/s, running training loss: 1.2439]\u001b[A\n",
      "Training:  85%|████████▍ | 1505/1772 [03:51<00:38,  6.93it/s, running training loss: 0.7810]\u001b[A\n",
      "Training:  85%|████████▍ | 1506/1772 [03:51<00:39,  6.77it/s, running training loss: 0.7810]\u001b[A\n",
      "Training:  85%|████████▍ | 1506/1772 [03:51<00:39,  6.77it/s, running training loss: 1.0786]\u001b[A\n",
      "Training:  85%|████████▌ | 1507/1772 [03:51<00:39,  6.65it/s, running training loss: 1.0786]\u001b[A\n",
      "Training:  85%|████████▌ | 1507/1772 [03:51<00:39,  6.65it/s, running training loss: 1.0139]\u001b[A\n",
      "Training:  85%|████████▌ | 1508/1772 [03:51<00:39,  6.65it/s, running training loss: 1.0139]\u001b[A\n",
      "Training:  85%|████████▌ | 1508/1772 [03:51<00:39,  6.65it/s, running training loss: 1.3255]\u001b[A\n",
      "Training:  85%|████████▌ | 1509/1772 [03:51<00:38,  6.90it/s, running training loss: 1.3255]\u001b[A\n",
      "Training:  85%|████████▌ | 1509/1772 [03:51<00:38,  6.90it/s, running training loss: 1.3834]\u001b[A\n",
      "Training:  85%|████████▌ | 1510/1772 [03:51<00:37,  7.04it/s, running training loss: 1.3834]\u001b[A\n",
      "Training:  85%|████████▌ | 1510/1772 [03:52<00:37,  7.04it/s, running training loss: 0.6692]\u001b[A\n",
      "Training:  85%|████████▌ | 1511/1772 [03:52<00:37,  7.04it/s, running training loss: 0.6692]\u001b[A\n",
      "Training:  85%|████████▌ | 1511/1772 [03:52<00:37,  7.04it/s, running training loss: 1.6108]\u001b[A\n",
      "Training:  85%|████████▌ | 1512/1772 [03:52<00:36,  7.09it/s, running training loss: 1.6108]\u001b[A\n",
      "Training:  85%|████████▌ | 1512/1772 [03:52<00:36,  7.09it/s, running training loss: 1.4373]\u001b[A\n",
      "Training:  85%|████████▌ | 1513/1772 [03:52<00:38,  6.77it/s, running training loss: 1.4373]\u001b[A\n",
      "Training:  85%|████████▌ | 1513/1772 [03:52<00:38,  6.77it/s, running training loss: 1.4204]\u001b[A\n",
      "Training:  85%|████████▌ | 1514/1772 [03:52<00:38,  6.75it/s, running training loss: 1.4204]\u001b[A\n",
      "Training:  85%|████████▌ | 1514/1772 [03:52<00:38,  6.75it/s, running training loss: 1.0304]\u001b[A\n",
      "Training:  85%|████████▌ | 1515/1772 [03:52<00:38,  6.60it/s, running training loss: 1.0304]\u001b[A\n",
      "Training:  85%|████████▌ | 1515/1772 [03:52<00:38,  6.60it/s, running training loss: 1.1015]\u001b[A\n",
      "Training:  86%|████████▌ | 1516/1772 [03:52<00:37,  6.86it/s, running training loss: 1.1015]\u001b[A\n",
      "Training:  86%|████████▌ | 1516/1772 [03:52<00:37,  6.86it/s, running training loss: 1.2849]\u001b[A\n",
      "Training:  86%|████████▌ | 1517/1772 [03:52<00:36,  6.95it/s, running training loss: 1.2849]\u001b[A\n",
      "Training:  86%|████████▌ | 1517/1772 [03:53<00:36,  6.95it/s, running training loss: 0.8502]\u001b[A\n",
      "Training:  86%|████████▌ | 1518/1772 [03:53<00:37,  6.77it/s, running training loss: 0.8502]\u001b[A\n",
      "Training:  86%|████████▌ | 1518/1772 [03:53<00:37,  6.77it/s, running training loss: 0.9105]\u001b[A\n",
      "Training:  86%|████████▌ | 1519/1772 [03:53<00:36,  6.86it/s, running training loss: 0.9105]\u001b[A\n",
      "Training:  86%|████████▌ | 1519/1772 [03:53<00:36,  6.86it/s, running training loss: 0.9616]\u001b[A\n",
      "Training:  86%|████████▌ | 1520/1772 [03:53<00:39,  6.31it/s, running training loss: 0.9616]\u001b[A\n",
      "Training:  86%|████████▌ | 1520/1772 [03:53<00:39,  6.31it/s, running training loss: 0.8849]\u001b[A\n",
      "Training:  86%|████████▌ | 1521/1772 [03:53<00:40,  6.23it/s, running training loss: 0.8849]\u001b[A\n",
      "Training:  86%|████████▌ | 1521/1772 [03:53<00:40,  6.23it/s, running training loss: 0.8667]\u001b[A\n",
      "Training:  86%|████████▌ | 1522/1772 [03:53<00:39,  6.29it/s, running training loss: 0.8667]\u001b[A\n",
      "Training:  86%|████████▌ | 1522/1772 [03:53<00:39,  6.29it/s, running training loss: 0.7717]\u001b[A\n",
      "Training:  86%|████████▌ | 1523/1772 [03:53<00:38,  6.53it/s, running training loss: 0.7717]\u001b[A\n",
      "Training:  86%|████████▌ | 1523/1772 [03:54<00:38,  6.53it/s, running training loss: 0.8339]\u001b[A\n",
      "Training:  86%|████████▌ | 1524/1772 [03:54<00:36,  6.70it/s, running training loss: 0.8339]\u001b[A\n",
      "Training:  86%|████████▌ | 1524/1772 [03:54<00:36,  6.70it/s, running training loss: 0.7596]\u001b[A\n",
      "Training:  86%|████████▌ | 1525/1772 [03:54<00:35,  7.00it/s, running training loss: 0.7596]\u001b[A\n",
      "Training:  86%|████████▌ | 1525/1772 [03:54<00:35,  7.00it/s, running training loss: 0.9491]\u001b[A\n",
      "Training:  86%|████████▌ | 1526/1772 [03:54<00:39,  6.25it/s, running training loss: 0.9491]\u001b[A\n",
      "Training:  86%|████████▌ | 1526/1772 [03:54<00:39,  6.25it/s, running training loss: 0.7909]\u001b[A\n",
      "Training:  86%|████████▌ | 1527/1772 [03:54<00:37,  6.54it/s, running training loss: 0.7909]\u001b[A\n",
      "Training:  86%|████████▌ | 1527/1772 [03:54<00:37,  6.54it/s, running training loss: 0.7230]\u001b[A\n",
      "Training:  86%|████████▌ | 1528/1772 [03:54<00:38,  6.27it/s, running training loss: 0.7230]\u001b[A\n",
      "Training:  86%|████████▌ | 1528/1772 [03:54<00:38,  6.27it/s, running training loss: 0.7740]\u001b[A\n",
      "Training:  86%|████████▋ | 1529/1772 [03:54<00:36,  6.72it/s, running training loss: 0.7740]\u001b[A\n",
      "Training:  86%|████████▋ | 1529/1772 [03:54<00:36,  6.72it/s, running training loss: 1.0446]\u001b[A\n",
      "Training:  86%|████████▋ | 1530/1772 [03:54<00:35,  6.76it/s, running training loss: 1.0446]\u001b[A\n",
      "Training:  86%|████████▋ | 1530/1772 [03:55<00:35,  6.76it/s, running training loss: 0.8872]\u001b[A\n",
      "Training:  86%|████████▋ | 1531/1772 [03:55<00:35,  6.81it/s, running training loss: 0.8872]\u001b[A\n",
      "Training:  86%|████████▋ | 1531/1772 [03:55<00:35,  6.81it/s, running training loss: 1.1483]\u001b[A\n",
      "Training:  86%|████████▋ | 1532/1772 [03:55<00:34,  6.95it/s, running training loss: 1.1483]\u001b[A\n",
      "Training:  86%|████████▋ | 1532/1772 [03:55<00:34,  6.95it/s, running training loss: 1.0188]\u001b[A\n",
      "Training:  87%|████████▋ | 1533/1772 [03:55<00:34,  6.89it/s, running training loss: 1.0188]\u001b[A\n",
      "Training:  87%|████████▋ | 1533/1772 [03:55<00:34,  6.89it/s, running training loss: 0.8915]\u001b[A\n",
      "Training:  87%|████████▋ | 1534/1772 [03:55<00:36,  6.49it/s, running training loss: 0.8915]\u001b[A\n",
      "Training:  87%|████████▋ | 1534/1772 [03:55<00:36,  6.49it/s, running training loss: 1.1162]\u001b[A\n",
      "Training:  87%|████████▋ | 1535/1772 [03:55<00:34,  6.84it/s, running training loss: 1.1162]\u001b[A\n",
      "Training:  87%|████████▋ | 1535/1772 [03:55<00:34,  6.84it/s, running training loss: 1.3159]\u001b[A\n",
      "Training:  87%|████████▋ | 1536/1772 [03:55<00:37,  6.23it/s, running training loss: 1.3159]\u001b[A\n",
      "Training:  87%|████████▋ | 1536/1772 [03:56<00:37,  6.23it/s, running training loss: 1.2055]\u001b[A\n",
      "Training:  87%|████████▋ | 1537/1772 [03:56<00:36,  6.48it/s, running training loss: 1.2055]\u001b[A\n",
      "Training:  87%|████████▋ | 1537/1772 [03:56<00:36,  6.48it/s, running training loss: 0.7446]\u001b[A\n",
      "Training:  87%|████████▋ | 1538/1772 [03:56<00:34,  6.69it/s, running training loss: 0.7446]\u001b[A\n",
      "Training:  87%|████████▋ | 1538/1772 [03:56<00:34,  6.69it/s, running training loss: 0.9969]\u001b[A\n",
      "Training:  87%|████████▋ | 1539/1772 [03:56<00:34,  6.83it/s, running training loss: 0.9969]\u001b[A\n",
      "Training:  87%|████████▋ | 1539/1772 [03:56<00:34,  6.83it/s, running training loss: 0.9634]\u001b[A\n",
      "Training:  87%|████████▋ | 1540/1772 [03:56<00:33,  6.96it/s, running training loss: 0.9634]\u001b[A\n",
      "Training:  87%|████████▋ | 1540/1772 [03:56<00:33,  6.96it/s, running training loss: 0.7691]\u001b[A\n",
      "Training:  87%|████████▋ | 1541/1772 [03:56<00:35,  6.60it/s, running training loss: 0.7691]\u001b[A\n",
      "Training:  87%|████████▋ | 1541/1772 [03:56<00:35,  6.60it/s, running training loss: 1.0193]\u001b[A\n",
      "Training:  87%|████████▋ | 1542/1772 [03:56<00:33,  6.87it/s, running training loss: 1.0193]\u001b[A\n",
      "Training:  87%|████████▋ | 1542/1772 [03:56<00:33,  6.87it/s, running training loss: 0.9712]\u001b[A\n",
      "Training:  87%|████████▋ | 1543/1772 [03:56<00:32,  7.00it/s, running training loss: 0.9712]\u001b[A\n",
      "Training:  87%|████████▋ | 1543/1772 [03:57<00:32,  7.00it/s, running training loss: 0.8428]\u001b[A\n",
      "Training:  87%|████████▋ | 1544/1772 [03:57<00:30,  7.41it/s, running training loss: 0.8428]\u001b[A\n",
      "Training:  87%|████████▋ | 1544/1772 [03:57<00:30,  7.41it/s, running training loss: 1.2942]\u001b[A\n",
      "Training:  87%|████████▋ | 1545/1772 [03:57<00:32,  7.05it/s, running training loss: 1.2942]\u001b[A\n",
      "Training:  87%|████████▋ | 1545/1772 [03:57<00:32,  7.05it/s, running training loss: 1.1139]\u001b[A\n",
      "Training:  87%|████████▋ | 1546/1772 [03:57<00:33,  6.78it/s, running training loss: 1.1139]\u001b[A\n",
      "Training:  87%|████████▋ | 1546/1772 [03:57<00:33,  6.78it/s, running training loss: 0.7678]\u001b[A\n",
      "Training:  87%|████████▋ | 1547/1772 [03:57<00:34,  6.55it/s, running training loss: 0.7678]\u001b[A\n",
      "Training:  87%|████████▋ | 1547/1772 [03:57<00:34,  6.55it/s, running training loss: 0.8178]\u001b[A\n",
      "Training:  87%|████████▋ | 1548/1772 [03:57<00:33,  6.65it/s, running training loss: 0.8178]\u001b[A\n",
      "Training:  87%|████████▋ | 1548/1772 [03:57<00:33,  6.65it/s, running training loss: 0.8351]\u001b[A\n",
      "Training:  87%|████████▋ | 1549/1772 [03:57<00:32,  6.81it/s, running training loss: 0.8351]\u001b[A\n",
      "Training:  87%|████████▋ | 1549/1772 [03:57<00:32,  6.81it/s, running training loss: 0.8069]\u001b[A\n",
      "Training:  87%|████████▋ | 1550/1772 [03:57<00:31,  6.99it/s, running training loss: 0.8069]\u001b[A\n",
      "Training:  87%|████████▋ | 1550/1772 [03:58<00:31,  6.99it/s, running training loss: 0.7589]\u001b[A\n",
      "Training:  88%|████████▊ | 1551/1772 [03:58<00:32,  6.82it/s, running training loss: 0.7589]\u001b[A\n",
      "Training:  88%|████████▊ | 1551/1772 [03:58<00:32,  6.82it/s, running training loss: 1.0007]\u001b[A\n",
      "Training:  88%|████████▊ | 1552/1772 [03:58<00:35,  6.15it/s, running training loss: 1.0007]\u001b[A\n",
      "Training:  88%|████████▊ | 1552/1772 [03:58<00:35,  6.15it/s, running training loss: 0.6694]\u001b[A\n",
      "Training:  88%|████████▊ | 1553/1772 [03:58<00:33,  6.48it/s, running training loss: 0.6694]\u001b[A\n",
      "Training:  88%|████████▊ | 1553/1772 [03:58<00:33,  6.48it/s, running training loss: 0.7526]\u001b[A\n",
      "Training:  88%|████████▊ | 1554/1772 [03:58<00:33,  6.48it/s, running training loss: 0.7526]\u001b[A\n",
      "Training:  88%|████████▊ | 1554/1772 [03:58<00:33,  6.48it/s, running training loss: 1.3328]\u001b[A\n",
      "Training:  88%|████████▊ | 1555/1772 [03:58<00:32,  6.62it/s, running training loss: 1.3328]\u001b[A\n",
      "Training:  88%|████████▊ | 1555/1772 [03:58<00:32,  6.62it/s, running training loss: 1.0350]\u001b[A\n",
      "Training:  88%|████████▊ | 1556/1772 [03:58<00:31,  6.84it/s, running training loss: 1.0350]\u001b[A\n",
      "Training:  88%|████████▊ | 1556/1772 [03:59<00:31,  6.84it/s, running training loss: 1.1327]\u001b[A\n",
      "Training:  88%|████████▊ | 1557/1772 [03:59<00:31,  6.74it/s, running training loss: 1.1327]\u001b[A\n",
      "Training:  88%|████████▊ | 1557/1772 [03:59<00:31,  6.74it/s, running training loss: 0.9838]\u001b[A\n",
      "Training:  88%|████████▊ | 1558/1772 [03:59<00:31,  6.86it/s, running training loss: 0.9838]\u001b[A\n",
      "Training:  88%|████████▊ | 1558/1772 [03:59<00:31,  6.86it/s, running training loss: 1.1812]\u001b[A\n",
      "Training:  88%|████████▊ | 1559/1772 [03:59<00:30,  7.04it/s, running training loss: 1.1812]\u001b[A\n",
      "Training:  88%|████████▊ | 1559/1772 [03:59<00:30,  7.04it/s, running training loss: 0.9273]\u001b[A\n",
      "Training:  88%|████████▊ | 1560/1772 [03:59<00:29,  7.09it/s, running training loss: 0.9273]\u001b[A\n",
      "Training:  88%|████████▊ | 1560/1772 [03:59<00:29,  7.09it/s, running training loss: 0.5768]\u001b[A\n",
      "Training:  88%|████████▊ | 1561/1772 [03:59<00:29,  7.13it/s, running training loss: 0.5768]\u001b[A\n",
      "Training:  88%|████████▊ | 1561/1772 [03:59<00:29,  7.13it/s, running training loss: 0.9437]\u001b[A\n",
      "Training:  88%|████████▊ | 1562/1772 [03:59<00:28,  7.36it/s, running training loss: 0.9437]\u001b[A\n",
      "Training:  88%|████████▊ | 1562/1772 [03:59<00:28,  7.36it/s, running training loss: 0.7360]\u001b[A\n",
      "Training:  88%|████████▊ | 1563/1772 [03:59<00:29,  7.13it/s, running training loss: 0.7360]\u001b[A\n",
      "Training:  88%|████████▊ | 1563/1772 [03:59<00:29,  7.13it/s, running training loss: 0.7763]\u001b[A\n",
      "Training:  88%|████████▊ | 1564/1772 [03:59<00:30,  6.81it/s, running training loss: 0.7763]\u001b[A\n",
      "Training:  88%|████████▊ | 1564/1772 [04:00<00:30,  6.81it/s, running training loss: 0.9640]\u001b[A\n",
      "Training:  88%|████████▊ | 1565/1772 [04:00<00:29,  6.93it/s, running training loss: 0.9640]\u001b[A\n",
      "Training:  88%|████████▊ | 1565/1772 [04:00<00:29,  6.93it/s, running training loss: 1.1181]\u001b[A\n",
      "Training:  88%|████████▊ | 1566/1772 [04:00<00:29,  6.95it/s, running training loss: 1.1181]\u001b[A\n",
      "Training:  88%|████████▊ | 1566/1772 [04:00<00:29,  6.95it/s, running training loss: 1.3286]\u001b[A\n",
      "Training:  88%|████████▊ | 1567/1772 [04:00<00:29,  6.91it/s, running training loss: 1.3286]\u001b[A\n",
      "Training:  88%|████████▊ | 1567/1772 [04:00<00:29,  6.91it/s, running training loss: 0.8991]\u001b[A\n",
      "Training:  88%|████████▊ | 1568/1772 [04:00<00:29,  7.03it/s, running training loss: 0.8991]\u001b[A\n",
      "Training:  88%|████████▊ | 1568/1772 [04:00<00:29,  7.03it/s, running training loss: 1.1876]\u001b[A\n",
      "Training:  89%|████████▊ | 1569/1772 [04:00<00:27,  7.51it/s, running training loss: 1.1876]\u001b[A\n",
      "Training:  89%|████████▊ | 1569/1772 [04:00<00:27,  7.51it/s, running training loss: 0.7767]\u001b[A\n",
      "Training:  89%|████████▊ | 1570/1772 [04:00<00:27,  7.41it/s, running training loss: 0.7767]\u001b[A\n",
      "Training:  89%|████████▊ | 1570/1772 [04:00<00:27,  7.41it/s, running training loss: 0.7050]\u001b[A\n",
      "Training:  89%|████████▊ | 1571/1772 [04:00<00:28,  6.97it/s, running training loss: 0.7050]\u001b[A\n",
      "Training:  89%|████████▊ | 1571/1772 [04:01<00:28,  6.97it/s, running training loss: 1.1344]\u001b[A\n",
      "Training:  89%|████████▊ | 1572/1772 [04:01<00:27,  7.27it/s, running training loss: 1.1344]\u001b[A\n",
      "Training:  89%|████████▊ | 1572/1772 [04:01<00:27,  7.27it/s, running training loss: 1.0452]\u001b[A\n",
      "Training:  89%|████████▉ | 1573/1772 [04:01<00:27,  7.16it/s, running training loss: 1.0452]\u001b[A\n",
      "Training:  89%|████████▉ | 1573/1772 [04:01<00:27,  7.16it/s, running training loss: 0.7142]\u001b[A\n",
      "Training:  89%|████████▉ | 1574/1772 [04:01<00:27,  7.20it/s, running training loss: 0.7142]\u001b[A\n",
      "Training:  89%|████████▉ | 1574/1772 [04:01<00:27,  7.20it/s, running training loss: 0.9161]\u001b[A\n",
      "Training:  89%|████████▉ | 1575/1772 [04:01<00:26,  7.44it/s, running training loss: 0.9161]\u001b[A\n",
      "Training:  89%|████████▉ | 1575/1772 [04:01<00:26,  7.44it/s, running training loss: 1.0529]\u001b[A\n",
      "Training:  89%|████████▉ | 1576/1772 [04:01<00:26,  7.49it/s, running training loss: 1.0529]\u001b[A\n",
      "Training:  89%|████████▉ | 1576/1772 [04:01<00:26,  7.49it/s, running training loss: 1.4146]\u001b[A\n",
      "Training:  89%|████████▉ | 1577/1772 [04:01<00:27,  7.04it/s, running training loss: 1.4146]\u001b[A\n",
      "Training:  89%|████████▉ | 1577/1772 [04:01<00:27,  7.04it/s, running training loss: 0.9731]\u001b[A\n",
      "Training:  89%|████████▉ | 1578/1772 [04:01<00:27,  6.95it/s, running training loss: 0.9731]\u001b[A\n",
      "Training:  89%|████████▉ | 1578/1772 [04:02<00:27,  6.95it/s, running training loss: 0.9323]\u001b[A\n",
      "Training:  89%|████████▉ | 1579/1772 [04:02<00:28,  6.84it/s, running training loss: 0.9323]\u001b[A\n",
      "Training:  89%|████████▉ | 1579/1772 [04:02<00:28,  6.84it/s, running training loss: 0.8773]\u001b[A\n",
      "Training:  89%|████████▉ | 1580/1772 [04:02<00:27,  7.11it/s, running training loss: 0.8773]\u001b[A\n",
      "Training:  89%|████████▉ | 1580/1772 [04:02<00:27,  7.11it/s, running training loss: 0.6948]\u001b[A\n",
      "Training:  89%|████████▉ | 1581/1772 [04:02<00:28,  6.71it/s, running training loss: 0.6948]\u001b[A\n",
      "Training:  89%|████████▉ | 1581/1772 [04:02<00:28,  6.71it/s, running training loss: 1.1326]\u001b[A\n",
      "Training:  89%|████████▉ | 1582/1772 [04:02<00:29,  6.35it/s, running training loss: 1.1326]\u001b[A\n",
      "Training:  89%|████████▉ | 1582/1772 [04:02<00:29,  6.35it/s, running training loss: 1.0446]\u001b[A\n",
      "Training:  89%|████████▉ | 1583/1772 [04:02<00:32,  5.78it/s, running training loss: 1.0446]\u001b[A\n",
      "Training:  89%|████████▉ | 1583/1772 [04:02<00:32,  5.78it/s, running training loss: 0.8017]\u001b[A\n",
      "Training:  89%|████████▉ | 1584/1772 [04:02<00:30,  6.09it/s, running training loss: 0.8017]\u001b[A\n",
      "Training:  89%|████████▉ | 1584/1772 [04:03<00:30,  6.09it/s, running training loss: 1.2363]\u001b[A\n",
      "Training:  89%|████████▉ | 1585/1772 [04:03<00:29,  6.33it/s, running training loss: 1.2363]\u001b[A\n",
      "Training:  89%|████████▉ | 1585/1772 [04:03<00:29,  6.33it/s, running training loss: 1.0694]\u001b[A\n",
      "Training:  90%|████████▉ | 1586/1772 [04:03<00:28,  6.61it/s, running training loss: 1.0694]\u001b[A\n",
      "Training:  90%|████████▉ | 1586/1772 [04:03<00:28,  6.61it/s, running training loss: 0.9733]\u001b[A\n",
      "Training:  90%|████████▉ | 1587/1772 [04:03<00:27,  6.74it/s, running training loss: 0.9733]\u001b[A\n",
      "Training:  90%|████████▉ | 1587/1772 [04:03<00:27,  6.74it/s, running training loss: 0.8709]\u001b[A\n",
      "Training:  90%|████████▉ | 1588/1772 [04:03<00:26,  6.86it/s, running training loss: 0.8709]\u001b[A\n",
      "Training:  90%|████████▉ | 1588/1772 [04:03<00:26,  6.86it/s, running training loss: 0.8658]\u001b[A\n",
      "Training:  90%|████████▉ | 1589/1772 [04:03<00:26,  6.93it/s, running training loss: 0.8658]\u001b[A\n",
      "Training:  90%|████████▉ | 1589/1772 [04:03<00:26,  6.93it/s, running training loss: 1.1294]\u001b[A\n",
      "Training:  90%|████████▉ | 1590/1772 [04:03<00:26,  6.98it/s, running training loss: 1.1294]\u001b[A\n",
      "Training:  90%|████████▉ | 1590/1772 [04:03<00:26,  6.98it/s, running training loss: 0.7732]\u001b[A\n",
      "Training:  90%|████████▉ | 1591/1772 [04:03<00:26,  6.84it/s, running training loss: 0.7732]\u001b[A\n",
      "Training:  90%|████████▉ | 1591/1772 [04:04<00:26,  6.84it/s, running training loss: 0.8601]\u001b[A\n",
      "Training:  90%|████████▉ | 1592/1772 [04:04<00:25,  6.97it/s, running training loss: 0.8601]\u001b[A\n",
      "Training:  90%|████████▉ | 1592/1772 [04:04<00:25,  6.97it/s, running training loss: 1.2962]\u001b[A\n",
      "Training:  90%|████████▉ | 1593/1772 [04:04<00:27,  6.42it/s, running training loss: 1.2962]\u001b[A\n",
      "Training:  90%|████████▉ | 1593/1772 [04:04<00:27,  6.42it/s, running training loss: 0.5799]\u001b[A\n",
      "Training:  90%|████████▉ | 1594/1772 [04:04<00:27,  6.55it/s, running training loss: 0.5799]\u001b[A\n",
      "Training:  90%|████████▉ | 1594/1772 [04:04<00:27,  6.55it/s, running training loss: 0.6814]\u001b[A\n",
      "Training:  90%|█████████ | 1595/1772 [04:04<00:26,  6.72it/s, running training loss: 0.6814]\u001b[A\n",
      "Training:  90%|█████████ | 1595/1772 [04:04<00:26,  6.72it/s, running training loss: 0.7786]\u001b[A\n",
      "Training:  90%|█████████ | 1596/1772 [04:04<00:29,  5.94it/s, running training loss: 0.7786]\u001b[A\n",
      "Training:  90%|█████████ | 1596/1772 [04:04<00:29,  5.94it/s, running training loss: 0.6719]\u001b[A\n",
      "Training:  90%|█████████ | 1597/1772 [04:04<00:31,  5.50it/s, running training loss: 0.6719]\u001b[A\n",
      "Training:  90%|█████████ | 1597/1772 [04:05<00:31,  5.50it/s, running training loss: 1.1175]\u001b[A\n",
      "Training:  90%|█████████ | 1598/1772 [04:05<00:30,  5.62it/s, running training loss: 1.1175]\u001b[A\n",
      "Training:  90%|█████████ | 1598/1772 [04:05<00:30,  5.62it/s, running training loss: 1.0910]\u001b[A\n",
      "Training:  90%|█████████ | 1599/1772 [04:05<00:28,  6.03it/s, running training loss: 1.0910]\u001b[A\n",
      "Training:  90%|█████████ | 1599/1772 [04:05<00:28,  6.03it/s, running training loss: 1.4274]\u001b[A\n",
      "\n",
      "Evaluation:   0%|          | 0/270 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   0%|          | 1/270 [00:00<02:39,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   2%|▏         | 6/270 [00:00<01:51,  2.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   5%|▍         | 13/270 [00:00<01:17,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   7%|▋         | 19/270 [00:00<00:54,  4.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:   9%|▉         | 25/270 [00:01<00:38,  6.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  11%|█▏        | 31/270 [00:01<00:27,  8.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  14%|█▎        | 37/270 [00:01<00:19, 11.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  16%|█▌        | 43/270 [00:01<00:14, 15.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  18%|█▊        | 49/270 [00:01<00:11, 19.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  20%|██        | 55/270 [00:01<00:08, 24.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  23%|██▎       | 61/270 [00:01<00:07, 29.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  25%|██▍       | 67/270 [00:01<00:05, 34.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  27%|██▋       | 74/270 [00:01<00:04, 39.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  30%|██▉       | 80/270 [00:01<00:04, 44.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  32%|███▏      | 86/270 [00:02<00:03, 47.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  34%|███▍      | 92/270 [00:02<00:03, 49.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  37%|███▋      | 99/270 [00:02<00:03, 52.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  39%|███▉      | 105/270 [00:02<00:03, 53.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  41%|████      | 111/270 [00:02<00:02, 55.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  43%|████▎     | 117/270 [00:02<00:02, 55.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  46%|████▌     | 124/270 [00:02<00:02, 57.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  48%|████▊     | 130/270 [00:02<00:02, 55.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  50%|█████     | 136/270 [00:02<00:02, 55.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  53%|█████▎    | 142/270 [00:03<00:02, 55.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  55%|█████▍    | 148/270 [00:03<00:02, 56.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  57%|█████▋    | 154/270 [00:03<00:02, 55.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  59%|█████▉    | 160/270 [00:03<00:01, 56.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  61%|██████▏   | 166/270 [00:03<00:01, 56.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  64%|██████▎   | 172/270 [00:03<00:01, 57.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  66%|██████▌   | 178/270 [00:03<00:01, 55.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  68%|██████▊   | 184/270 [00:03<00:01, 54.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  70%|███████   | 190/270 [00:03<00:01, 55.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  73%|███████▎  | 196/270 [00:04<00:01, 54.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  75%|███████▍  | 202/270 [00:04<00:01, 54.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  77%|███████▋  | 208/270 [00:04<00:01, 55.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  79%|███████▉  | 214/270 [00:04<00:01, 55.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  82%|████████▏ | 221/270 [00:04<00:00, 57.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  84%|████████▍ | 228/270 [00:04<00:00, 57.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  87%|████████▋ | 234/270 [00:04<00:00, 57.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  89%|████████▉ | 240/270 [00:04<00:00, 57.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  91%|█████████ | 246/270 [00:04<00:00, 56.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  93%|█████████▎| 252/270 [00:05<00:00, 54.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  96%|█████████▌| 258/270 [00:05<00:00, 54.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation:  98%|█████████▊| 264/270 [00:05<00:00, 54.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluation: 100%|██████████| 270/270 [00:05<00:00, 48.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Training:  90%|█████████ | 1600/1772 [04:11<05:39,  1.98s/it, running training loss: 1.4274]\u001b[A\n",
      "Training:  90%|█████████ | 1600/1772 [04:11<05:39,  1.98s/it, running training loss: 1.2817]\u001b[A\n",
      "Training:  90%|█████████ | 1601/1772 [04:11<04:06,  1.44s/it, running training loss: 1.2817]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> training loss: 0.999916, valid loss: 0.589353, valid f1: 0.236436, valid acc: 0.690222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:  90%|█████████ | 1601/1772 [04:11<04:06,  1.44s/it, running training loss: 0.6819]\u001b[A\n",
      "Training:  90%|█████████ | 1602/1772 [04:11<03:00,  1.06s/it, running training loss: 0.6819]\u001b[A\n",
      "Training:  90%|█████████ | 1602/1772 [04:11<03:00,  1.06s/it, running training loss: 1.2535]\u001b[A\n",
      "Training:  90%|█████████ | 1603/1772 [04:11<02:13,  1.27it/s, running training loss: 1.2535]\u001b[A\n",
      "Training:  90%|█████████ | 1603/1772 [04:12<02:13,  1.27it/s, running training loss: 0.9168]\u001b[A\n",
      "Training:  91%|█████████ | 1604/1772 [04:12<01:40,  1.68it/s, running training loss: 0.9168]\u001b[A\n",
      "Training:  91%|█████████ | 1604/1772 [04:12<01:40,  1.68it/s, running training loss: 0.9584]\u001b[A\n",
      "Training:  91%|█████████ | 1605/1772 [04:12<01:17,  2.15it/s, running training loss: 0.9584]\u001b[A\n",
      "Training:  91%|█████████ | 1605/1772 [04:12<01:17,  2.15it/s, running training loss: 0.8801]\u001b[A\n",
      "Training:  91%|█████████ | 1606/1772 [04:12<01:01,  2.71it/s, running training loss: 0.8801]\u001b[A\n",
      "Training:  91%|█████████ | 1606/1772 [04:12<01:01,  2.71it/s, running training loss: 1.0030]\u001b[A\n",
      "Training:  91%|█████████ | 1607/1772 [04:12<00:49,  3.30it/s, running training loss: 1.0030]\u001b[A\n",
      "Training:  91%|█████████ | 1607/1772 [04:12<00:49,  3.30it/s, running training loss: 1.3346]\u001b[A\n",
      "Training:  91%|█████████ | 1608/1772 [04:12<00:44,  3.66it/s, running training loss: 1.3346]\u001b[A\n",
      "Training:  91%|█████████ | 1608/1772 [04:12<00:44,  3.66it/s, running training loss: 0.9586]\u001b[A\n",
      "Training:  91%|█████████ | 1609/1772 [04:12<00:38,  4.25it/s, running training loss: 0.9586]\u001b[A\n",
      "Training:  91%|█████████ | 1609/1772 [04:13<00:38,  4.25it/s, running training loss: 0.9669]\u001b[A\n",
      "Training:  91%|█████████ | 1610/1772 [04:13<00:33,  4.86it/s, running training loss: 0.9669]\u001b[A\n",
      "Training:  91%|█████████ | 1610/1772 [04:13<00:33,  4.86it/s, running training loss: 0.8259]\u001b[A\n",
      "Training:  91%|█████████ | 1611/1772 [04:13<00:29,  5.41it/s, running training loss: 0.8259]\u001b[A\n",
      "Training:  91%|█████████ | 1611/1772 [04:13<00:29,  5.41it/s, running training loss: 1.0185]\u001b[A\n",
      "Training:  91%|█████████ | 1612/1772 [04:13<00:27,  5.84it/s, running training loss: 1.0185]\u001b[A\n",
      "Training:  91%|█████████ | 1612/1772 [04:13<00:27,  5.84it/s, running training loss: 0.8452]\u001b[A\n",
      "Training:  91%|█████████ | 1613/1772 [04:13<00:25,  6.30it/s, running training loss: 0.8452]\u001b[A\n",
      "Training:  91%|█████████ | 1613/1772 [04:13<00:25,  6.30it/s, running training loss: 0.9554]\u001b[A\n",
      "Training:  91%|█████████ | 1614/1772 [04:13<00:25,  6.28it/s, running training loss: 0.9554]\u001b[A\n",
      "Training:  91%|█████████ | 1614/1772 [04:13<00:25,  6.28it/s, running training loss: 0.8473]\u001b[A\n",
      "Training:  91%|█████████ | 1615/1772 [04:13<00:24,  6.42it/s, running training loss: 0.8473]\u001b[A\n",
      "Training:  91%|█████████ | 1615/1772 [04:13<00:24,  6.42it/s, running training loss: 0.9267]\u001b[A\n",
      "Training:  91%|█████████ | 1616/1772 [04:13<00:24,  6.48it/s, running training loss: 0.9267]\u001b[A\n",
      "Training:  91%|█████████ | 1616/1772 [04:14<00:24,  6.48it/s, running training loss: 0.5285]\u001b[A\n",
      "Training:  91%|█████████▏| 1617/1772 [04:14<00:23,  6.70it/s, running training loss: 0.5285]\u001b[A\n",
      "Training:  91%|█████████▏| 1617/1772 [04:14<00:23,  6.70it/s, running training loss: 0.8528]\u001b[A\n",
      "Training:  91%|█████████▏| 1618/1772 [04:14<00:22,  6.87it/s, running training loss: 0.8528]\u001b[A\n",
      "Training:  91%|█████████▏| 1618/1772 [04:14<00:22,  6.87it/s, running training loss: 0.9150]\u001b[A\n",
      "Training:  91%|█████████▏| 1619/1772 [04:14<00:21,  6.99it/s, running training loss: 0.9150]\u001b[A\n",
      "Training:  91%|█████████▏| 1619/1772 [04:14<00:21,  6.99it/s, running training loss: 0.6201]\u001b[A\n",
      "Training:  91%|█████████▏| 1620/1772 [04:14<00:21,  7.02it/s, running training loss: 0.6201]\u001b[A\n",
      "Training:  91%|█████████▏| 1620/1772 [04:14<00:21,  7.02it/s, running training loss: 1.0360]\u001b[A\n",
      "Training:  91%|█████████▏| 1621/1772 [04:14<00:23,  6.38it/s, running training loss: 1.0360]\u001b[A\n",
      "Training:  91%|█████████▏| 1621/1772 [04:14<00:23,  6.38it/s, running training loss: 0.7049]\u001b[A\n",
      "Training:  92%|█████████▏| 1622/1772 [04:14<00:22,  6.69it/s, running training loss: 0.7049]\u001b[A\n",
      "Training:  92%|█████████▏| 1622/1772 [04:14<00:22,  6.69it/s, running training loss: 0.5923]\u001b[A\n",
      "Training:  92%|█████████▏| 1623/1772 [04:14<00:21,  6.92it/s, running training loss: 0.5923]\u001b[A\n",
      "Training:  92%|█████████▏| 1623/1772 [04:15<00:21,  6.92it/s, running training loss: 0.7614]\u001b[A\n",
      "Training:  92%|█████████▏| 1624/1772 [04:15<00:21,  6.99it/s, running training loss: 0.7614]\u001b[A\n",
      "Training:  92%|█████████▏| 1624/1772 [04:15<00:21,  6.99it/s, running training loss: 0.7745]\u001b[A\n",
      "Training:  92%|█████████▏| 1625/1772 [04:15<00:20,  7.10it/s, running training loss: 0.7745]\u001b[A\n",
      "Training:  92%|█████████▏| 1625/1772 [04:15<00:20,  7.10it/s, running training loss: 0.4697]\u001b[A\n",
      "Training:  92%|█████████▏| 1626/1772 [04:15<00:20,  7.14it/s, running training loss: 0.4697]\u001b[A\n",
      "Training:  92%|█████████▏| 1626/1772 [04:15<00:20,  7.14it/s, running training loss: 0.9380]\u001b[A\n",
      "Training:  92%|█████████▏| 1627/1772 [04:15<00:19,  7.30it/s, running training loss: 0.9380]\u001b[A\n",
      "Training:  92%|█████████▏| 1627/1772 [04:15<00:19,  7.30it/s, running training loss: 0.8569]\u001b[A\n",
      "Training:  92%|█████████▏| 1628/1772 [04:15<00:19,  7.39it/s, running training loss: 0.8569]\u001b[A\n",
      "Training:  92%|█████████▏| 1628/1772 [04:15<00:19,  7.39it/s, running training loss: 1.0345]\u001b[A\n",
      "Training:  92%|█████████▏| 1629/1772 [04:15<00:20,  6.95it/s, running training loss: 1.0345]\u001b[A\n",
      "Training:  92%|█████████▏| 1629/1772 [04:15<00:20,  6.95it/s, running training loss: 1.7280]\u001b[A\n",
      "Training:  92%|█████████▏| 1630/1772 [04:15<00:20,  7.00it/s, running training loss: 1.7280]\u001b[A\n",
      "Training:  92%|█████████▏| 1630/1772 [04:16<00:20,  7.00it/s, running training loss: 1.2926]\u001b[A\n",
      "Training:  92%|█████████▏| 1631/1772 [04:16<00:22,  6.23it/s, running training loss: 1.2926]\u001b[A\n",
      "Training:  92%|█████████▏| 1631/1772 [04:16<00:22,  6.23it/s, running training loss: 1.0446]\u001b[A\n",
      "Training:  92%|█████████▏| 1632/1772 [04:16<00:22,  6.16it/s, running training loss: 1.0446]\u001b[A\n",
      "Training:  92%|█████████▏| 1632/1772 [04:16<00:22,  6.16it/s, running training loss: 1.3161]\u001b[A\n",
      "Training:  92%|█████████▏| 1633/1772 [04:16<00:21,  6.45it/s, running training loss: 1.3161]\u001b[A\n",
      "Training:  92%|█████████▏| 1633/1772 [04:16<00:21,  6.45it/s, running training loss: 1.1420]\u001b[A\n",
      "Training:  92%|█████████▏| 1634/1772 [04:16<00:20,  6.68it/s, running training loss: 1.1420]\u001b[A\n",
      "Training:  92%|█████████▏| 1634/1772 [04:16<00:20,  6.68it/s, running training loss: 1.2129]\u001b[A\n",
      "Training:  92%|█████████▏| 1635/1772 [04:16<00:20,  6.77it/s, running training loss: 1.2129]\u001b[A\n",
      "Training:  92%|█████████▏| 1635/1772 [04:16<00:20,  6.77it/s, running training loss: 1.1084]\u001b[A\n",
      "Training:  92%|█████████▏| 1636/1772 [04:16<00:20,  6.65it/s, running training loss: 1.1084]\u001b[A\n",
      "Training:  92%|█████████▏| 1636/1772 [04:16<00:20,  6.65it/s, running training loss: 0.9666]\u001b[A\n",
      "Training:  92%|█████████▏| 1637/1772 [04:16<00:19,  7.01it/s, running training loss: 0.9666]\u001b[A\n",
      "Training:  92%|█████████▏| 1637/1772 [04:17<00:19,  7.01it/s, running training loss: 0.6164]\u001b[A\n",
      "Training:  92%|█████████▏| 1638/1772 [04:17<00:19,  7.03it/s, running training loss: 0.6164]\u001b[A\n",
      "Training:  92%|█████████▏| 1638/1772 [04:17<00:19,  7.03it/s, running training loss: 0.4705]\u001b[A\n",
      "Training:  92%|█████████▏| 1639/1772 [04:17<00:18,  7.12it/s, running training loss: 0.4705]\u001b[A\n",
      "Training:  92%|█████████▏| 1639/1772 [04:17<00:18,  7.12it/s, running training loss: 1.1142]\u001b[A\n",
      "Training:  93%|█████████▎| 1640/1772 [04:17<00:18,  7.31it/s, running training loss: 1.1142]\u001b[A\n",
      "Training:  93%|█████████▎| 1640/1772 [04:17<00:18,  7.31it/s, running training loss: 1.0437]\u001b[A\n",
      "Training:  93%|█████████▎| 1641/1772 [04:17<00:19,  6.77it/s, running training loss: 1.0437]\u001b[A\n",
      "Training:  93%|█████████▎| 1641/1772 [04:17<00:19,  6.77it/s, running training loss: 0.6195]\u001b[A\n",
      "Training:  93%|█████████▎| 1642/1772 [04:17<00:18,  6.91it/s, running training loss: 0.6195]\u001b[A\n",
      "Training:  93%|█████████▎| 1642/1772 [04:17<00:18,  6.91it/s, running training loss: 0.8877]\u001b[A\n",
      "Training:  93%|█████████▎| 1643/1772 [04:17<00:18,  7.01it/s, running training loss: 0.8877]\u001b[A\n",
      "Training:  93%|█████████▎| 1643/1772 [04:17<00:18,  7.01it/s, running training loss: 0.6584]\u001b[A\n",
      "Training:  93%|█████████▎| 1644/1772 [04:17<00:18,  6.77it/s, running training loss: 0.6584]\u001b[A\n",
      "Training:  93%|█████████▎| 1644/1772 [04:18<00:18,  6.77it/s, running training loss: 0.8939]\u001b[A\n",
      "Training:  93%|█████████▎| 1645/1772 [04:18<00:18,  6.80it/s, running training loss: 0.8939]\u001b[A\n",
      "Training:  93%|█████████▎| 1645/1772 [04:18<00:18,  6.80it/s, running training loss: 0.6992]\u001b[A\n",
      "Training:  93%|█████████▎| 1646/1772 [04:18<00:18,  6.85it/s, running training loss: 0.6992]\u001b[A\n",
      "Training:  93%|█████████▎| 1646/1772 [04:18<00:18,  6.85it/s, running training loss: 0.7433]\u001b[A\n",
      "Training:  93%|█████████▎| 1647/1772 [04:18<00:18,  6.72it/s, running training loss: 0.7433]\u001b[A\n",
      "Training:  93%|█████████▎| 1647/1772 [04:18<00:18,  6.72it/s, running training loss: 0.8676]\u001b[A\n",
      "Training:  93%|█████████▎| 1648/1772 [04:18<00:19,  6.50it/s, running training loss: 0.8676]\u001b[A\n",
      "Training:  93%|█████████▎| 1648/1772 [04:18<00:19,  6.50it/s, running training loss: 0.8406]\u001b[A\n",
      "Training:  93%|█████████▎| 1649/1772 [04:18<00:18,  6.75it/s, running training loss: 0.8406]\u001b[A\n",
      "Training:  93%|█████████▎| 1649/1772 [04:18<00:18,  6.75it/s, running training loss: 0.5805]\u001b[A\n",
      "Training:  93%|█████████▎| 1650/1772 [04:18<00:18,  6.58it/s, running training loss: 0.5805]\u001b[A\n",
      "Training:  93%|█████████▎| 1650/1772 [04:19<00:18,  6.58it/s, running training loss: 0.7562]\u001b[A\n",
      "Training:  93%|█████████▎| 1651/1772 [04:19<00:17,  6.95it/s, running training loss: 0.7562]\u001b[A\n",
      "Training:  93%|█████████▎| 1651/1772 [04:19<00:17,  6.95it/s, running training loss: 0.6090]\u001b[A\n",
      "Training:  93%|█████████▎| 1652/1772 [04:19<00:19,  6.24it/s, running training loss: 0.6090]\u001b[A\n",
      "Training:  93%|█████████▎| 1652/1772 [04:19<00:19,  6.24it/s, running training loss: 1.1466]\u001b[A\n",
      "Training:  93%|█████████▎| 1653/1772 [04:19<00:17,  6.62it/s, running training loss: 1.1466]\u001b[A\n",
      "Training:  93%|█████████▎| 1653/1772 [04:19<00:17,  6.62it/s, running training loss: 1.1946]\u001b[A\n",
      "Training:  93%|█████████▎| 1654/1772 [04:19<00:16,  6.95it/s, running training loss: 1.1946]\u001b[A\n",
      "Training:  93%|█████████▎| 1654/1772 [04:19<00:16,  6.95it/s, running training loss: 1.3668]\u001b[A\n",
      "Training:  93%|█████████▎| 1655/1772 [04:19<00:16,  6.93it/s, running training loss: 1.3668]\u001b[A\n",
      "Training:  93%|█████████▎| 1655/1772 [04:19<00:16,  6.93it/s, running training loss: 0.8634]\u001b[A\n",
      "Training:  93%|█████████▎| 1656/1772 [04:19<00:16,  7.04it/s, running training loss: 0.8634]\u001b[A\n",
      "Training:  93%|█████████▎| 1656/1772 [04:19<00:16,  7.04it/s, running training loss: 1.0737]\u001b[A\n",
      "Training:  94%|█████████▎| 1657/1772 [04:19<00:16,  7.13it/s, running training loss: 1.0737]\u001b[A\n",
      "Training:  94%|█████████▎| 1657/1772 [04:20<00:16,  7.13it/s, running training loss: 0.6553]\u001b[A\n",
      "Training:  94%|█████████▎| 1658/1772 [04:20<00:15,  7.20it/s, running training loss: 0.6553]\u001b[A\n",
      "Training:  94%|█████████▎| 1658/1772 [04:20<00:15,  7.20it/s, running training loss: 0.7320]\u001b[A\n",
      "Training:  94%|█████████▎| 1659/1772 [04:20<00:15,  7.23it/s, running training loss: 0.7320]\u001b[A\n",
      "Training:  94%|█████████▎| 1659/1772 [04:20<00:15,  7.23it/s, running training loss: 1.1663]\u001b[A\n",
      "Training:  94%|█████████▎| 1660/1772 [04:20<00:15,  7.08it/s, running training loss: 1.1663]\u001b[A\n",
      "Training:  94%|█████████▎| 1660/1772 [04:20<00:15,  7.08it/s, running training loss: 1.1757]\u001b[A\n",
      "Training:  94%|█████████▎| 1661/1772 [04:20<00:15,  7.33it/s, running training loss: 1.1757]\u001b[A\n",
      "Training:  94%|█████████▎| 1661/1772 [04:20<00:15,  7.33it/s, running training loss: 1.2875]\u001b[A\n",
      "Training:  94%|█████████▍| 1662/1772 [04:20<00:15,  7.01it/s, running training loss: 1.2875]\u001b[A\n",
      "Training:  94%|█████████▍| 1662/1772 [04:20<00:15,  7.01it/s, running training loss: 0.6764]\u001b[A\n",
      "Training:  94%|█████████▍| 1663/1772 [04:20<00:16,  6.79it/s, running training loss: 0.6764]\u001b[A\n",
      "Training:  94%|█████████▍| 1663/1772 [04:20<00:16,  6.79it/s, running training loss: 0.6445]\u001b[A\n",
      "Training:  94%|█████████▍| 1664/1772 [04:20<00:15,  7.02it/s, running training loss: 0.6445]\u001b[A\n",
      "Training:  94%|█████████▍| 1664/1772 [04:21<00:15,  7.02it/s, running training loss: 0.6668]\u001b[A\n",
      "Training:  94%|█████████▍| 1665/1772 [04:21<00:14,  7.29it/s, running training loss: 0.6668]\u001b[A\n",
      "Training:  94%|█████████▍| 1665/1772 [04:21<00:14,  7.29it/s, running training loss: 0.7840]\u001b[A\n",
      "Training:  94%|█████████▍| 1666/1772 [04:21<00:15,  7.06it/s, running training loss: 0.7840]\u001b[A\n",
      "Training:  94%|█████████▍| 1666/1772 [04:21<00:15,  7.06it/s, running training loss: 0.8902]\u001b[A\n",
      "Training:  94%|█████████▍| 1667/1772 [04:21<00:17,  6.14it/s, running training loss: 0.8902]\u001b[A\n",
      "Training:  94%|█████████▍| 1667/1772 [04:21<00:17,  6.14it/s, running training loss: 0.5150]\u001b[A\n",
      "Training:  94%|█████████▍| 1668/1772 [04:21<00:15,  6.51it/s, running training loss: 0.5150]\u001b[A\n",
      "Training:  94%|█████████▍| 1668/1772 [04:21<00:15,  6.51it/s, running training loss: 1.1236]\u001b[A\n",
      "Training:  94%|█████████▍| 1669/1772 [04:21<00:15,  6.62it/s, running training loss: 1.1236]\u001b[A\n",
      "Training:  94%|█████████▍| 1669/1772 [04:21<00:15,  6.62it/s, running training loss: 1.1383]\u001b[A\n",
      "Training:  94%|█████████▍| 1670/1772 [04:21<00:15,  6.52it/s, running training loss: 1.1383]\u001b[A\n",
      "Training:  94%|█████████▍| 1670/1772 [04:21<00:15,  6.52it/s, running training loss: 1.4365]\u001b[A\n",
      "Training:  94%|█████████▍| 1671/1772 [04:21<00:16,  6.25it/s, running training loss: 1.4365]\u001b[A\n",
      "Training:  94%|█████████▍| 1671/1772 [04:22<00:16,  6.25it/s, running training loss: 0.8239]\u001b[A\n",
      "Training:  94%|█████████▍| 1672/1772 [04:22<00:16,  6.13it/s, running training loss: 0.8239]\u001b[A\n",
      "Training:  94%|█████████▍| 1672/1772 [04:22<00:16,  6.13it/s, running training loss: 0.7716]\u001b[A\n",
      "Training:  94%|█████████▍| 1673/1772 [04:22<00:15,  6.30it/s, running training loss: 0.7716]\u001b[A\n",
      "Training:  94%|█████████▍| 1673/1772 [04:22<00:15,  6.30it/s, running training loss: 0.8729]\u001b[A\n",
      "Training:  94%|█████████▍| 1674/1772 [04:22<00:14,  6.73it/s, running training loss: 0.8729]\u001b[A\n",
      "Training:  94%|█████████▍| 1674/1772 [04:22<00:14,  6.73it/s, running training loss: 0.8913]\u001b[A\n",
      "Training:  95%|█████████▍| 1675/1772 [04:22<00:13,  6.97it/s, running training loss: 0.8913]\u001b[A\n",
      "Training:  95%|█████████▍| 1675/1772 [04:22<00:13,  6.97it/s, running training loss: 0.7392]\u001b[A\n",
      "Training:  95%|█████████▍| 1676/1772 [04:22<00:13,  7.25it/s, running training loss: 0.7392]\u001b[A\n",
      "Training:  95%|█████████▍| 1676/1772 [04:22<00:13,  7.25it/s, running training loss: 1.0069]\u001b[A\n",
      "Training:  95%|█████████▍| 1677/1772 [04:22<00:13,  6.98it/s, running training loss: 1.0069]\u001b[A\n",
      "Training:  95%|█████████▍| 1677/1772 [04:22<00:13,  6.98it/s, running training loss: 1.1225]\u001b[A\n",
      "Training:  95%|█████████▍| 1678/1772 [04:22<00:13,  7.19it/s, running training loss: 1.1225]\u001b[A\n",
      "Training:  95%|█████████▍| 1678/1772 [04:23<00:13,  7.19it/s, running training loss: 0.6386]\u001b[A\n",
      "Training:  95%|█████████▍| 1679/1772 [04:23<00:13,  6.90it/s, running training loss: 0.6386]\u001b[A\n",
      "Training:  95%|█████████▍| 1679/1772 [04:23<00:13,  6.90it/s, running training loss: 0.5461]\u001b[A\n",
      "Training:  95%|█████████▍| 1680/1772 [04:23<00:13,  6.57it/s, running training loss: 0.5461]\u001b[A\n",
      "Training:  95%|█████████▍| 1680/1772 [04:23<00:13,  6.57it/s, running training loss: 0.5786]\u001b[A\n",
      "Training:  95%|█████████▍| 1681/1772 [04:23<00:14,  6.47it/s, running training loss: 0.5786]\u001b[A\n",
      "Training:  95%|█████████▍| 1681/1772 [04:23<00:14,  6.47it/s, running training loss: 0.8354]\u001b[A\n",
      "Training:  95%|█████████▍| 1682/1772 [04:23<00:13,  6.76it/s, running training loss: 0.8354]\u001b[A\n",
      "Training:  95%|█████████▍| 1682/1772 [04:23<00:13,  6.76it/s, running training loss: 0.7630]\u001b[A\n",
      "Training:  95%|█████████▍| 1683/1772 [04:23<00:12,  6.91it/s, running training loss: 0.7630]\u001b[A\n",
      "Training:  95%|█████████▍| 1683/1772 [04:23<00:12,  6.91it/s, running training loss: 0.9762]\u001b[A\n",
      "Training:  95%|█████████▌| 1684/1772 [04:23<00:12,  7.10it/s, running training loss: 0.9762]\u001b[A\n",
      "Training:  95%|█████████▌| 1684/1772 [04:24<00:12,  7.10it/s, running training loss: 1.2181]\u001b[A\n",
      "Training:  95%|█████████▌| 1685/1772 [04:24<00:12,  7.20it/s, running training loss: 1.2181]\u001b[A\n",
      "Training:  95%|█████████▌| 1685/1772 [04:24<00:12,  7.20it/s, running training loss: 0.8701]\u001b[A\n",
      "Training:  95%|█████████▌| 1686/1772 [04:24<00:11,  7.28it/s, running training loss: 0.8701]\u001b[A\n",
      "Training:  95%|█████████▌| 1686/1772 [04:24<00:11,  7.28it/s, running training loss: 0.9650]\u001b[A\n",
      "Training:  95%|█████████▌| 1687/1772 [04:24<00:12,  6.97it/s, running training loss: 0.9650]\u001b[A\n",
      "Training:  95%|█████████▌| 1687/1772 [04:24<00:12,  6.97it/s, running training loss: 0.9293]\u001b[A\n",
      "Training:  95%|█████████▌| 1688/1772 [04:24<00:12,  6.93it/s, running training loss: 0.9293]\u001b[A\n",
      "Training:  95%|█████████▌| 1688/1772 [04:24<00:12,  6.93it/s, running training loss: 0.8476]\u001b[A\n",
      "Training:  95%|█████████▌| 1689/1772 [04:24<00:11,  7.19it/s, running training loss: 0.8476]\u001b[A\n",
      "Training:  95%|█████████▌| 1689/1772 [04:24<00:11,  7.19it/s, running training loss: 0.5796]\u001b[A\n",
      "Training:  95%|█████████▌| 1690/1772 [04:24<00:11,  7.38it/s, running training loss: 0.5796]\u001b[A\n",
      "Training:  95%|█████████▌| 1690/1772 [04:24<00:11,  7.38it/s, running training loss: 0.8951]\u001b[A\n",
      "Training:  95%|█████████▌| 1691/1772 [04:24<00:11,  7.06it/s, running training loss: 0.8951]\u001b[A\n",
      "Training:  95%|█████████▌| 1691/1772 [04:24<00:11,  7.06it/s, running training loss: 1.0276]\u001b[A\n",
      "Training:  95%|█████████▌| 1692/1772 [04:24<00:10,  7.31it/s, running training loss: 1.0276]\u001b[A\n",
      "Training:  95%|█████████▌| 1692/1772 [04:25<00:10,  7.31it/s, running training loss: 0.5464]\u001b[A\n",
      "Training:  96%|█████████▌| 1693/1772 [04:25<00:11,  6.77it/s, running training loss: 0.5464]\u001b[A\n",
      "Training:  96%|█████████▌| 1693/1772 [04:25<00:11,  6.77it/s, running training loss: 0.9164]\u001b[A\n",
      "Training:  96%|█████████▌| 1694/1772 [04:25<00:12,  6.42it/s, running training loss: 0.9164]\u001b[A\n",
      "Training:  96%|█████████▌| 1694/1772 [04:25<00:12,  6.42it/s, running training loss: 0.9647]\u001b[A\n",
      "Training:  96%|█████████▌| 1695/1772 [04:25<00:11,  6.60it/s, running training loss: 0.9647]\u001b[A\n",
      "Training:  96%|█████████▌| 1695/1772 [04:25<00:11,  6.60it/s, running training loss: 0.6919]\u001b[A\n",
      "Training:  96%|█████████▌| 1696/1772 [04:25<00:10,  6.97it/s, running training loss: 0.6919]\u001b[A\n",
      "Training:  96%|█████████▌| 1696/1772 [04:25<00:10,  6.97it/s, running training loss: 0.9044]\u001b[A\n",
      "Training:  96%|█████████▌| 1697/1772 [04:25<00:10,  6.83it/s, running training loss: 0.9044]\u001b[A\n",
      "Training:  96%|█████████▌| 1697/1772 [04:25<00:10,  6.83it/s, running training loss: 0.9007]\u001b[A\n",
      "Training:  96%|█████████▌| 1698/1772 [04:25<00:10,  6.79it/s, running training loss: 0.9007]\u001b[A\n",
      "Training:  96%|█████████▌| 1698/1772 [04:26<00:10,  6.79it/s, running training loss: 0.8252]\u001b[A\n",
      "Training:  96%|█████████▌| 1699/1772 [04:26<00:10,  6.94it/s, running training loss: 0.8252]\u001b[A\n",
      "Training:  96%|█████████▌| 1699/1772 [04:26<00:10,  6.94it/s, running training loss: 0.7788]\u001b[A\n",
      "Training:  96%|█████████▌| 1700/1772 [04:26<00:10,  7.20it/s, running training loss: 0.7788]\u001b[A\n",
      "Training:  96%|█████████▌| 1700/1772 [04:26<00:10,  7.20it/s, running training loss: 0.7690]\u001b[A\n",
      "Training:  96%|█████████▌| 1701/1772 [04:26<00:09,  7.28it/s, running training loss: 0.7690]\u001b[A\n",
      "Training:  96%|█████████▌| 1701/1772 [04:26<00:09,  7.28it/s, running training loss: 0.7706]\u001b[A\n",
      "Training:  96%|█████████▌| 1702/1772 [04:26<00:10,  6.80it/s, running training loss: 0.7706]\u001b[A\n",
      "Training:  96%|█████████▌| 1702/1772 [04:26<00:10,  6.80it/s, running training loss: 0.7305]\u001b[A\n",
      "Training:  96%|█████████▌| 1703/1772 [04:26<00:10,  6.38it/s, running training loss: 0.7305]\u001b[A\n",
      "Training:  96%|█████████▌| 1703/1772 [04:26<00:10,  6.38it/s, running training loss: 0.8018]\u001b[A\n",
      "Training:  96%|█████████▌| 1704/1772 [04:26<00:10,  6.76it/s, running training loss: 0.8018]\u001b[A\n",
      "Training:  96%|█████████▌| 1704/1772 [04:26<00:10,  6.76it/s, running training loss: 0.8876]\u001b[A\n",
      "Training:  96%|█████████▌| 1705/1772 [04:26<00:09,  6.94it/s, running training loss: 0.8876]\u001b[A\n",
      "Training:  96%|█████████▌| 1705/1772 [04:27<00:09,  6.94it/s, running training loss: 0.7235]\u001b[A\n",
      "Training:  96%|█████████▋| 1706/1772 [04:27<00:09,  6.79it/s, running training loss: 0.7235]\u001b[A\n",
      "Training:  96%|█████████▋| 1706/1772 [04:27<00:09,  6.79it/s, running training loss: 0.8082]\u001b[A\n",
      "Training:  96%|█████████▋| 1707/1772 [04:27<00:09,  6.95it/s, running training loss: 0.8082]\u001b[A\n",
      "Training:  96%|█████████▋| 1707/1772 [04:27<00:09,  6.95it/s, running training loss: 0.9680]\u001b[A\n",
      "Training:  96%|█████████▋| 1708/1772 [04:27<00:09,  6.64it/s, running training loss: 0.9680]\u001b[A\n",
      "Training:  96%|█████████▋| 1708/1772 [04:27<00:09,  6.64it/s, running training loss: 0.7486]\u001b[A\n",
      "Training:  96%|█████████▋| 1709/1772 [04:27<00:09,  6.33it/s, running training loss: 0.7486]\u001b[A\n",
      "Training:  96%|█████████▋| 1709/1772 [04:27<00:09,  6.33it/s, running training loss: 0.7510]\u001b[A\n",
      "Training:  97%|█████████▋| 1710/1772 [04:27<00:09,  6.34it/s, running training loss: 0.7510]\u001b[A\n",
      "Training:  97%|█████████▋| 1710/1772 [04:27<00:09,  6.34it/s, running training loss: 0.5851]\u001b[A\n",
      "Training:  97%|█████████▋| 1711/1772 [04:27<00:10,  6.06it/s, running training loss: 0.5851]\u001b[A\n",
      "Training:  97%|█████████▋| 1711/1772 [04:28<00:10,  6.06it/s, running training loss: 0.7868]\u001b[A\n",
      "Training:  97%|█████████▋| 1712/1772 [04:28<00:09,  6.41it/s, running training loss: 0.7868]\u001b[A\n",
      "Training:  97%|█████████▋| 1712/1772 [04:28<00:09,  6.41it/s, running training loss: 0.7254]\u001b[A\n",
      "Training:  97%|█████████▋| 1713/1772 [04:28<00:09,  6.38it/s, running training loss: 0.7254]\u001b[A\n",
      "Training:  97%|█████████▋| 1713/1772 [04:28<00:09,  6.38it/s, running training loss: 0.7017]\u001b[A\n",
      "Training:  97%|█████████▋| 1714/1772 [04:28<00:09,  6.33it/s, running training loss: 0.7017]\u001b[A\n",
      "Training:  97%|█████████▋| 1714/1772 [04:28<00:09,  6.33it/s, running training loss: 0.9989]\u001b[A\n",
      "Training:  97%|█████████▋| 1715/1772 [04:28<00:08,  6.68it/s, running training loss: 0.9989]\u001b[A\n",
      "Training:  97%|█████████▋| 1715/1772 [04:28<00:08,  6.68it/s, running training loss: 0.9809]\u001b[A\n",
      "Training:  97%|█████████▋| 1716/1772 [04:28<00:08,  6.63it/s, running training loss: 0.9809]\u001b[A\n",
      "Training:  97%|█████████▋| 1716/1772 [04:28<00:08,  6.63it/s, running training loss: 0.4881]\u001b[A\n",
      "Training:  97%|█████████▋| 1717/1772 [04:28<00:09,  5.90it/s, running training loss: 0.4881]\u001b[A\n",
      "Training:  97%|█████████▋| 1717/1772 [04:28<00:09,  5.90it/s, running training loss: 1.0728]\u001b[A\n",
      "Training:  97%|█████████▋| 1718/1772 [04:28<00:08,  6.20it/s, running training loss: 1.0728]\u001b[A\n",
      "Training:  97%|█████████▋| 1718/1772 [04:29<00:08,  6.20it/s, running training loss: 0.8259]\u001b[A\n",
      "Training:  97%|█████████▋| 1719/1772 [04:29<00:09,  5.66it/s, running training loss: 0.8259]\u001b[A\n",
      "Training:  97%|█████████▋| 1719/1772 [04:29<00:09,  5.66it/s, running training loss: 0.9719]\u001b[A\n",
      "Training:  97%|█████████▋| 1720/1772 [04:29<00:09,  5.50it/s, running training loss: 0.9719]\u001b[A\n",
      "Training:  97%|█████████▋| 1720/1772 [04:29<00:09,  5.50it/s, running training loss: 0.8898]\u001b[A\n",
      "Training:  97%|█████████▋| 1721/1772 [04:29<00:09,  5.54it/s, running training loss: 0.8898]\u001b[A\n",
      "Training:  97%|█████████▋| 1721/1772 [04:29<00:09,  5.54it/s, running training loss: 1.2731]\u001b[A\n",
      "Training:  97%|█████████▋| 1722/1772 [04:29<00:08,  5.92it/s, running training loss: 1.2731]\u001b[A\n",
      "Training:  97%|█████████▋| 1722/1772 [04:29<00:08,  5.92it/s, running training loss: 1.0514]\u001b[A\n",
      "Training:  97%|█████████▋| 1723/1772 [04:29<00:08,  6.10it/s, running training loss: 1.0514]\u001b[A\n",
      "Training:  97%|█████████▋| 1723/1772 [04:29<00:08,  6.10it/s, running training loss: 0.8889]\u001b[A\n",
      "Training:  97%|█████████▋| 1724/1772 [04:29<00:07,  6.32it/s, running training loss: 0.8889]\u001b[A\n",
      "Training:  97%|█████████▋| 1724/1772 [04:30<00:07,  6.32it/s, running training loss: 0.5030]\u001b[A\n",
      "Training:  97%|█████████▋| 1725/1772 [04:30<00:07,  6.56it/s, running training loss: 0.5030]\u001b[A\n",
      "Training:  97%|█████████▋| 1725/1772 [04:30<00:07,  6.56it/s, running training loss: 0.8542]\u001b[A\n",
      "Training:  97%|█████████▋| 1726/1772 [04:30<00:07,  6.53it/s, running training loss: 0.8542]\u001b[A\n",
      "Training:  97%|█████████▋| 1726/1772 [04:30<00:07,  6.53it/s, running training loss: 1.0598]\u001b[A\n",
      "Training:  97%|█████████▋| 1727/1772 [04:30<00:06,  6.86it/s, running training loss: 1.0598]\u001b[A\n",
      "Training:  97%|█████████▋| 1727/1772 [04:30<00:06,  6.86it/s, running training loss: 0.4374]\u001b[A\n",
      "Training:  98%|█████████▊| 1728/1772 [04:30<00:06,  6.90it/s, running training loss: 0.4374]\u001b[A\n",
      "Training:  98%|█████████▊| 1728/1772 [04:30<00:06,  6.90it/s, running training loss: 1.0164]\u001b[A\n",
      "Training:  98%|█████████▊| 1729/1772 [04:30<00:06,  7.00it/s, running training loss: 1.0164]\u001b[A\n",
      "Training:  98%|█████████▊| 1729/1772 [04:30<00:06,  7.00it/s, running training loss: 0.7211]\u001b[A\n",
      "Training:  98%|█████████▊| 1730/1772 [04:30<00:05,  7.37it/s, running training loss: 0.7211]\u001b[A\n",
      "Training:  98%|█████████▊| 1730/1772 [04:30<00:05,  7.37it/s, running training loss: 0.6018]\u001b[A\n",
      "Training:  98%|█████████▊| 1731/1772 [04:30<00:05,  7.20it/s, running training loss: 0.6018]\u001b[A\n",
      "Training:  98%|█████████▊| 1731/1772 [04:31<00:05,  7.20it/s, running training loss: 0.7421]\u001b[A\n",
      "Training:  98%|█████████▊| 1732/1772 [04:31<00:05,  7.14it/s, running training loss: 0.7421]\u001b[A\n",
      "Training:  98%|█████████▊| 1732/1772 [04:31<00:05,  7.14it/s, running training loss: 0.5982]\u001b[A\n",
      "Training:  98%|█████████▊| 1733/1772 [04:31<00:05,  6.86it/s, running training loss: 0.5982]\u001b[A\n",
      "Training:  98%|█████████▊| 1733/1772 [04:31<00:05,  6.86it/s, running training loss: 1.1162]\u001b[A\n",
      "Training:  98%|█████████▊| 1734/1772 [04:31<00:05,  6.82it/s, running training loss: 1.1162]\u001b[A\n",
      "Training:  98%|█████████▊| 1734/1772 [04:31<00:05,  6.82it/s, running training loss: 0.8391]\u001b[A\n",
      "Training:  98%|█████████▊| 1735/1772 [04:31<00:05,  6.99it/s, running training loss: 0.8391]\u001b[A\n",
      "Training:  98%|█████████▊| 1735/1772 [04:31<00:05,  6.99it/s, running training loss: 0.4567]\u001b[A\n",
      "Training:  98%|█████████▊| 1736/1772 [04:31<00:04,  7.32it/s, running training loss: 0.4567]\u001b[A\n",
      "Training:  98%|█████████▊| 1736/1772 [04:31<00:04,  7.32it/s, running training loss: 0.6151]\u001b[A\n",
      "Training:  98%|█████████▊| 1737/1772 [04:31<00:05,  6.73it/s, running training loss: 0.6151]\u001b[A\n",
      "Training:  98%|█████████▊| 1737/1772 [04:31<00:05,  6.73it/s, running training loss: 0.5865]\u001b[A\n",
      "Training:  98%|█████████▊| 1738/1772 [04:31<00:04,  7.01it/s, running training loss: 0.5865]\u001b[A\n",
      "Training:  98%|█████████▊| 1738/1772 [04:32<00:04,  7.01it/s, running training loss: 0.5535]\u001b[A\n",
      "Training:  98%|█████████▊| 1739/1772 [04:32<00:04,  7.17it/s, running training loss: 0.5535]\u001b[A\n",
      "Training:  98%|█████████▊| 1739/1772 [04:32<00:04,  7.17it/s, running training loss: 0.7383]\u001b[A\n",
      "Training:  98%|█████████▊| 1740/1772 [04:32<00:04,  7.12it/s, running training loss: 0.7383]\u001b[A\n",
      "Training:  98%|█████████▊| 1740/1772 [04:32<00:04,  7.12it/s, running training loss: 0.8992]\u001b[A\n",
      "Training:  98%|█████████▊| 1741/1772 [04:32<00:04,  7.19it/s, running training loss: 0.8992]\u001b[A\n",
      "Training:  98%|█████████▊| 1741/1772 [04:32<00:04,  7.19it/s, running training loss: 1.3387]\u001b[A\n",
      "Training:  98%|█████████▊| 1742/1772 [04:32<00:04,  7.42it/s, running training loss: 1.3387]\u001b[A\n",
      "Training:  98%|█████████▊| 1742/1772 [04:32<00:04,  7.42it/s, running training loss: 1.1243]\u001b[A\n",
      "Training:  98%|█████████▊| 1743/1772 [04:32<00:04,  7.07it/s, running training loss: 1.1243]\u001b[A\n",
      "Training:  98%|█████████▊| 1743/1772 [04:32<00:04,  7.07it/s, running training loss: 0.5684]\u001b[A\n",
      "Training:  98%|█████████▊| 1744/1772 [04:32<00:04,  6.32it/s, running training loss: 0.5684]\u001b[A\n",
      "Training:  98%|█████████▊| 1744/1772 [04:32<00:04,  6.32it/s, running training loss: 0.5346]\u001b[A\n",
      "Training:  98%|█████████▊| 1745/1772 [04:32<00:04,  6.65it/s, running training loss: 0.5346]\u001b[A\n",
      "Training:  98%|█████████▊| 1745/1772 [04:33<00:04,  6.65it/s, running training loss: 0.8313]\u001b[A\n",
      "Training:  99%|█████████▊| 1746/1772 [04:33<00:03,  6.76it/s, running training loss: 0.8313]\u001b[A\n",
      "Training:  99%|█████████▊| 1746/1772 [04:33<00:03,  6.76it/s, running training loss: 0.6719]\u001b[A\n",
      "Training:  99%|█████████▊| 1747/1772 [04:33<00:03,  6.85it/s, running training loss: 0.6719]\u001b[A\n",
      "Training:  99%|█████████▊| 1747/1772 [04:33<00:03,  6.85it/s, running training loss: 0.8413]\u001b[A\n",
      "Training:  99%|█████████▊| 1748/1772 [04:33<00:03,  6.67it/s, running training loss: 0.8413]\u001b[A\n",
      "Training:  99%|█████████▊| 1748/1772 [04:33<00:03,  6.67it/s, running training loss: 0.9730]\u001b[A\n",
      "Training:  99%|█████████▊| 1749/1772 [04:33<00:03,  6.85it/s, running training loss: 0.9730]\u001b[A\n",
      "Training:  99%|█████████▊| 1749/1772 [04:33<00:03,  6.85it/s, running training loss: 0.8026]\u001b[A\n",
      "Training:  99%|█████████▉| 1750/1772 [04:33<00:03,  7.05it/s, running training loss: 0.8026]\u001b[A\n",
      "Training:  99%|█████████▉| 1750/1772 [04:33<00:03,  7.05it/s, running training loss: 1.1816]\u001b[A\n",
      "Training:  99%|█████████▉| 1751/1772 [04:33<00:02,  7.20it/s, running training loss: 1.1816]\u001b[A\n",
      "Training:  99%|█████████▉| 1751/1772 [04:33<00:02,  7.20it/s, running training loss: 0.8507]\u001b[A\n",
      "Training:  99%|█████████▉| 1752/1772 [04:33<00:02,  6.89it/s, running training loss: 0.8507]\u001b[A\n",
      "Training:  99%|█████████▉| 1752/1772 [04:34<00:02,  6.89it/s, running training loss: 0.6401]\u001b[A\n",
      "Training:  99%|█████████▉| 1753/1772 [04:34<00:02,  7.10it/s, running training loss: 0.6401]\u001b[A\n",
      "Training:  99%|█████████▉| 1753/1772 [04:34<00:02,  7.10it/s, running training loss: 0.5879]\u001b[A\n",
      "Training:  99%|█████████▉| 1754/1772 [04:34<00:02,  7.21it/s, running training loss: 0.5879]\u001b[A\n",
      "Training:  99%|█████████▉| 1754/1772 [04:34<00:02,  7.21it/s, running training loss: 0.5497]\u001b[A\n",
      "Training:  99%|█████████▉| 1755/1772 [04:34<00:02,  7.15it/s, running training loss: 0.5497]\u001b[A\n",
      "Training:  99%|█████████▉| 1755/1772 [04:34<00:02,  7.15it/s, running training loss: 0.8528]\u001b[A\n",
      "Training:  99%|█████████▉| 1756/1772 [04:34<00:02,  7.06it/s, running training loss: 0.8528]\u001b[A\n",
      "Training:  99%|█████████▉| 1756/1772 [04:34<00:02,  7.06it/s, running training loss: 0.7224]\u001b[A\n",
      "Training:  99%|█████████▉| 1757/1772 [04:34<00:02,  6.87it/s, running training loss: 0.7224]\u001b[A\n",
      "Training:  99%|█████████▉| 1757/1772 [04:34<00:02,  6.87it/s, running training loss: 0.7373]\u001b[A\n",
      "Training:  99%|█████████▉| 1758/1772 [04:34<00:02,  6.77it/s, running training loss: 0.7373]\u001b[A\n",
      "Training:  99%|█████████▉| 1758/1772 [04:35<00:02,  6.77it/s, running training loss: 0.8827]\u001b[A\n",
      "Training:  99%|█████████▉| 1759/1772 [04:35<00:02,  6.43it/s, running training loss: 0.8827]\u001b[A\n",
      "Training:  99%|█████████▉| 1759/1772 [04:35<00:02,  6.43it/s, running training loss: 0.6853]\u001b[A\n",
      "Training:  99%|█████████▉| 1760/1772 [04:35<00:01,  6.62it/s, running training loss: 0.6853]\u001b[A\n",
      "Training:  99%|█████████▉| 1760/1772 [04:35<00:01,  6.62it/s, running training loss: 0.4570]\u001b[A\n",
      "Training:  99%|█████████▉| 1761/1772 [04:35<00:01,  6.64it/s, running training loss: 0.4570]\u001b[A\n",
      "Training:  99%|█████████▉| 1761/1772 [04:35<00:01,  6.64it/s, running training loss: 0.8588]\u001b[A\n",
      "Training:  99%|█████████▉| 1762/1772 [04:35<00:01,  6.44it/s, running training loss: 0.8588]\u001b[A\n",
      "Training:  99%|█████████▉| 1762/1772 [04:35<00:01,  6.44it/s, running training loss: 0.5631]\u001b[A\n",
      "Training:  99%|█████████▉| 1763/1772 [04:35<00:01,  6.67it/s, running training loss: 0.5631]\u001b[A\n",
      "Training:  99%|█████████▉| 1763/1772 [04:35<00:01,  6.67it/s, running training loss: 0.5464]\u001b[A\n",
      "Training: 100%|█████████▉| 1764/1772 [04:35<00:01,  6.77it/s, running training loss: 0.5464]\u001b[A\n",
      "Training: 100%|█████████▉| 1764/1772 [04:35<00:01,  6.77it/s, running training loss: 0.7864]\u001b[A\n",
      "Training: 100%|█████████▉| 1765/1772 [04:35<00:01,  6.90it/s, running training loss: 0.7864]\u001b[A\n",
      "Training: 100%|█████████▉| 1765/1772 [04:36<00:01,  6.90it/s, running training loss: 0.6934]\u001b[A\n",
      "Training: 100%|█████████▉| 1766/1772 [04:36<00:00,  6.86it/s, running training loss: 0.6934]\u001b[A\n",
      "Training: 100%|█████████▉| 1766/1772 [04:36<00:00,  6.86it/s, running training loss: 0.7639]\u001b[A\n",
      "Training: 100%|█████████▉| 1767/1772 [04:36<00:00,  7.15it/s, running training loss: 0.7639]\u001b[A\n",
      "Training: 100%|█████████▉| 1767/1772 [04:36<00:00,  7.15it/s, running training loss: 0.7704]\u001b[A\n",
      "Training: 100%|█████████▉| 1768/1772 [04:36<00:00,  7.18it/s, running training loss: 0.7704]\u001b[A\n",
      "Training: 100%|█████████▉| 1768/1772 [04:36<00:00,  7.18it/s, running training loss: 0.6621]\u001b[A\n",
      "Training: 100%|█████████▉| 1769/1772 [04:36<00:00,  7.33it/s, running training loss: 0.6621]\u001b[A\n",
      "Training: 100%|█████████▉| 1769/1772 [04:36<00:00,  7.33it/s, running training loss: 1.1744]\u001b[A\n",
      "Training: 100%|█████████▉| 1770/1772 [04:36<00:00,  7.10it/s, running training loss: 1.1744]\u001b[A\n",
      "Training: 100%|█████████▉| 1770/1772 [04:36<00:00,  7.10it/s, running training loss: 0.6872]\u001b[A\n",
      "Training: 100%|█████████▉| 1771/1772 [04:36<00:00,  6.83it/s, running training loss: 0.6872]\u001b[A\n",
      "Training: 100%|█████████▉| 1771/1772 [04:36<00:00,  6.83it/s, running training loss: 0.4865]\u001b[A\n",
      "Training: 100%|██████████| 1772/1772 [04:37<00:00,  6.40it/s, running training loss: 0.4865]\u001b[A\n",
      "100%|██████████| 1/1 [04:37<00:00, 277.68s/it]\n"
     ]
    }
   ],
   "source": [
    "model, best_model_path = train(config, train_dataloader, dev_dataloader, unsup_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "def predict(config, model, test_dataloader):\n",
    "    test_iterator = tqdm(test_dataloader, desc='Predicting', total=len(test_dataloader))\n",
    "    test_preds = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_iterator:\n",
    "            batch_cuda = {item: value.to(config['device']) for item, value in list(batch.items())}\n",
    "\n",
    "            logits = model(**batch_cuda)[0]\n",
    "\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "            test_preds.append(probs[:, 1].detach().cpu())\n",
    "    \n",
    "    test_preds = torch.cat(test_preds)\n",
    "    test_preds = torch.stack(test_preds.split(2), dim=0).mean(dim=1).numpy()\n",
    "    submission_path = os.path.join(config['output_path'], 'submission.tsv')\n",
    "    test_df = pd.DataFrame(data={'prediction': test_preds})\n",
    "    test_df.to_csv(submission_path, index=False, header=False, encoding='utf8', sep='\\t')\n",
    "    with ZipFile(os.path.join(config['output_path'], 'submission.zip'), 'w') as myzip:\n",
    "        myzip.write(submission_path, 'submission.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 483/483 [00:08<00:00, 55.56it/s]\n"
     ]
    }
   ],
   "source": [
    "predict(config, model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
